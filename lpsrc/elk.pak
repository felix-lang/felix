@head(1,'elkhound')
@h=tangler('licences/elk_licence.txt','data')
@select(h)
The elkhound software
Copyright (c) 2002, Regents of the University of California
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

    * Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.

    * Redistributions in binary form must reproduce the above 
      copyright notice, this list of conditions and the following 
      disclaimer in the documentation and/or other materials provided 
      with the distribution.

    * Neither the name of the University of California, Berkeley nor 
      the names of its contributors may be used to endorse or promote 
      products derived from this software without specific prior 
      written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

@h=tangler('elk/elk_gramexpl.cpp')
@select(h)
// gramexpl.cc            see license.txt for copyright and terms of use
// interactively query and modify a grammar; primary purpose
// is to assist diagnosing SLR conflict reports

#include "elk_gramanl.h"    // GrammarAnalysis
#include "sm_strtokp.h"    // StrtokParse

#include <iostream.h>   // cin/cout


void grammarExplorer(GrammarAnalysis &g)
{
  cout << "exploring the grammar:\n";

  #if 0
  for (;;) {
    cout << "commands:\n"
            "  terminals\n"
            "  nonterminals\n"
            "  productions <nonterm-id>\n"
            "  state <state-id>\n"
            "  suppress-except <term-id> (-1 to disable)\n"
            "  reach <state-id>\n"
            "  track-la <state-id> <prod-id> <term-id>\n"
            "  quit\n";
    cout << "command> ";
    cout.flush();

    char buf[80];
    cin >> buf;     // buffer overrun potential, don't care
    if (cin.eof()) break;

    StrtokParse tok(buf, " \n\t");
    if (tok == 0) continue;

    try {
      if (0==strcmp(tok[0], "terminals")) {
        for (int i=0; i < g.numTerminals(); i++) {
          Terminal const *t = g.getTerminal(i);
          t->print(cout);
        }
      }

      else if (0==strcmp(tok[0], "nonterminals")) {
        for (int i=0; i < g.numNonterminals(); i++) {
          Nonterminal const *nt = g.getNonterminal(i);
          nt->print(cout);
        }
      }

      else if (0==strcmp(tok[0], "productions")) {
        int id = atoi(tok[1]);
        Nonterminal const *nt = g.getNonterminal(i);
        int ct=0;
        FOREACH_PRODUCTION(g.productions, iter) {
          if (iter.data()->left == nt) {
            cout << "[" << ct << "] ";   // production id
            iter.data()->print(cout);
          }
          ct++;
        }
      }

      else if (0==strcmp(tok[0], "state")) {
        ItemSet const *is = g.getItemSet(atoi(tok[1]));
        is->print(cout, g);
      }

      else if (0==strcmp(tok[0], "suppress-except")) {
        int id = atoi(tok[1]);
        Terminal const *t = (id==-1? NULL : g.getTerminal(atoi(tok[1])));
        DottedProduction::lookaheadSuppressExcept = t;
        if (t) {
          cout << "suppressing  " << t->name << endl;
        }
        else {
          cout << "suppressing nothing\n";
        }
      }

      else if (0==strcmp(tok[0], "reach")) {
        int targetId = atoi(tok[1]);

        // consider every state..
        for (int i=0; i < g.numItemSets(); i++) {
          ItemSet const *set = g.getItemSet(i);

          // iterate over all possible symbols to find transitions
          for (int termId=0; termId < g.numTerminals(); termId++) {
            ItemSet const *dest = set->transitionC(g.getTerminal(termId));
            if (dest && dest->id == targetId) {
              dest->print(cout, g);
            }
          }
          for (int nontermId=0; nontermId < g.numNonterminals(); nontermId++) {
            ItemSet const *dest = set->transitionC(g.getNonterminal(nontermId));
            if (dest && dest->id == targetId) {
              dest->print(cout, g);
            }
          }
        }
      }

      else if (0==strcmp(tok[0], "track-la")) {
        int stateId = atoi(tok[1]);
        ItemSet const *set = g.getItemSet(stateId);

        int prodId = atoi(tok[2]);                 
        Production const *prod = g.productions.nth(prodId);

        int termId = atoi(tok[3]);                         
        Terminal const *term = g.getTerminal(termId);
        
        






      }
      else if (0==strcmp(tok[0], "quit")) {
      }
      else {
        cout << "unknown command: " << tok[0] << endl;
      }
    }
    catch (xArrayBounds &) {
      cout << "too few arguments to " << tok[0] << endl;
    }








  #endif // 0

}


@h=tangler('elk/elk_asockind.h')
@select(h)
// asockind.h            see license.txt for copyright and terms of use
// AssocKind; pulled out on its own so I don't have dependency problems

#ifndef ASOCKIND_H
#define ASOCKIND_H

#include "sm_str.h"
  
// specifies what to do when there is a shift/reduce conflict, and
// the production and token have the same precedence; this is attached
// to the token
enum AssocKind {
  AK_LEFT,            // disambiguate by reducing
  AK_RIGHT,           // disambiguate by shifting
  AK_NONASSOC,        // make it a parse-time syntax error
  AK_NEVERASSOC,      // make it a parsgen-time specification error
  AK_SPLIT,           // (GLR-specific) fork the parser

  NUM_ASSOC_KINDS
};

sm_string toString(AssocKind k);

#endif // ASOCKIND_H
@h=tangler('elk/elk_cyctimer.h')
@select(h)
// cyctimer.h            see license.txt for copyright and terms of use
// simple cycles/milliseconds timer

#ifndef CYCTIMER_H
#define CYCTIMER_H

#include "sm_str.h"

class CycleTimer {
public:
  unsigned long long startCycles;
  unsigned long startMilliseconds;
  
public:
  CycleTimer();            // starts timer
  sm_string elapsed() const;  // formats elapsed time as "NN ms, NN_NNNNNN cycles"
};

#endif // CYCTIMER_H
@h=tangler('elk/elk_emitcode.h')
@select(h)
// emitcode.h            see license.txt for copyright and terms of use
// track state of emitted code so I can emit #line too

#ifndef EMITCODE_H
#define EMITCODE_H
  
#include <fstream.h>      // ofstream
#include "sm_str.h"
#include "sm_srcloc.h"

class EmitCode : public sm_stringBuilder {
private:     // data
  ofstream os;         // stream to write to
  sm_string fname;        // filename for emitting #line
  int line;            // current line number

public:      // funcs
  EmitCode(char const *fname);
  ~EmitCode();

  sm_string const &getFname() const { return fname; }

  // get current line number; flushes internally
  int getLine();

  // flush data in sm_stringBuffer to 'os'
  void flush();
};


// return a #line directive for the given location
sm_string lineDirective(SourceLoc loc);  

// emit a #line directive to restore reporting to the
// EmitCode file itself (the 'sb' argument must be an EmitFile object)
sm_stringBuilder &restoreLine(sm_stringBuilder &sb);


#endif // EMITCODE_H
@h=tangler('elk/elk_flatutil.h')
@select(h)
// flatutil.h            see license.txt for copyright and terms of use
// flatten helpers

#ifndef FLATUTIL_H
#define FLATUTIL_H

#include "sm_flatten.h"
#include "sm_objlist.h"
#include "sm_sobjlist.h"


// ------------- xfer of owners -----------------
template <class T>
void xferOwnerPtr(Flatten &flat, T *&ptr)
{
  if (flat.reading()) {
    // construct a new, empty object
    ptr = new T(flat);
  }

  // read/write it
  ptr->xfer(flat);

  // note it so we can have serfs to it
  flat.noteOwner(ptr);
}


template <class T>
void xferOwnerPtr_readObj(Flatten &flat, T *&ptr)
{
  if (flat.reading()) {
    // construct a new object, *and* read it from file
    ptr = T::readObj(flat);
  }
  else {
    // write it
    ptr->xfer(flat);
  }

  // note it so we can have serfs to it
  flat.noteOwner(ptr);
}


template <class T>
void xferObjList(Flatten &flat, ObjList <T> &list)
{
  if (flat.writing()) {
    flat.writeInt(list.count());

    MUTATE_EACH_OBJLIST(T, list, iter) {
      iter.data()->xfer(flat);
      flat.noteOwner(iter.data());
    }
  }
  else {
    int listLen = flat.readInt();

    ObjListMutator<T> mut(list);
    while (listLen--) {
      // construct a new, empty object
      T *obj = new T(flat);

      // read it
      obj->xfer(flat);
      flat.noteOwner(obj);

      // add it to the list
      mut.append(obj);
    }
  }
}


// for things like AExprNode which have a readObj
// static method .. it's possible to merge this with
// the above code, but I'm not sure that's a good idea yet
template <class T>
void xferObjList_readObj(Flatten &flat, ObjList <T> &list)
{
  if (flat.writing()) {
    flat.writeInt(list.count());

    MUTATE_EACH_OBJLIST(T, list, iter) {
      iter.data()->xfer(flat);
      flat.noteOwner(iter.data());
    }
  }
  else {
    int listLen = flat.readInt();

    ObjListMutator<T> mut(list);
    while (listLen--) {
      // construct a new object, *and* read its
      // contents from the file
      T *obj = T::readObj(flat);
      flat.noteOwner(obj);

      // add it to the list
      mut.append(obj);
    }
  }
}


// ------------- xfer of serfs -----------------
// xfer a list of serf pointers to objects, each object
// could be in one of several owner lists
template <class T>
void xferSObjList_multi(Flatten &flat, SObjList<T> &list,
                        ObjList<T> **masterLists, int numMasters)
{
  // be sure the same number of master lists are used at
  // read and write time
  flat.checkpoint(numMasters);

  if (flat.writing()) {
    flat.writeInt(list.count());

    SMUTATE_EACH_OBJLIST(T, list, iter) {
      // determine which master list it's in
      int master;
      for (master = 0; master<numMasters; master++) {
        int index = masterLists[master]->indexOf(iter.data());
        if (index != -1) {
          // we found it -- encode the list and its index
          if (numMasters > 1) {
            flat.writeInt(master);    // only do this if multiple masters
          }
          flat.writeInt(index);
          break;
        }
      }

      if (master == numMasters) {
        // failed to find the master list
        xfailure("xferSObjList_multi: obj not in any of the lists");
      }
    }
  }

  else {
    int listLen = flat.readInt();

    SObjListMutator<T> mut(list);
    while (listLen--) {
      int master = 0;               // assume just 1 master
      if (numMasters > 1) {
        master = flat.readInt();    // then refine
      }

      mut.append(masterLists[master]->nth(flat.readInt()));
    }
  }
}


// xfer a list of serf pointers to objects owner by 'masterList'
template <class T>
void xferSObjList(Flatten &flat, SObjList<T> &list, ObjList<T> &masterList)
{
  ObjList<T> *ptr = &masterList;
  xferSObjList_multi(flat, list, &ptr, 1 /*numMasters*/);
}


// xfer a pointer which points to something in a master list
template <class T>
void xferSerfPtrToList(Flatten &flat, T *&ptr, ObjList<T> &masterList)
{
  if (flat.writing()) {
    flat.writeInt(masterList.indexOfF(ptr));
  }
  else {
    ptr = masterList.nth(flat.readInt());
  }
}


template <class T>
void xferNullableSerfPtrToList(Flatten &flat, T *&ptr, ObjList<T> &masterList)
{
  if (flat.writing()) {
    flat.writeInt(masterList.indexOf(ptr));
  }
  else {
    int index = flat.readInt();
    if (index >= 0) {
      ptr = masterList.nth(index);
    }
    else {
      ptr = NULL;
    }
  }
}

                  
template <class T>
void computedValue(Flatten &flat, T &variable, T value)
{
  if (flat.writing()) {
    // check it
    xassert(variable == value);
  }
  else {
    // set it
    variable = value;
  }
}


// void* implementation
//#define Leaf void
//#define Root void
//#define FirstLevel void
template <class Root, class FirstLevel, class Leaf>
void xferSerfPtr_twoLevelAccess(
  Flatten &flat,
  Leaf *&leaf,
  Root *root,
  FirstLevel* (*getNthFirst)(Root *r, int n),
  Leaf* (*getNthLeaf)(FirstLevel *f, int n))
{
  if (flat.writing()) {
    // determine both indices
    for (int index1=0; ; index1++) {
      // get a first-level obj
      FirstLevel *first = getNthFirst(root, index1);
      if (!first) {
        // exhausted first-level objs
        xfailure("xferSerfPtr_twoLevelAccess: couldn't find obj to xfer");
      }

      // look for the leaf inside it
      for (int index2=0; ; index2++) {
        Leaf *second = getNthLeaf(first, index2);
        if (second == leaf) {
          // found it; encode both indices
          flat.writeInt(index1);
          flat.writeInt(index2);
          return;
        }
        if (second == NULL) {
          // exhausted this subtree
          break;
        }
      } // end of iter over leaves
    } // end of iter over first-lvl objs
  }

  else /*reading*/ {
    // read both indicies
    int index1 = flat.readInt();
    int index2 = flat.readInt();

    // follow the access path
    FirstLevel *first = getNthFirst(root, index1);
    formatAssert(first != NULL);
    Leaf *second = getNthLeaf(first, index2);
    formatAssert(second != NULL);

    // found it
    leaf = second;
  }
}
//#undef Leaf
//#undef Root
//#undef FirstLevel


#if 0
typedef void *accessFunc_void(void *parent, int childNum);

// typesafe interface
template <class Root, class FirstLevel, class Leaf>
inline void xferSerfPtr_twoLevelAccess(
  Flatten &flat,
  Leaf *&leaf,
  Root *root,
  FirstLevel* (*getNthFirst)(Root *r, int n),
  Leaf* (*getNthLeaf)(FirstLevel *f, int n))
{
  xferSerfPtr_twoLevelAccess(
    flat,
    (void*&)leaf,
    (void*)root,
    (accessFunc_void)getNthFirst,
    (accessFunc_void)getNthLeaf);
}
#endif // 0


template <class Root, class FirstLevel, class Leaf>
void xferSObjList_twoLevelAccess(
  Flatten &flat,
  SObjList<Leaf> &serfList,
  Root *root,
  FirstLevel* (*getNthFirst)(Root *r, int n),
  Leaf* (*getNthLeaf)(FirstLevel *f, int n))
{
  if (flat.writing()) {
    // length of list
    flat.writeInt(serfList.count());

    // iterate over list
    SMUTATE_EACH_OBJLIST(Leaf, serfList, iter) {
      // write the obj
      Leaf *leaf = iter.data();
      xferSerfPtr_twoLevelAccess(
        flat, leaf, root,
        getNthFirst, getNthLeaf);
    }
  }
  else {
    int length = flat.readInt();

    SObjListMutator<Leaf> mut(serfList);
    while (length--) {
      // read the obj
      Leaf *leaf;
      xferSerfPtr_twoLevelAccess(
        flat, leaf, root,
        getNthFirst, getNthLeaf);

      // store it in the list
      mut.append(leaf);
    }
  }
}


template <class T>
void xferSerfPtr(Flatten &flat, T *&serfPtr)
{
  flat.xferSerf((void*&)serfPtr, false /*nullable*/);
}

template <class T>
void xferNullableSerfPtr(Flatten &flat, T *&serfPtr)
{
  flat.xferSerf((void*&)serfPtr, true /*nullable*/);
}


#endif // FLATUTIL_H
@h=tangler('elk/elk_genml.h')
@select(h)
// genml.h            see license.txt for copyright and terms of use
// extension to gramanl module that generates ML instead of C

#ifndef GENML_H
#define GENML_H

class GrammarAnalysis;

// entry point
void emitMLActionCode(GrammarAnalysis const &g, char const *mliFname,
                      char const *mlFname, char const *srcFname);

#endif // GENML_H
@h=tangler('elk/elk_glrconfig.h')
@select(h)
// glrconfig.h
// do not edit; generated by ./configure

// glrconfig.h.in            see license.txt for copyright and terms of use
// compile-time configuration options which affect the generated
// GLR parser, and the interface to the user actions

#ifndef GLRCONFIG_H
#define GLRCONFIG_H


// when NO_GLR_SOURCELOC is #defined, we disable all support for
// automatically propagating source location information in the
// parser; user actions can still refer to 'loc', but they just get
// a dummy no-location value
#ifndef GLR_SOURCELOC
  #define GLR_SOURCELOC 1        // set by ./configure
#endif

#if GLR_SOURCELOC
  #define SOURCELOC(stuff) stuff

  // this one adds a leading comma (I can't put that into the
  // argument <stuff>, because then it looks like the macro is
  // being passed 2 arguments)
  #define SOURCELOCARG(stuff) , stuff

  #define NOSOURCELOC(stuff)
#else
  #define SOURCELOC(stuff)
  #define SOURCELOCARG(stuff)
  #define NOSOURCELOC(stuff) stuff
#endif


// when enabled, NODE_COLUMN tracks in each stack node the
// appropriate column to display it for in debugging dump.
// in the new RWL core, this is required to always be 1.
#ifndef ENABLE_NODE_COLUMNS
  #define ENABLE_NODE_COLUMNS 1
#endif
#if ENABLE_NODE_COLUMNS
  #define NODE_COLUMN(stuff) stuff
#else
  #define NODE_COLUMN(stuff)
#endif


// when enabled, YIELD_COUNT keeps track of the number of times a
// given semantic value is yielded; this is useful for warning the
// user when a merge is performed but one of the merged values has
// already been yielded to another semantic action, which implies
// that the induced parse forest is incomplete
#ifndef ENABLE_YIELD_COUNT
  #define ENABLE_YIELD_COUNT 1
#endif
#if ENABLE_YIELD_COUNT
  #define YIELD_COUNT(stuff) stuff
#else
  #define YIELD_COUNT(stuff)
#endif


// when true, error entries in the action table are extracted into
// their own bitmap; this then enables compression on the action
// table, since it makes it sparse
#ifndef ENABLE_EEF_COMPRESSION
  #define ENABLE_EEF_COMPRESSION 0
#endif

// when true, the action and goto tables are compressed using
// graph coloring
#ifndef ENABLE_GCS_COMPRESSION
  #define ENABLE_GCS_COMPRESSION 0
#endif

// when true, action and goto *columns* are merged during GCS;
// otherwise, only rows are merged
#ifndef ENABLE_GCS_COLUMN_COMPRESSION
  #define ENABLE_GCS_COLUMN_COMPRESSION 0
#endif

// when true, entries in the action and goto tables are a
// 1-byte index into an appropriate map
#ifndef ENABLE_CRS_COMPRESSION
  #define ENABLE_CRS_COMPRESSION 0
#endif



#endif // GLRCONFIG_H
@h=tangler('elk/elk_glr.h')
@select(h)
// glr.h            see license.txt for copyright and terms of use
// GLR parsing algorithm

/*
 * Author: Scott McPeak, April 2000
 *
 * The fundamental concept in Generalized LR (GLR) parsing
 * is to permit (at least local) ambiguity by "forking" the
 * parse stack.  If the input is actually unambiguous, then
 * all but one of the forked parsers will, at some point,
 * fail to shift a symbol, and die.  If the input is truly
 * ambiguous, forked parsers rejoin at some point, and the
 * parse tree becomes a parse DAG, representing all possible
 * parses.  (In fact, since cyclic grammars are supported,
 * which can have an infinite number of parse trees for
 * some inputs, we may end up with a cyclic parse *graph*.)
 *
 * In the larger scheme of things, this level of support for
 * ambiguity is useful because it lets us use simpler and
 * more intuitive grammars, more sophisticated disambiguation
 * techniques, and parsing in the presence of incomplete
 * or incorrect information (e.g. in an editor).
 *
 * The downside is that parsing is slower, and whatever tool
 * processes the parse graph needs to have ways of dealing
 * with the multiple parse interpretations.
 *
 * references:
 *
 *   [GLR]  J. Rekers.  Parser Generation for Interactive
 *          Environments.  PhD thesis, University of
 *          Amsterdam, 1992.  Available by ftp from
 *          ftp://ftp.cwi.nl/pub/gipe/reports/Rek92.ps.Z .
 *          [Contains a good description of the Generalized
 *          LR (GLR) algorithm.]
 */

#ifndef GLR_H
#define GLR_H

#include "elk_glrconfig.h"
#include "elk_parsetables.h"
#include "elk_rcptr.h"
#include "elk_useract.h"
#include "sm_objpool.h"
#include "sm_objlist.h"
#include "sm_srcloc.h"
#include "sm_sobjlist.h"

#include <stdio.h>         // FILE
#include <iostream.h>      // ostream


// fwds from other files
class LexerInterface;      // lexerint.h
class CycleTimer;          // cyctimer.h

// forward decls for things declared below
class StackNode;           // unit of parse state
class SiblingLink;         // connections between stack nodes
class PendingShift;        // for postponing shifts.. may remove
class GLR;                 // main class for GLR parsing


// a pointer from a stacknode to one 'below' it (in the LR
// parse stack sense); also has a link to the parse graph
// we're constructing
class SiblingLink {
public:
  // the stack node being pointed-at; it was created eariler
  // than the one doing the pointing
  RCPtr<StackNode> sib;

  // this is the semantic value associated with this link
  // (parse tree nodes are *not* associated with stack nodes --
  // that's now it was originally, but I figured out the hard
  // way that's wrong (more info in compiler.notes.txt));
  // this is an *owner* pointer
  SemanticValue sval;

  // the source location of the left edge of the subtree rooted
  // at this stack node; this is in essence part of the semantic
  // value, but automatically propagated by the parser
  SOURCELOC( SourceLoc loc; )

  // number of times this 'sval' has been yielded; this is used
  // to track cases where we yield a value and then merge it
  // (which means the induced parse forest is incomplete)
  YIELD_COUNT( int yieldCount; )

  // if you add additional fields, they need to be inited in the
  // constructor *and* in StackNode::addFirstSiblingLink_noRefCt

public:
  SiblingLink(StackNode *s, SemanticValue sv
              SOURCELOCARG( SourceLoc L ) );
  ~SiblingLink();
  
  #if GLR_SOURCELOC
    bool validLoc() const { return loc != SL_UNKNOWN; }
  #else
    bool validLoc() const { return false; }
  #endif
};


// the GLR parse state is primarily made up of a graph of these
// nodes, which play a role analogous to the stack nodes of a
// normal LR parser; GLR nodes form a graph instead of a linear
// stack because choice points (real or potential ambiguities)
// are represented as multiple left-siblings
class StackNode {
public:
  // the LR state the parser is in when this node is at the
  // top ("at the top" means that nothing, besides perhaps itself,
  // is pointing to it)
  //ItemSet const * const state;                 // (serf)
  StateId state;       // now it is an id

  // each leftSibling points to a stack node in one possible LR stack.
  // if there is more than one, it means two or more LR stacks have
  // been joined at this point.  this is the parse-time representation
  // of ambiguity (actually, unambiguous grammars or inputs do
  // sometimes lead to multiple siblings)
  ObjList<SiblingLink> leftSiblings;           // this is a set

  // the *first* sibling is simply embedded directly into the
  // stack node, to avoid list overhead in the common case of
  // only one sibling; when firstSib.sib==NULL, there are no
  // siblings
  SiblingLink firstSib;

  // number of sibling links pointing at 'this', plus the number
  // of worklists on which 'this' appears (some liberty is taken
  // in the mini-LR parser, but it is carefully documented there)
  int referenceCount;

  // how many stack nodes can I pop before hitting a nondeterminism?
  // if this node itself has >1 sibling link, determinDepth==0; if
  // this node has 1 sibling, but that sibling has >1 sibling, then
  // determinDepth==1, and so on; if this node has 0 siblings, then
  // determinDepth==1
  int determinDepth;

  union {
    // somewhat nonideal: I need access to the 'userActions' to
    // deallocate semantic values when refCt hits zero, and I need
    // to map states to state-symbols for the same reason.
    // update: now I'm also using this to support pool-based
    // deallocation in decRefCt()
    GLR *glr;

    // this is used by the ObjectPool which handles allocation of
    // StackNodes
    StackNode *nextInFreeList;
  };

  // ordinal position of the token that was being processed
  // when this stack node was created; this information is useful
  // for laying out the nodes when visualizing the GSS, but is
  // not used by the parsing algorithm itself
  NODE_COLUMN( int column; )

  // count and high-water for stack nodes
  static int numStackNodesAllocd;
  static int maxStackNodesAllocd;
                           
  
private:    // funcs
  SiblingLink *
    addAdditionalSiblingLink(StackNode *leftSib, SemanticValue sval
                             SOURCELOCARG( SourceLoc loc ) );

public:     // funcs
  StackNode();
  ~StackNode();

  // ctor/dtor from point of view of the object pool user
  void init(StateId state, GLR *glr);
  void deinit();

  // internal workings of 'deinit', exposed for performance reasons
  inline void decrementAllocCounter();
  void deallocSemanticValues();

  // add a new link with the given tree node; return the link
  SiblingLink *addSiblingLink(StackNode *leftSib, SemanticValue sval
                              SOURCELOCARG( SourceLoc loc ) );
                                
  // specialized version for performance-critical sections
  inline void
    addFirstSiblingLink_noRefCt(StackNode *leftSib, SemanticValue sval
                                SOURCELOCARG( SourceLoc loc ) );

  // return the symbol represented by this stack node;  it's
  // the symbol shifted or reduced-to to get to this state
  // (this used to be a data member, but there are at least
  // two ways to compute it, so there's no need to store it)
  SymbolId getSymbolC() const;

  // reference count stuff
  void incRefCt() { referenceCount++; }
  void decRefCt();

  // sibling count queries (each one answerable in constant time)
  bool hasZeroSiblings() const { return firstSib.sib==NULL; }
  bool hasOneSibling() const { return firstSib.sib!=NULL && leftSiblings.isEmpty(); }
  bool hasMultipleSiblings() const { return leftSiblings.isNotEmpty(); }

  // when you expect there's only one sibling link, get it this way
  SiblingLink const *getUniqueLinkC() const;
  SiblingLink *getUniqueLink() { return const_cast<SiblingLink*>(getUniqueLinkC()); }

  // retrieve pointer to the sibling link to a given node, or NULL if none
  SiblingLink *getLinkTo(StackNode *another);

  // recompute my determinDepth based on siblings, 
  // but don't actually change the state
  int computeDeterminDepth() const;

  // debugging
  static void printAllocStats();
  void checkLocalInvariants() const;
};


// this is a priority queue of stack node paths that are candidates to
// reduce, maintained such that we can select paths in an order which
// will avoid yield-then-merge
class ReductionPathQueue {
public:       // types
  // a single path in the stack
  class Path {
  public:     // data
    // ---- right edge info ----
    // the rightmost state's id; we're reducing in this state
    StateId startStateId;

    // id of the production with which we're reducing
    int prodIndex;

    // ---- left edge info ----
    // the token column (ordinal position of a token in the token
    // stream) of the leftmost stack node; the smaller the
    // startColumn, the more tokens this reduction spans
    int startColumn;

    // stack node at the left edge; our reduction will push a new
    // stack node on top of this one
    StackNode *leftEdgeNode;

    // ---- path in between ----
    // array of sibling links, naming the path; 'sibLink[0]' is the
    // leftmost link; array length is given by the rhsLen of
    // prodIndex's production
    GrowArray<SiblingLink*> sibLinks;    // (array of serfs)

    // corresponding array of symbol ids so we know how to interpret
    // the semantic values in the links
    GrowArray<SymbolId> symbols;

    union {
      // link between nodes for construction of a linked list,
      // kept in sorted order
      Path *next;

      // link for free list in the object pool
      Path *nextInFreeList;
    };

  public:     // funcs
    Path();
    ~Path();

    void init(StateId startStateId, int prodIndex, int rhsLen);
    void deinit() {}
  };

private:      // data
  // head of the list
  Path *top;

  // allocation pool of Path objects
  ObjectPool<Path> pathPool;

  // parse tables, so we can decode prodIndex and also compare
  // production ids for sorting purposes
  ParseTables *tables;
       
private:      // funcs
  bool goesBefore(Path const *p1, Path const *p2) const;

public:       // funcs
  ReductionPathQueue(ParseTables *t);
  ~ReductionPathQueue();

  // get another Path object, inited with these values
  Path *newPath(StateId startStateId, int prodIndex, int rhsLen);

  // make a copy of the prototype 'src', fill in its left-edge
  // fields using 'leftEdge', and insert it into sorted order
  // in the queue
  void insertPathCopy(Path const *src, StackNode *leftEdge);
                       
  // true if there are no more paths
  bool isEmpty() const { return top == NULL; }
  bool isNotEmpty() const { return !isEmpty(); }

  // remove the next path to reduce from the list, and return it
  Path *dequeue();

  // mark a path as not being used, so it will be recycled into the pool
  void deletePath(Path *p);
};


// each GLR object is a parser for a specific grammar, but can be
// used to parse multiple token streams
class GLR {
public:
  // ---- grammar-wide data ----
  // user-specified actions
  UserActions *userAct;                     // (serf)

  // parse tables derived from the grammar
  ParseTables *tables;                      // (serf)

  // ---- parser state between tokens ----
  // I keep a pointer to this so I can ask for token descriptions
  // inside some of the helper functions
  LexerInterface *lexerPtr;                 // (serf)

  // Every node in this set is (the top of) a parser that might
  // ultimately succeed to parse the input, or might reach a
  // point where it cannot proceed, and therefore dies.  (See
  // comments at top of glr.cc for more details.)
  ArrayStack<StackNode*> topmostParsers;     // (refct list)

  // index: StateId -> index in 'topmostParsers' of unique parser
  // with that state, or INDEX_NO_PARSER if none has that state
  typedef unsigned char ParserIndexEntry;
  enum { INDEX_NO_PARSER = 255 };
  ParserIndexEntry *parserIndex;            // (owner)

  // this is for assigning unique ids to stack nodes
  int nextStackNodeId;
  enum { initialStackNodeId = 1 };

  // ---- parser state during each token ----
  // I used to have fields:
  //   int currentTokenType;
  //   SemanticValue currentTokenValue;
  //   SourceLoc currentTokenLoc;
  // but these have been now replaced by, respectively,
  //   lexerPtr->type
  //   lexerPtr->sval
  //   lexerPtr->loc

  // ---- scratch space re-used at token-level (or finer) granularity ----
  // to be regarded as a local variable of GLR::rwlProcessWorklist
  GrowArray<SemanticValue> toPass;

  // persistent array that I swap with 'topmostParsers' during
  // 'rwlShiftTerminals' to avoid extra copying or allocation;
  // this should be regarded as variable local to that function
  ArrayStack<StackNode*> prevTopmost;        // (refct list)

  // ---- allocation pools ----
  // this is a pointer to the same-named local variable in innerGlrParse
  ObjectPool<StackNode> *stackNodePool;
                               
  // pool and list for the RWL implementation
  ReductionPathQueue pathQueue;

  // ---- user options ----
  // when true, failed parses are accompanied by some rudimentary
  // diagnosis; when false, failed parses are silent (default: true)
  bool noisyFailedParse;

  // ---- debugging trace ----
  // these are computed during GLR::GLR since the profiler reports
  // there is significant expense to computing the debug sm_strings
  // (that are then usually not printed)
  bool trParse;                             // tracingSys("parse")
  ostream &trsParse;                        // trace("parse")

  // track column for new nodes
  NODE_COLUMN( int globalNodeColumn; )

  // statistics on parser actions
  int detShift, detReduce, nondetShift, nondetReduce;
  
  // count of # of times yield-then-merge happens
  int yieldThenMergeCt;

private:    // funcs
  // comments in glr.cc
  SemanticValue duplicateSemanticValue(SymbolId sym, SemanticValue sval);
  void deallocateSemanticValue(SymbolId sym, SemanticValue sval);
  SemanticValue grabTopSval(StackNode *node);

  StackNode *findTopmostParser(StateId state);
  StackNode *makeStackNode(StateId state);
  void writeParseGraph(char const *input) const;
  void clearAllStackNodes();
  void addTopmostParser(StackNode *parser);
  void pullFromTopmostParsers(StackNode *parser);
  bool canMakeProgress(StackNode *parser);
  void dumpGSS(int tokenNumber) const;
  void dumpGSSEdge(FILE *dest, StackNode const *src,
                               StackNode const *target) const;
  void printConfig() const;
  void buildParserIndex();
  void printParseErrorMessage(StateId lastToDie);
  bool cleanupAfterParse(CycleTimer &timer, SemanticValue &treeTop);
  bool nondeterministicParseToken();
  static bool innerGlrParse(GLR &glr, LexerInterface &lexer, SemanticValue &treeTop);
  SemanticValue doReductionAction(
    int productionId, SemanticValue const *svals
    SOURCELOCARG( SourceLoc loc ) );

  void rwlProcessWorklist();
  SiblingLink *rwlShiftNonterminal(StackNode *leftSibling, int lhsIndex,
                                   SemanticValue /*owner*/ sval
                                   SOURCELOCARG( SourceLoc loc ) );
  int rwlEnqueueReductions(StackNode *parser, ActionEntry action,
                           SiblingLink *sibLink);
  void rwlCollectPathLink(
    ReductionPathQueue::Path *proto, int popsRemaining,
    StackNode *currentNode, SiblingLink *mustUseLink, SiblingLink *linkToAdd);
  void rwlRecursiveEnqueue(
    ReductionPathQueue::Path *proto,
    int popsRemaining,
    StackNode *currentNode,
    SiblingLink *mustUseLink);
  void rwlShiftTerminals();

  void configCheck(char const *option, bool core, bool table);

  sm_string stackSummary() const;
  void nodeSummary(sm_stringBuilder &sb, StackNode const *node) const;
  void innerStackSummary(sm_stringBuilder &sb,
                         SObjList<StackNode const> &printed,
                         StackNode const *node) const;

public:     // funcs
  GLR(UserActions *userAct, ParseTables *tables);
  ~GLR();

  // ------- primary interface -------
  // read the named grammar file (.bin extension, typically)
  void readBinaryGrammar(char const *grammarFname);

  // parse, using the token stream in 'lexer', and store the final
  // semantic value in 'treeTop'
  bool glrParse(LexerInterface &lexer, SemanticValue &treeTop);

};


#endif // GLR_H
@h=tangler('elk/elk_gramanl.h')
@select(h)
// gramanl.h            see license.txt for copyright and terms of use
// grammar analysis module; separated from grammar.h to
//   reduce mixing of representation and algorithm; this
//   module should be entirely algorithm

// Author: Scott McPeak, April 2000
// Updates: March 2002

// references:
//
//   [ASU]  Aho, Sethi Ullman.  Compilers: Principles,
//          Techniques, and Tools.  Addison-Wesley,
//          Reading, MA.  1986.  Second printing (3/88).
//          [A classic reference for LR parsing.]


#ifndef __GRAMANL_H
#define __GRAMANL_H

#include "elk_grammar.h"
#include "sm_ohashtbl.h"
#include "sm_okhashtbl.h"
#include "sm_okhasharr.h"
#include "elk_glrconfig.h"
#include "elk_parsetables.h"

// forward decls
class Bit2d;              // bit2d.h
class BitArray;           // bitarray.h
class EmitCode;           // emitcode.h

// this file
class GrammarAnalysis;


// ---------------- DottedProduction --------------------
// a production, with an indicator that says how much of this
// production has been matched by some part of the input sm_string
// (exactly which part of the input depends on where this appears
// in the algorithm's data structures)
class DottedProduction {
// ------ representation ------
private:    // data
  Production const *prod;        // (serf) the base production
  int dot;                       // 0 means it's before all RHS symbols, 1 means after first, etc.

// -------- annotation ----------
private:    // data
  // performance optimization: NULL if dot at end, or else pointer
  // to the symbol right after the dot
  Symbol *afterDot;

public:     // data    
  // First of the sentential form that follows the dot; this set
  // is computed by GrammarAnalysis::computeDProdFirsts
  TerminalSet firstSet;
  
  // also computed by computeDProdFirsts, this is true if the
  // sentential form can derive epsilon (the empty sm_string)
  bool canDeriveEmpty;

  // during item set closure, I need a way to map from dotted prods to
  // the items which use them; so rather than use a hash table, I'll
  // just annotate the dprods themselves with backpointers; these
  // backpointers *must* be maintained as NULL when there's no
  // association
  mutable class LRItem *backPointer;

private:    // funcs
  void init();

public:     // funcs
  //DottedProduction(DottedProduction const &obj);

  // need the grammar passed during creation so we know how big
  // to make 'lookahead'
  //DottedProduction(GrammarAnalysis const &g);       // for later filling-in
  //DottedProduction(/*GrammarAnalysis const &g,*/ Production *p, int d);
  DottedProduction();     // for creating arrays of them
  ~DottedProduction();

  // no point to flattening these because they're easily re-computable
  #if 0
  DottedProduction(Flatten&);
  void xfer(Flatten &flat);
  void xferSerfs(Flatten &flat, GrammarAnalysis &g);
  #endif // 0

  // simple queries
  Production const *getProd() const { return prod; }
  int getDot() const { return dot; }
  bool isDotAtStart() const { return dot==0; }
  bool isDotAtEnd() const { return afterDot==NULL; }

  // no need for equality now, since all DPs with the same
  // prod/dot are shared
  //bool isEqual(DottedProduction const &obj) const;
  //bool operator== (DottedProduction const &obj) const;

  // call this to change prod and dot
  void setProdAndDot(Production const *p, int d);

  // dot must not be at the start (left edge)
  Symbol const *symbolBeforeDotC() const;
  Symbol *symbolBeforeDot() { return const_cast<Symbol*>(symbolBeforeDotC()); }

  // dot must not be at the end (right edge)
  Symbol const *symbolAfterDotC() const { return afterDot; }
  Symbol *symbolAfterDot() { return const_cast<Symbol*>(symbolAfterDotC()); }

  // print to cout as 'A -> B . c D' (no newline)
  void print(ostream &os/*, GrammarAnalysis const &g*/) const;
  OSTREAM_OPERATOR(DottedProduction)
};

// lists of dotted productions
typedef ObjList<DottedProduction> DProductionList;
typedef ObjListIter<DottedProduction> DProductionListIter;
typedef SObjList<DottedProduction> SDProductionList;
typedef SObjListIter<DottedProduction> SDProductionListIter;

#define FOREACH_DOTTEDPRODUCTION(list, iter) FOREACH_OBJLIST(DottedProduction, list, iter)
#define MUTATE_EACH_DOTTEDPRODUCTION(list, iter) MUTATE_EACH_OBJLIST(DottedProduction, list, iter)
#define SFOREACH_DOTTEDPRODUCTION(list, iter) SFOREACH_OBJLIST(DottedProduction, list, iter)
#define SMUTATE_EACH_DOTTEDPRODUCTION(list, iter) SMUTATE_EACH_OBJLIST(DottedProduction, list, iter)


// --------------- LRItem ---------------
// a dotted production with a lookahead; whereas each production
// has a fixed number of dotted versions of that production, there
// can be lots of items, because of the differing lookahead sets
// (I prefer the name "LRItem" to simply "Item" because the latter
// easily collides with other uses)
class LRItem {
public:    // data
  DottedProduction const *dprod;  // (serf) production and dot position
  TerminalSet lookahead;          // lookahead symbols

public:    // funcs
  LRItem(LRItem const &obj);
  ~LRItem();

  // need 'numTerms' to tell how big to make 'lookahead'
  LRItem(int numTerms, DottedProduction const *dp);

  LRItem(Flatten&);
  void xfer(Flatten &flat);
  void xferSerfs(Flatten &flat, GrammarAnalysis &g);

  // comparison
  static int diff(LRItem const *a, LRItem const *b, void*);
  bool equalNoLA(LRItem const &obj) const
    { return dprod == obj.dprod; }

  // manipulate the lookahead set
  bool laContains(int terminalId) const
    { return lookahead.contains(terminalId); }
  void laAdd(int terminalId)
    { lookahead.add(terminalId); }
  void laRemove(int terminalId)
    { lookahead.remove(terminalId); }
  void laCopy(LRItem const &obj)
    { lookahead.copy(obj.lookahead); }
  bool laMerge(LRItem const &obj)     // returns true if merging changed lookahead
    { return lookahead.merge(obj.lookahead); }
  bool laIsEqual(LRItem const &obj) const
    { return lookahead.isEqual(obj.lookahead); }

  // pass-thru queries into 'dprod'
  Production const *getProd() const
    { return dprod->getProd(); }
  int getDot() const
    { return dprod->getDot(); }
  bool isDotAtStart() const
    { return dprod->isDotAtStart(); }
  bool isDotAtEnd() const
    { return dprod->isDotAtEnd(); }
  Symbol const *symbolBeforeDotC() const
    { return dprod->symbolBeforeDotC(); }
  Symbol const *symbolAfterDotC() const
    { return dprod->symbolAfterDotC(); }
    
  int prodIndex() const
    { return getProd()->prodIndex; }

  // stuff for insertion into a hash table
  static unsigned hash(DottedProduction const *key);
  static DottedProduction const *dataToKey(LRItem *dp);
  static bool dpEqual(DottedProduction const *key1, DottedProduction const *key2);

  // true if this item is "A -> alpha * t beta"
  bool isExtendingShift(Nonterminal const *A, Terminal const *t) const;

  void print(ostream &os, GrammarAnalysis const &g) const;
};


// ---------------- ItemSet -------------------
// a set of dotted productions, and the transitions between
// item sets, as in LR(0) set-of-items construction
class ItemSet {
public:     // intended to be read-only public
  // kernel items: the items that define the set; except for
  // the special case of the initial item in the initial state,
  // the kernel items are distinguished by having the dot *not*
  // at the left edge
  ObjList<LRItem> kernelItems;

  // nonkernel items: those derived as the closure of the kernel
  // items by expanding symbols to the right of dots; here I am
  // making the choice to materialize them, rather than derive
  // them on the spot as needed (and may change this decision)
  ObjList<LRItem> nonkernelItems;

private:    // data
  // transition function (where we go on shifts); NULL means no transition
  //   Map : (Terminal id or Nonterminal id)  -> ItemSet*
  ItemSet **termTransition;                  // (owner ptr to array of serf ptrs)
  ItemSet **nontermTransition;               // (owner ptr to array of serf ptrs)

  // bounds for above
  int terms;
  int nonterms;

  // profiler reports I'm spending significant time rifling through
  // the items looking for those that have the dot at the end; so this
  // array will point to all such items
  LRItem const **dotsAtEnd;                  // (owner ptr to array of serf ptrs)
  int numDotsAtEnd;                          // number of elements in 'dotsAtEnd'

  // profiler also reports I'm still spending time comparing item sets; this
  // stores a CRC of the numerically sorted kernel item pointer addresses,
  // concatenated into a buffer of sufficient size
  unsigned long kernelItemsCRC;

  // need to store this, because I can't compute it once I throw
  // away the items
  Symbol const *stateSymbol;

public:     // data
  // numerical state id, should be unique among item sets
  // in a particular grammar's sets
  StateId id;

  // it's useful to have a BFS tree superimposed on the transition
  // graph; for example, it makes it easy to generate sample inputs
  // for each state.  so we store the parent pointer; we can derive
  // child pointers by looking at all outgoing transitions, and
  // filtering for those whose targets' parent pointers equal 'this'.
  // the start state's parent is NULL, since it is the root of the
  // BFS tree
  ItemSet *BFSparent;                        // (serf)

private:    // funcs
  int bcheckTerm(int index) const;
  int bcheckNonterm(int index) const;
  ItemSet *&refTransition(Symbol const *sym);

  void allocateTransitionFunction();
  Symbol const *computeStateSymbolC() const;

  void deleteNonReductions(ObjList<LRItem> &list);

public:     // funcs
  ItemSet(StateId id, int numTerms, int numNonterms);
  ~ItemSet();

  ItemSet(Flatten&);
  void xfer(Flatten &flat);
  void xferSerfs(Flatten &flat, GrammarAnalysis &g);

  // ---- item queries ----
  // the set of items names a symbol as the symbol used
  // to reach this state -- namely, the symbol that appears
  // to the left of a dot.  this fn retrieves that symbol
  // (if all items have dots at left edge, returns NULL; this
  // would be true only for the initial state)
  Symbol const *getStateSymbolC() const { return stateSymbol; }

  // equality is defined as having the same items (basic set equality)
  bool operator== (ItemSet const &obj) const;

  // sometimes it's convenient to have all items mixed together
  // (CONSTNESS: allows modification of items...)
  void getAllItems(SObjList<LRItem> &dest, bool nonkernel=true) const;

  // used for sorting by id
  static int diffById(ItemSet const *left, ItemSet const *right, void*);

  // ---- transition queries ----
  // query transition fn for an arbitrary symbol; returns
  // NULL if no transition is defined
  ItemSet const *transitionC(Symbol const *sym) const;
  ItemSet *transition(Symbol const *sym)
    { return const_cast<ItemSet*>(transitionC(sym)); }

  // alternate interface; also might return NULL
  ItemSet const *getTermTransition(int termId) const
    { return termTransition[bcheckTerm(termId)]; }
  ItemSet const *getNontermTransition(int nontermId) const
    { return nontermTransition[bcheckNonterm(nontermId)]; }

  // get the list of productions that are ready to reduce, given
  // that the next input symbol is 'lookahead' (i.e. in the follow
  // of a production's LHS); parsing=true means we are actually
  // parsing input, so certain tracing output is appropriate;
  // 'reductions' is a list of const Productions
  void getPossibleReductions(ProductionList &reductions,
                             Terminal const *lookahead,
                             bool parsing) const;


  // assuming this itemset has at least one reduction ready (an assertion
  // checks this), retrieve the first one
  Production const *getFirstReduction() const;

  // ---- item mutations ----
  // add a kernel item; used while constructing the state
  void addKernelItem(LRItem * /*owner*/ item);

  // after adding all kernel items, call this
  void sortKernelItems();

  // add a nonkernel item; used while computing closure; this
  // item must not already be in the item set
  void addNonkernelItem(LRItem * /*owner*/ item);

  // computes things derived from the item set lists:
  // dotsAtEnd, numDotsAtEnd, kernelItemsCRC, stateSymbol;
  // do this after adding things to the items lists
  void changedItems();

  // a part of 'changedItems', this is used in a specialized way
  // during LR item set construction; it leaves 'this' in a somewhat
  // half-baked state (if changedItems is not also called), so some
  // care needs to be taken when using this directly
  void computeKernelCRC(GrowArray<DottedProduction const*> &array);

  // remove the reduce using 'prod' on lookahead 'sym;
  // calls 'changedItems' internally
  void removeReduce(Production const *prod, Terminal const *sym);

  // throw away information not needed during parsing
  void throwAwayItems();

  // 'dest' has already been established to have the same kernel
  // items as 'this' -- so merge all the kernel lookahead items
  // of 'this' into 'dest'; return 'true' if any changes were made
  // to 'dest'
  bool mergeLookaheadsInto(ItemSet &dest) const;

  // true if this itemset has an item "A -> alpha * t beta", i.e.
  // one that would extend 'A' by shifting 't'
  bool hasExtendingShift(Nonterminal const *A, Terminal const *t) const;

  // ---- transition mutations ----
  // set transition on 'sym' to be 'dest'
  void setTransition(Symbol const *sym, ItemSet *dest);

  // remove the the shift on 'sym'
  void removeShift(Terminal const *sym);

  // ------ hashtable stuff --------
  static ItemSet const *dataToKey(ItemSet *data);
  static unsigned hash(ItemSet const *key);
  static bool equalKey(ItemSet const *key1, ItemSet const *key2);

  // ---- debugging ----
  void writeGraph(ostream &os, GrammarAnalysis const &g) const;
  void print(ostream &os, GrammarAnalysis const &g, bool nonkernel=true) const;
};


// ---------------------- GrammarAnalysis -------------------
class GrammarAnalysis : public Grammar {
protected:  // data
  // if entry i,j is true, then nonterminal i can derive nonterminal j
  // (this is a graph, represented (for now) as an adjacency matrix)
  enum { emptyStringIndex = 0 };
  Bit2d *derivable;                     // (owner)

  // index the symbols on their integer ids
  Nonterminal **indexedNonterms;        // (owner -> serfs) ntIndex -> Nonterminal
  Terminal **indexedTerms;              // (owner -> serfs) termIndex -> Terminal
  // numNonterms==Grammar::numNonterminals(), numTerms==Grammar::numTerminals()
  int numNonterms;                      // length of 'indexedNonterms' array
  int numTerms;                         //   "     "         terms       "

  // during itemSetClosure, profiling reports we spend a lot of time
  // walking the list of productions looking for those that have a given
  // symbol on the LHS; so let's index produtions by LHS symbol index;
  // this array has 'numNonterms' elements, mapping each nonterminal to
  // the list of productions with that nonterminal on the LHS
  SObjList<Production> *productionsByLHS;    // (owner ptr to array)

  // map of production x dotPosition -> DottedProduction;
  // each element of the 'dottedProds' array is a pointer to an
  // array of DottedProduction objects
  DottedProduction **dottedProds;       // (owner ptr to array of owners)
  
  // index of productions by id
  Production **indexedProds;            // (owner -> serfs) prodIndex -> Production
  int numProds;                         // length of 'dottedProds'

  // only true after initializeAuxData has been called
  bool initialized;

  // used to assign itemset ids while the item sets are being
  // initially constructed; later, they get renumbered into a
  // canonical order
  int nextItemSetId;

  // the LR parsing tables
  ObjList<ItemSet> itemSets;
  
  // distinguished start state; NOTE: much of the grammar analysis
  // code currently assumes (and checks) that state 0 is the start
  // state, so if you want to do something different, that code might
  // need to be changed
  ItemSet *startState;                  // (serf)

public:     // data
  // true if any nonterminal can derive itself (with no extra symbols
  // surrounding it) in 1 or more steps
  bool cyclic;

  // symbol of interest; various diagnostics are printed when
  // certain things happen with it (e.g. the first application
  // is to print whenever something is added to this sym's
  // follow)
  Symbol const *symOfInterest;

  // incremented each time we encounter an error that we can recover from
  int errors;

  // parse tables
  ParseTables *tables;                  // (owner)

private:    // funcs
  // ---- analyis init ----
  // call this after grammar is completely built
  void initializeAuxData();
  void computeIndexedNonterms();
  void computeIndexedTerms();
  void computeProductionsByLHS();
  void computeReachable();
  void computeReachableDFS(Nonterminal *nt);
  void resetFirstFollow();
  void computeDProdFirsts();
  void computeSupersets();

  // ---- dotted productions ----
  void createDottedProductions();
  void deleteDottedProductions();
  DottedProduction const *getDProd(Production const *prod, int posn) const;
  DottedProduction *getDProd_nc(Production const *prod, int posn)
    { return const_cast<DottedProduction*>(getDProd(prod, posn)); }

  // given a dprod, yield the one obtained by moving the dot one
  // place to the right
  DottedProduction const *nextDProd(DottedProduction const *dp) const
    #ifdef NDEBUG
      { return dp+1; }      // take advantage of physical co-location
    #endif
      ;                     // debug version checks bounds

  // ---- derivability ----
  // iteratively compute every pair A,B such that A can derive B
  void computeWhatCanDeriveWhat();
  void initDerivableRelation();

  // add a derivability relation; returns true if this makes a change
  bool addDerivable(Nonterminal const *left, Nonterminal const *right);
  bool addDerivable(int leftNtIndex, int rightNtIndex);

  // private derivability interface
  bool canDerive(int leftNtIndex, int rightNtIndex) const;
  bool sequenceCanDeriveEmpty(RHSEltList const &list) const;
  bool iterSeqCanDeriveEmpty(RHSEltListIter iter) const;

  // ---- First ----
  void computeFirst();
  //bool addFirst(Nonterminal *NT, Terminal *term);
  void firstOfSequence(TerminalSet &destList, RHSEltList const &sequence);
  void firstOfIterSeq(TerminalSet &destList, RHSEltListIter sym);

  // ---- Follow ----
  void computeFollow();
  //bool addFollow(Nonterminal *NT, Terminal *term);

  // ---- LR item sets ----
  ItemSet *makeItemSet();
  void disposeItemSet(ItemSet *is);
  void moveDotNoClosure(ItemSet const *source, Symbol const *symbol,
                        ItemSet *dest, ObjList<LRItem> &unusedTail,
                        GrowArray<DottedProduction const*> &array);
  ItemSet *findItemSetInList(ObjList<ItemSet> &list,
                             ItemSet const *itemSet);
  static bool itemSetsEqual(ItemSet const *is1, ItemSet const *is2);

  void constructLRItemSets();
  void lrParse(char const *input);

  void handleShiftReduceConflict(
    bool &keepShift, bool &keepReduce, bool &dontWarn,
    ItemSet const *state, Production const *prod, Terminal const *sym);

  void resolveConflicts(
    ItemSet const *state,        // parse state in which the actions are possible
    Terminal const *sym,         // lookahead symbol for these actions
    ItemSet const *&shiftDest,   // (inout) if non-NULL, the state to which we can shift
    ProductionList &reductions,  // (inout) list of possible reductions
    bool allowAmbig,             // if false, always return at most 1 action
    bool &printedConflictHeader, // (inout) true once we've printed the state header
    int &sr, int &rr);           // (inout) counts of S/R and R/R conflicts, resp.
  void computeParseTables(bool allowAmbig);

  int subsetDirectiveResolution(
    ItemSet const *state,        // parse state in which the actions are possible
    Terminal const *sym,         // lookahead symbol for these actions
    ProductionList &reductions); // list to try to cut down
  
  void renumberStates();
  static int renumberStatesDiff
    (ItemSet const *left, ItemSet const *right, void *vgramanl);
  static int arbitraryProductionOrder
    (Production const *left, Production const *right, void*);
  static int arbitraryRHSEltOrder
    (Production::RHSElt const *left, Production::RHSElt const *right, void*);

  void computeBFSTree();

  // misc
  void computePredictiveParsingTable();
    // non-const because have to add productions to lists

  void topologicalSort(NtIndex *order,  int &nextOrdinal,
                       NtIndex current, BitArray &seen);
  
  // the inverse of transition: map a target state to the symbol that
  // would transition to that state (from the given source state)
  Symbol const *inverseTransitionC(ItemSet const *source,
                                   ItemSet const *target) const;

  // sample input helpers
  void leftContext(SymbolList &output, ItemSet const *state) const;
  bool rewriteAsTerminals(TerminalList &output, SymbolList const &input) const;
  bool rewriteAsTerminalsHelper(TerminalList &output, SymbolList const &input,
                                ProductionList &reductionStack) const;
  bool rewriteSingleNTAsTerminals(TerminalList &output, Nonterminal const *nonterminal,
                                  ProductionList &reductionStack) const;

  // let's try this .. it needs to access 'itemSets'
  friend void ItemSet::xferSerfs(Flatten &flat, GrammarAnalysis &g);

  void singleItemClosure(OwnerKHashTable<LRItem, DottedProduction> &finished,
                         ArrayStack<LRItem*> &worklist,
                         //OwnerKHashArray<LRItem, DottedProduction> &workhash,
                         LRItem const *item, TerminalSet &scratchSet);

public:     // funcs
  GrammarAnalysis();
  ~GrammarAnalysis();

  // access symbols by index
  Terminal const *getTerminal(int index) const;
  Nonterminal const *getNonterminal(int index) const;
  Production const *getProduction(int index) const;

  ItemSet const *getItemSet(int index) const;
  int numItemSets() const { return nextItemSetId; }

  // faster access to counts
  int numTerminals() const { return numTerms; }
  int numNonterminals() const { return numNonterms; }

  // binary read/write
  void xfer(Flatten &flat);

  // essentially, my 'main()' while experimenting
  void exampleGrammar();

  // overrides base class to add a little bit of the
  // annotated info
  void printProductions(ostream &os, bool printCode=true) const;

  // print lots of stuff
  void printProductionsAndItems(ostream &os, bool printCode=true) const;

  // when grammar is built, this runs all analyses and stores
  // the results in this object's data fields; write the LR item
  // sets to the given file (or don't, if NULL)
  void runAnalyses(char const *setsFname);

  // print the item sets to a stream (optionally include nonkernel items)
  void printItemSets(ostream &os, bool nonkernel) const;

  // given a grammar, replace all of its actions with actions that
  // will build a straightforward parse tree using the facilities
  // of ptreenode.h; the rules will need the user to already have
  // done some necessary work in the verbatim preamble, such as
  // #including ptreenode.h
  void addTreebuildingActions();

  // ---- grammar queries ----
  bool canDerive(Nonterminal const *lhs, Nonterminal const *rhs) const;
  bool canDeriveEmpty(Nonterminal const *lhs) const;

  bool firstIncludes(Nonterminal const *NT, Terminal const *term) const;
  bool followIncludes(Nonterminal const *NT, Terminal const *term) const;

  // ---- sample inputs and contexts ----
  sm_string sampleInput(ItemSet const *state) const;
  sm_string leftContextString(ItemSet const *state) const;
  
  // ---- moved out of private ----
  void itemSetClosure(ItemSet &itemSet);
  DottedProduction const *getDProdIndex(int prodIndex, int posn) const;
};


// in gramexpl.cc: interactive grammar experimentation system
void grammarExplorer(GrammarAnalysis &g);


#endif // __GRAMANL_H
@h=tangler('elk/elk_gramast.ast.gen.h')
@select(h)
// gramast.ast.gen.h
// *** DO NOT EDIT ***
// generated automatically by astgen, from gramast.ast

#ifndef GRAMAST_AST_GEN_H
#define GRAMAST_AST_GEN_H

#include "ast_asthelp.h"

// fwd decls
class GrammarAST;
class TopForm;
class TF_context;
class TF_verbatim;
class TF_option;
class TF_terminals;
class TF_nonterm;
class TermDecl;
class TermType;
class PrecSpec;
class SpecFunc;
class ProdDecl;
class RHSElt;
class RH_name;
class RH_sm_string;
class RH_prec;


// *** DO NOT EDIT ***

#include "ast_locstr.h"
#include "elk_asockind.h"

// *** DO NOT EDIT ***
class GrammarAST {
public:      // data
  ASTList <TopForm > forms;

public:      // funcs
  GrammarAST(ASTList <TopForm > *_forms) : forms(_forms) {
     { terms=NULL; firstNT=NULL; };
  }
  ~GrammarAST();

  char const *kindName() const { return "GrammarAST"; }

  GrammarAST *clone() const;

  void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  public:  TF_terminals *terms;
  public:  TF_nonterm *firstNT;
};



// *** DO NOT EDIT ***
class TopForm {
public:      // data

public:      // funcs
  TopForm() {
  }
  virtual ~TopForm();

  enum Kind { TF_CONTEXT, TF_VERBATIM, TF_OPTION, TF_TERMINALS, TF_NONTERM, NUM_KINDS };
  virtual Kind kind() const = 0;

  static char const * const kindNames[NUM_KINDS];
  char const *kindName() const { return kindNames[kind()]; }

  DECL_AST_DOWNCASTS(TF_context, TF_CONTEXT)
  DECL_AST_DOWNCASTS(TF_verbatim, TF_VERBATIM)
  DECL_AST_DOWNCASTS(TF_option, TF_OPTION)
  DECL_AST_DOWNCASTS(TF_terminals, TF_TERMINALS)
  DECL_AST_DOWNCASTS(TF_nonterm, TF_NONTERM)

  virtual TopForm *clone() const=0;

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

};

class TF_context : public TopForm {
public:      // data
  LocString body;

public:      // funcs
  TF_context(LocString *_body) : TopForm(), body(_body) {
  }
  virtual ~TF_context();

  virtual Kind kind() const { return TF_CONTEXT; }
  enum { TYPE_TAG = TF_CONTEXT };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual TF_context *clone() const;

};

class TF_verbatim : public TopForm {
public:      // data
  bool isImpl;
  LocString code;

public:      // funcs
  TF_verbatim(bool _isImpl, LocString *_code) : TopForm(), isImpl(_isImpl), code(_code) {
  }
  virtual ~TF_verbatim();

  virtual Kind kind() const { return TF_VERBATIM; }
  enum { TYPE_TAG = TF_VERBATIM };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual TF_verbatim *clone() const;

};

class TF_option : public TopForm {
public:      // data
  LocString name;
  int value;

public:      // funcs
  TF_option(LocString *_name, int _value) : TopForm(), name(_name), value(_value) {
  }
  virtual ~TF_option();

  virtual Kind kind() const { return TF_OPTION; }
  enum { TYPE_TAG = TF_OPTION };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual TF_option *clone() const;

};

class TF_terminals : public TopForm {
public:      // data
  ASTList <TermDecl > decls;
  ASTList <TermType > types;
  ASTList <PrecSpec > prec;

public:      // funcs
  TF_terminals(ASTList <TermDecl > *_decls, ASTList <TermType > *_types, ASTList <PrecSpec > *_prec) : TopForm(), decls(_decls), types(_types), prec(_prec) {
  }
  virtual ~TF_terminals();

  virtual Kind kind() const { return TF_TERMINALS; }
  enum { TYPE_TAG = TF_TERMINALS };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual TF_terminals *clone() const;

};

class TF_nonterm : public TopForm {
public:      // data
  LocString name;
  LocString type;
  ASTList <SpecFunc > funcs;
  ASTList <ProdDecl > productions;
  ASTList <LocString > subsets;

public:      // funcs
  TF_nonterm(LocString *_name, LocString *_type, ASTList <SpecFunc > *_funcs, ASTList <ProdDecl > *_productions, ASTList <LocString > *_subsets) : TopForm(), name(_name), type(_type), funcs(_funcs), productions(_productions), subsets(_subsets) {
  }
  virtual ~TF_nonterm();

  virtual Kind kind() const { return TF_NONTERM; }
  enum { TYPE_TAG = TF_NONTERM };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual TF_nonterm *clone() const;

};



// *** DO NOT EDIT ***
class TermDecl {
public:      // data
  int code;
  LocString name;
  LocString alias;

public:      // funcs
  TermDecl(int _code, LocString *_name, LocString *_alias) : code(_code), name(_name), alias(_alias) {
  }
  ~TermDecl();

  char const *kindName() const { return "TermDecl"; }

  TermDecl *clone() const;

  void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

};



// *** DO NOT EDIT ***
class TermType {
public:      // data
  LocString name;
  LocString type;
  ASTList <SpecFunc > funcs;

public:      // funcs
  TermType(LocString *_name, LocString *_type, ASTList <SpecFunc > *_funcs) : name(_name), type(_type), funcs(_funcs) {
  }
  ~TermType();

  char const *kindName() const { return "TermType"; }

  TermType *clone() const;

  void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

};



// *** DO NOT EDIT ***
class PrecSpec {
public:      // data
  AssocKind kind;
  int prec;
  ASTList <LocString > tokens;

public:      // funcs
  PrecSpec(AssocKind _kind, int _prec, ASTList <LocString > *_tokens) : kind(_kind), prec(_prec), tokens(_tokens) {
  }
  ~PrecSpec();

  char const *kindName() const { return "PrecSpec"; }

  PrecSpec *clone() const;

  void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

};



// *** DO NOT EDIT ***
class SpecFunc {
public:      // data
  LocString name;
  ASTList <LocString > formals;
  LocString code;

public:      // funcs
  SpecFunc(LocString *_name, ASTList <LocString > *_formals, LocString *_code) : name(_name), formals(_formals), code(_code) {
  }
  ~SpecFunc();

  char const *kindName() const { return "SpecFunc"; }

  SpecFunc *clone() const;

  void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  public:  LocString nthFormal(int i) const
    { return *( formals.nthC(i) ); };
};



// *** DO NOT EDIT ***
class ProdDecl {
public:      // data
  ASTList <RHSElt > rhs;
  LocString actionCode;

public:      // funcs
  ProdDecl(ASTList <RHSElt > *_rhs, LocString *_actionCode) : rhs(_rhs), actionCode(_actionCode) {
  }
  ~ProdDecl();

  char const *kindName() const { return "ProdDecl"; }

  ProdDecl *clone() const;

  void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

};



// *** DO NOT EDIT ***
class RHSElt {
public:      // data

public:      // funcs
  RHSElt() {
  }
  virtual ~RHSElt();

  enum Kind { RH_NAME, RH_STRING, RH_PREC, NUM_KINDS };
  virtual Kind kind() const = 0;

  static char const * const kindNames[NUM_KINDS];
  char const *kindName() const { return kindNames[kind()]; }

  DECL_AST_DOWNCASTS(RH_name, RH_NAME)
  DECL_AST_DOWNCASTS(RH_sm_string, RH_STRING)
  DECL_AST_DOWNCASTS(RH_prec, RH_PREC)

  virtual RHSElt *clone() const=0;

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

};

class RH_name : public RHSElt {
public:      // data
  LocString tag;
  LocString name;

public:      // funcs
  RH_name(LocString *_tag, LocString *_name) : RHSElt(), tag(_tag), name(_name) {
  }
  virtual ~RH_name();

  virtual Kind kind() const { return RH_NAME; }
  enum { TYPE_TAG = RH_NAME };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual RH_name *clone() const;

};

class RH_sm_string : public RHSElt {
public:      // data
  LocString tag;
  LocString str;

public:      // funcs
  RH_sm_string(LocString *_tag, LocString *_str) : RHSElt(), tag(_tag), str(_str) {
  }
  virtual ~RH_sm_string();

  virtual Kind kind() const { return RH_STRING; }
  enum { TYPE_TAG = RH_STRING };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual RH_sm_string *clone() const;

};

class RH_prec : public RHSElt {
public:      // data
  LocString tokName;

public:      // funcs
  RH_prec(LocString *_tokName) : RHSElt(), tokName(_tokName) {
  }
  virtual ~RH_prec();

  virtual Kind kind() const { return RH_PREC; }
  enum { TYPE_TAG = RH_PREC };

  virtual void debugPrint(ostream &os, int indent, char const *subtreeName = "tree") const;

  virtual RH_prec *clone() const;

};



#endif // GRAMAST_AST_GEN_H
@h=tangler('elk/elk_grammar.cpp')
@select(h)
// grammar.cc            see license.txt for copyright and terms of use
// code for grammar.h

#include "elk_grammar.h"   // this module
#include "sm_syserr.h"    // xsyserror
#include "sm_strtokp.h"   // StrtokParse
#include "sm_trace.h"     // trace
#include "sm_exc.h"       // xBase
#include "sm_strutil.h"   // quoted, parseQuotedString
#include "sm_flatten.h"   // Flatten
#include "elk_flatutil.h"  // various xfer helpers

#include <stdarg.h>    // variable-args stuff
#include <stdio.h>     // FILE, etc.
#include <ctype.h>     // isupper
#include <stdlib.h>    // atoi


// print a variable value
#define PVAL(var) os << " " << #var "=" << var;


StringTable grammarStringTable;


// ---------------------- Symbol --------------------
Symbol::Symbol(LocString const &n, bool t, bool e)
  : name(n),
    isTerm(t),
    isEmptyString(e),
    type(NULL),
    dupParam(NULL),
    dupCode(),
    delParam(NULL),
    delCode(),
    reachable(false)
{}

Symbol::~Symbol()
{}


Symbol::Symbol(Flatten &flat)
  : name(flat),
    isTerm(false),
    isEmptyString(false),
    type(NULL),
    dupParam(NULL),
    delParam(NULL)
{}

void Symbol::xfer(Flatten &flat)
{
  // have to break constness to unflatten
  const_cast<LocString&>(name).xfer(flat);
  flat.xferBool(const_cast<bool&>(isTerm));
  flat.xferBool(const_cast<bool&>(isEmptyString));

  flattenStrTable->xfer(flat, type);

  flattenStrTable->xfer(flat, dupParam);
  dupCode.xfer(flat);

  flattenStrTable->xfer(flat, delParam);
  delCode.xfer(flat);
  
  flat.xferBool(reachable);
}


int Symbol::getTermOrNontermIndex() const
{
  if (isTerminal()) {
    return asTerminalC().termIndex;
  }
  else {
    return asNonterminalC().ntIndex;
  }
}


void Symbol::print(ostream &os) const
{
  os << name;
  if (type) {
    os << "[" << type << "]";
  }
  os << ":";
  PVAL(isTerm);
}


void Symbol::printDDM(ostream &os) const
{
  // don't print anything if no handlers
  if (!anyDDM()) return;

  // print with roughly the same syntax as input
  os << "  " << (isTerminal()? "token" : "nonterm");
  if (type) {
    os << "[" << type << "]";
  }
  os << " " << name << " {\n";

  internalPrintDDM(os);

  os << "  }\n";
}


void Symbol::internalPrintDDM(ostream &os) const
{
  if (dupCode.isNonNull()) {
    os << "    dup(" << dupParam << ") [" << dupCode << "]\n";
  }

  if (delCode.isNonNull()) {
    os << "    del(" << (delParam? delParam : "") << ") [" << delCode << "]\n";
  }
}


bool Symbol::anyDDM() const
{
  return dupCode.isNonNull() ||
         delCode.isNonNull();
}


Terminal const &Symbol::asTerminalC() const
{
  xassert(isTerminal());
  return (Terminal const &)(*this);
}

Nonterminal const &Symbol::asNonterminalC() const
{
  xassert(isNonterminal());
  return (Nonterminal const &)(*this);
}


Terminal const *Symbol::ifTerminalC() const
{
  return isTerminal()? (Terminal const *)this : NULL;
}

Nonterminal const *Symbol::ifNonterminalC() const
{
  return isNonterminal()? (Nonterminal const *)this : NULL;
}



// -------------------- Terminal ------------------------
Terminal::Terminal(Flatten &flat)
  : Symbol(flat),
    alias(flat),
    classifyParam(NULL)
{}

void Terminal::xfer(Flatten &flat)
{
  Symbol::xfer(flat);

  alias.xfer(flat);

  flat.xferInt(precedence);
  flat.xferInt((int&)associativity);

  flat.xferInt(termIndex);

  flattenStrTable->xfer(flat, classifyParam);
  classifyCode.xfer(flat);
}


void Terminal::print(ostream &os) const
{
  os << "[" << termIndex << "]";
  if (precedence) {
    os << "(" << ::toString(associativity) << " " << precedence << ")";
  }
  os << " ";
  Symbol::print(os);
}


void Terminal::internalPrintDDM(ostream &os) const
{
  Symbol::internalPrintDDM(os);

  if (classifyCode.isNonNull()) {
    os << "    classify(" << classifyParam << ") [" << classifyCode << "]\n";
  }
}


bool Terminal::anyDDM() const
{
  return Symbol::anyDDM() ||
         classifyCode.isNonNull();
}


sm_string Terminal::toString(bool quoteAliases) const
{
  if (alias.length() > 0) {
    if (quoteAliases) {
      return sm_stringc << "\"" << ::toString(alias) << "\"";
    }
    else {
      return ::toString(alias);
    }
  }
  else {
    return ::toString(name);
  }
}


// ----------------- Nonterminal ------------------------
Nonterminal::Nonterminal(LocString const &name, bool isEmpty)
  : Symbol(name, false /*terminal*/, isEmpty),
    mergeParam1(NULL),
    mergeParam2(NULL),
    mergeCode(),
    keepParam(NULL),
    keepCode(),
    maximal(false),
    subsets(),
    ntIndex(-1),
    cyclic(false),
    first(0),
    follow(0),
    superset(NULL)
{}

Nonterminal::~Nonterminal()
{}


Nonterminal::Nonterminal(Flatten &flat)
  : Symbol(flat),
    mergeParam1(NULL),
    mergeParam2(NULL),
    keepParam(NULL),
    first(flat),
    follow(flat),
    superset(NULL)
{}

void Nonterminal::xfer(Flatten &flat)
{
  Symbol::xfer(flat);

  flattenStrTable->xfer(flat, mergeParam1);
  flattenStrTable->xfer(flat, mergeParam2);
  mergeCode.xfer(flat);

  flattenStrTable->xfer(flat, keepParam);
  keepCode.xfer(flat);
}

void Nonterminal::xferSerfs(Flatten &flat, Grammar &g)
{
  // annotation
  flat.xferInt(ntIndex);
  flat.xferBool(cyclic);
  first.xfer(flat);
  follow.xfer(flat);
}


void Nonterminal::print(ostream &os, Grammar const *grammar) const
{
  os << "[" << ntIndex << "] ";
  Symbol::print(os);

  // cyclic?
  if (cyclic) {
    os << " (cyclic!)";
  }

  if (grammar) {
    // first
    os << " first={";
    first.print(os, *grammar);
    os << "}";

    // follow
    os << " follow=";
    follow.print(os, *grammar);
    os << "}";
  }
}


void Nonterminal::internalPrintDDM(ostream &os) const
{
  Symbol::internalPrintDDM(os);
  
  if (mergeCode.isNonNull()) {
    os << "    merge(" << mergeParam1 << ", " << mergeParam2
       << ") [" << mergeCode << "]\n";
  }

  if (keepCode.isNonNull()) {
    os << "    keep(" << keepParam << ") [" << keepCode << "]\n";
  }
}


bool Nonterminal::anyDDM() const
{
  return Symbol::anyDDM() ||
         mergeCode.isNonNull() ||
         keepCode.isNonNull();
}


// -------------------- TerminalSet ------------------------
STATICDEF Terminal const *TerminalSet::suppressExcept = NULL;

TerminalSet::TerminalSet(int numTerms)
{
  init(numTerms);
}

TerminalSet::TerminalSet(TerminalSet const &obj)
{
  init(obj.bitmapLen * 8);    // close enough; same # of bytes at least
  copy(obj);
}

void TerminalSet::init(int numTerms)
{
  if (numTerms != 0) {
    // allocate enough space for one bit per terminal; I assume
    // 8 bits per byte
    bitmapLen = (numTerms + 7) / 8;
    bitmap = new unsigned char[bitmapLen];

    // initially the set will be empty
    memset(bitmap, 0, bitmapLen);
  }
  else {
    // intended for situations where reset() will be called later
    // to allocate some space
    bitmapLen = 0;
    bitmap = NULL;
  }
}


TerminalSet::~TerminalSet()
{
  if (bitmap) {
    delete[] bitmap;
  }
}


TerminalSet::TerminalSet(Flatten&)
  : bitmap(NULL)
{}

void TerminalSet::xfer(Flatten &flat)
{
  flat.xferInt(bitmapLen);

  if (bitmapLen > 0) {
    if (flat.reading()) {
      bitmap = new unsigned char[bitmapLen];
    }
    flat.xferSimple(bitmap, bitmapLen);
  }
}


void TerminalSet::reset(int numTerms)
{
  if (bitmap) {
    delete[] bitmap;
  }
  init(numTerms);
}


unsigned char *TerminalSet::getByte(int id) const
{
  int offset = (unsigned)id / 8;
  xassert(offset < bitmapLen);

  return bitmap + offset;
}


bool TerminalSet::contains(int id) const
{
  unsigned char *p = getByte(id);
  return (*p >> getBit(id)) & 1 == 1;
}


bool TerminalSet::isEqual(TerminalSet const &obj) const
{
  xassert(obj.bitmapLen == bitmapLen);
  return 0==memcmp(bitmap, obj.bitmap, bitmapLen);
}


void TerminalSet::add(int id)
{
  unsigned char *p = getByte(id);
  *p |= (unsigned char)(1 << getBit(id));
}


void TerminalSet::remove(int id)
{                             
  unsigned char *p = getByte(id);
  *p &= (unsigned char)(~(1 << getBit(id)));
}


void TerminalSet::clear()
{
  memset(bitmap, 0, bitmapLen);
}


void TerminalSet::copy(TerminalSet const &obj)
{
  xassert(obj.bitmapLen == bitmapLen);
  memcpy(bitmap, obj.bitmap, bitmapLen);
}


bool TerminalSet::merge(TerminalSet const &obj)
{
  bool changed = false;
  for (int i=0; i<bitmapLen; i++) {
    unsigned before = bitmap[i];
    unsigned after = before | obj.bitmap[i];
    if (after != before) {
      changed = true;
      bitmap[i] = after;
    }
  }
  return changed;
}


void TerminalSet::print(ostream &os, Grammar const &g) const
{
  int ct=0;
  FOREACH_TERMINAL(g.terminals, iter) {
    Terminal const *t = iter.data();
    if (!contains(t->termIndex)) continue;

    if (suppressExcept &&                  // suppressing..
        suppressExcept != t) continue;     // and this isn't the exception

    if (ct++ == 0) {
      // by waiting until now to print this, if the set has no symbols
      // (e.g. we're in SLR(1) mode), then the comma won't be printed
      // either
      os << ", ";
    }
    else {
      os << "/";
    }

    os << t->toString();
  }
}


// -------------------- Production::RHSElt -------------------------
Production::RHSElt::~RHSElt()
{}


Production::RHSElt::RHSElt(Flatten &flat)
  : sym(NULL),
    tag(flat)
{}

void Production::RHSElt::xfer(Flatten &flat)
{
  tag.xfer(flat);
}

void Production::RHSElt::xferSerfs(Flatten &flat, Grammar &g)
{
  xferSerfPtr(flat, sym);
}



// -------------------- Production -------------------------
Production::Production(Nonterminal *L, char const *Ltag)
  : left(L),
    right(),
    precedence(0),
    rhsLen(-1),
    prodIndex(-1),
    firstSet(0)       // don't allocate bitmap yet
{}

Production::~Production()
{}


Production::Production(Flatten &flat)
  : left(NULL),
    action(flat),
    firstSet(flat)
{}

void Production::xfer(Flatten &flat)
{
  xferObjList(flat, right);
  action.xfer(flat);
  flat.xferInt(precedence);

  flat.xferInt(rhsLen);
  flat.xferInt(prodIndex);
  firstSet.xfer(flat);
}

void Production::xferSerfs(Flatten &flat, Grammar &g)
{
  // must break constness in xfer

  xferSerfPtrToList(flat, const_cast<Nonterminal*&>(left),
                          g.nonterminals);

  // xfer right's 'sym' pointers
  MUTATE_EACH_OBJLIST(RHSElt, right, iter) {
    iter.data()->xferSerfs(flat, g);
  }

  // compute derived data
  if (flat.reading()) {
    computeDerived();
  }
}


#if 0   // optimized away, using 'rhsLen' instead
int Production::rhsLength() const
{
  if (!right.isEmpty()) {
    // I used to have code here which handled this situation by returning 0;
    // since it should now never happen, I'll check that here instead
    xassert(!right.nthC(0)->sym->isEmptyString);
  }

  return right.count();
}
#endif // 0


#if 0    // useful for verifying 'finish' is called before rhsLen
int Production::rhsLength() const
{
  xassert(rhsLen != -1);     // otherwise 'finish' wasn't called
  return rhsLen;
}
#endif // 0


int Production::numRHSNonterminals() const
{
  int ct = 0;
  FOREACH_OBJLIST(RHSElt, right, iter) {
    if (iter.data()->sym->isNonterminal()) {
      ct++;
    }
  }
  return ct;
}


bool Production::rhsHasSymbol(Symbol const *sym) const
{
  FOREACH_OBJLIST(RHSElt, right, iter) {
    if (iter.data()->sym == sym) {
      return true;
    }
  }
  return false;
}


void Production::getRHSSymbols(SymbolList &output) const
{
  FOREACH_OBJLIST(RHSElt, right, iter) {
    output.append(iter.data()->sym);
  }
}


void Production::append(Symbol *sym, LocString const &tag)
{
  // my new design decision (6/26/00 14:24) is to disallow the
  // emptyString nonterminal from explicitly appearing in the
  // productions
  xassert(!sym->isEmptyString);

  right.append(new RHSElt(sym, tag));
}


void Production::finished(int numTerms)
{
  computeDerived();
  firstSet.reset(numTerms);
}

void Production::computeDerived()
{
  rhsLen = right.count();
}


// basically strcmp but without the segfaults when s1 or s2
// is null; return true if sm_strings are equal
// update: now that they're StringRef, simple "==" suffices
bool tagCompare(StringRef s1, StringRef s2)
{
  return s1 == s2;
}


int Production::findTag(StringRef tag) const
{
  // walk RHS list looking for a match
  ObjListIter<RHSElt> tagIter(right);
  int index=1;
  for(; !tagIter.isDone(); tagIter.adv(), index++) {
    if (tagCompare(tagIter.data()->tag, tag)) {
      return index;
    }
  }

  // not found
  return -1;
}


// assemble a possibly tagged name for printing
sm_string taggedName(char const *name, char const *tag)
{
  if (tag == NULL || tag[0] == 0) {
    return sm_string(name);
  }
  else {
    return sm_stringb(tag << ":" << name);
  }
}


sm_string Production::symbolTag(int index) const
{
  // no longer have tags for LHS
  xassert(index != 0);

  // find index in RHS list
  index--;
  return sm_string(right.nthC(index)->tag);
}


Symbol const *Production::symbolByIndexC(int index) const
{
  // check LHS
  if (index == 0) {
    return left;
  }

  // find index in RHS list
  index--;
  return right.nthC(index)->sym;
}


#if 0
DottedProduction const *Production::getDProdC(int dotPlace) const
{
  xassert(0 <= dotPlace && dotPlace < numDotPlaces);
  return &dprods[dotPlace];
}    
#endif // 0


void Production::print(ostream &os) const
{
  os << toString();
}


sm_string Production::toString(bool printType, bool printIndex) const
{
  // LHS "->" RHS
  sm_stringBuilder sb;
  if (printIndex) {
    sb << "[" << prodIndex << "] ";
  }

  sb << left->name;
  if (printType && left->type) {
    sb << "[" << left->type << "]";
  }
  sb << " -> " << rhsString();
  
  if (printType && precedence) {
    // take this as licence to print prec too
    sb << " %prec(" << precedence << ")";
  }
  return sb;
}


sm_string Production::rhsString(bool printTags, bool quoteAliases) const
{
  sm_stringBuilder sb;

  if (right.isNotEmpty()) {
    // print the RHS symbols
    int ct=0;
    FOREACH_OBJLIST(RHSElt, right, iter) {
      RHSElt const &elt = *(iter.data());

      if (ct++ > 0) {
        sb << " ";
      }

      sm_string symName;
      if (elt.sym->isNonterminal()) {
        symName = elt.sym->name;
      }
      else {
        // print terminals as aliases if possible
        symName = elt.sym->asTerminalC().toString(quoteAliases);
      }

      if (printTags) {
        // print tag if present
        sb << taggedName(symName, elt.tag);
      }
      else {
        sb << symName;
      }
    }
  }

  else {
    // empty RHS
    sb << "empty";
  }

  return sb;
}


sm_string Production::toStringMore(bool printCode) const
{
  sm_stringBuilder sb;
  sb << toString();

  if (printCode && !action.isNull()) {
    sb << "\t\t[" << action.strref() << "]";
  }

  sb << "\n";

  return sb;
}


// ------------------ Grammar -----------------
Grammar::Grammar()
  : startSymbol(NULL),
    emptyString(LocString(HERE_SOURCELOC, "empty"),
                true /*isEmptyString*/),
    targetLang("C++"),
    useGCDefaults(false),
    defaultMergeAborts(false),
    expectedSR(-1),
    expectedRR(-1),
    expectedUNRNonterms(-1),
    expectedUNRTerms(-1)
{}


Grammar::~Grammar()
{}


void Grammar::xfer(Flatten &flat)
{
  // owners
  flat.checkpoint(0xC7AB4D86);
  xferObjList(flat, nonterminals);
  xferObjList(flat, terminals);
  xferObjList(flat, productions);

  // emptyString is const

  xferObjList(flat, verbatim);

  actionClassName.xfer(flat);
  xferObjList(flat, actionClasses);

  xferObjList(flat, implVerbatim);
                               
  targetLang.xfer(flat);
  flat.xferBool(useGCDefaults);
  flat.xferBool(defaultMergeAborts);

  flat.xferInt(expectedSR);
  flat.xferInt(expectedRR);
  flat.xferInt(expectedUNRNonterms);
  flat.xferInt(expectedUNRTerms);

  // serfs
  flat.checkpoint(0x8580AAD2);

  MUTATE_EACH_OBJLIST(Nonterminal, nonterminals, nt) {
    nt.data()->xferSerfs(flat, *this);
  }
  MUTATE_EACH_OBJLIST(Production, productions, p) {
    p.data()->xferSerfs(flat, *this);
  }

  xferSerfPtrToList(flat, startSymbol, nonterminals);

  flat.checkpoint(0x2874DB95);
}


int Grammar::numTerminals() const
{
  return terminals.count();
}

int Grammar::numNonterminals() const
{                                
  // everywhere, we regard emptyString as a nonterminal
  return nonterminals.count() + 1;
}


void Grammar::printSymbolTypes(ostream &os) const
{
  os << "Grammar terminals with types or precedence:\n";
  FOREACH_OBJLIST(Terminal, terminals, term) {
    Terminal const &t = *(term.data());
    t.printDDM(os);
    if (t.precedence) {
      os << "  " << t.name << " " << ::toString(t.associativity)
         << " %prec " << t.precedence << endl;
    }
  }

  os << "Grammar nonterminals with types:\n";
  FOREACH_OBJLIST(Nonterminal, nonterminals, nt) {
    nt.data()->printDDM(os);
  }
}


void Grammar::printProductions(ostream &os, bool code) const
{
  os << "Grammar productions:\n";
  for (ObjListIter<Production> iter(productions);
       !iter.isDone(); iter.adv()) {
    os << "  " << iter.data()->toStringMore(code);
  }
}


#if 0
void Grammar::addProduction(Nonterminal *lhs, Symbol *firstRhs, ...)
{
  va_list argptr;                   // state for working through args
  Symbol *arg;
  va_start(argptr, firstRhs);       // initialize 'argptr'

  Production *prod = new Production(lhs, NULL /*tag*/);
  prod->append(firstRhs, NULL /*tag*/);
  for(;;) {
    arg = va_arg(argptr, Symbol*);  // get next argument
    if (arg == NULL) {
      break;    // end of list
    }

    prod->append(arg, NULL /*tag*/);
  }

  addProduction(prod);
}
#endif // 0


void Grammar::addProduction(Production *prod)
{
  // I used to add emptyString if there were 0 RHS symbols,
  // but I've now switched to not explicitly saying that

  prod->prodIndex = productions.count();
  productions.append(prod);
  
  // if the start symbol isn't defined yet, we can here
  // implement the convention that the LHS of the first
  // production is the start symbol
  if (startSymbol == NULL) {
    startSymbol = prod->left;
  }
}


// add a token to those we know about
bool Grammar::declareToken(LocString const &symbolName, int code, 
                           LocString const &alias)
{
  // verify that this token hasn't been declared already
  if (findSymbolC(symbolName)) {
    cout << "token " << symbolName << " has already been declared\n";
    return false;
  }

  // create a new terminal class
  Terminal *term = getOrMakeTerminal(symbolName);

  // assign fields specified in %token declaration
  term->termIndex = code;
  term->alias = alias;

  return true;
}


// well-formedness check
void Grammar::checkWellFormed() const
{
  // after removing some things, now there's nothing to check...
}


// syntax for identifying tokens in Bison output
sm_string bisonTokenName(Terminal const *t)
{
  // this worked with older versions of Bison
  //return sm_stringc << "\"" << t->name << "\"";

  // but the newer ones don't like quoted terminal names..
  return sm_string(t->name.str);
}

// print the grammar in a form that Bison likes
void Grammar::printAsBison(ostream &os) const
{
  os << "/* automatically generated grammar */\n\n";

  os << "/* -------- tokens -------- */\n";
  FOREACH_TERMINAL(terminals, term) {
    // I'll surround all my tokens with quotes and see how Bison likes it
    // TODO: the latest bison does *not* like it!
    os << "%token " << bisonTokenName(term.data()) << " "
       << term.data()->termIndex << "\n";
  }
  os << "\n\n";

  os << "/* -------- precedence and associativity ---------*/\n"
        "/* low precedence */\n";
  {
    // first, compute the highest precedence used anywhere in the grammar
    int highMark=0;
    FOREACH_TERMINAL(terminals, iter) {
      highMark = max(iter.data()->precedence, highMark);
    }
            
    // map AssocKind to bison declaration; map stuff bison doesn't
    // have to %nonassoc
    static char const * const kindMap[NUM_ASSOC_KINDS] =
      { "%left", "%right", "%nonassoc", "%nonassoc", "%nonassoc" };

    // now iterate over the precedence levels (level 0 is skipped
    // because it means 'unspecified')
    for (int level=1; level <= highMark; level++) {
      AssocKind kind = NUM_ASSOC_KINDS;   // means we haven't seen any kind yet
      FOREACH_TERMINAL(terminals, iter) {
        Terminal const *t = iter.data();

        if (t->precedence == level) {
          if (kind == NUM_ASSOC_KINDS) {
            // first token at this level
            kind = t->associativity;
            os << kindMap[kind];
          }
          else if (kind != t->associativity) {
            xfailure("different associativities at same precedence?!");
          }

          // print the token itself
          os << " " << bisonTokenName(t);
        }
      }

      // end of the level
      os << "\n";
    }
  }
  os << "/* high precedence */\n"
        "\n\n";

  os << "/* -------- productions ------ */\n"
        "%%\n\n";
  // print every nonterminal's rules
  FOREACH_NONTERMINAL(nonterminals, nt) {
    // look at every rule where this nonterminal is on LHS
    bool first = true;
    FOREACH_PRODUCTION(productions, prod) {
      if (prod.data()->left == nt.data()) {

        if (first) {
          os << nt.data()->name << ":";
        }
        else {       
          os << "\n";
          INTLOOP(i, 0, nt.data()->name.length()) {
            os << " ";
          }
          os << "|";
        }

        // print RHS symbols
        FOREACH_OBJLIST(Production::RHSElt, prod.data()->right, symIter) {
          Symbol const *sym = symIter.data()->sym;
          if (sym != &emptyString) {
            if (sym->isTerminal()) {
              os << " " << bisonTokenName(&( sym->asTerminalC() ));
            }
            else {
              os << " " << sym->name;
            }
          }
        }

        // or, if empty..
        if (prod.data()->rhsLength() == 0) {
          os << " /* empty */";
        }

        // precedence?
        if (prod.data()->precedence) {
          // search for a terminal with the required precedence level
          bool found=false;
          FOREACH_TERMINAL(terminals, iter) {
            if (iter.data()->precedence == prod.data()->precedence) {
              // found suitable token
              os << " %prec " << bisonTokenName(iter.data());
              found = true;
              break;
            }
          }
          if (!found) {
            cout << "warning: cannot find token for precedence level "
                 << prod.data()->precedence << endl;
            os << " /* no token precedence level "/* */
               << prod.data()->precedence << " */";
          }
        }

        // dummy action to help while debugging
        os << " { $$=" << prod.data()->prodIndex << "; }";

        first = false;
      }
    }

    if (first) {
      // no rules..
      os << "/* no rules for " << nt.data()->name << " */";
    }
    else {
      // finish the rules with a semicolon
      os << "\n";
      INTLOOP(i, 0, nt.data()->name.length()) {
        os << " ";
      }
      os << ";";
    }

    os << "\n\n";
  }
}



// ------------------- symbol access -------------------
Nonterminal const *Grammar::findNonterminalC(char const *name) const
{
  // check for empty first, since it's not in the list
  if (emptyString.name.equals(name)) {
    return &emptyString;
  }

  FOREACH_NONTERMINAL(nonterminals, iter) {
    if (iter.data()->name.equals(name)) {
      return iter.data();
    }
  }
  return NULL;
}


Terminal const *Grammar::findTerminalC(char const *name) const
{
  FOREACH_TERMINAL(terminals, iter) {
    if (iter.data()->name.equals(name) ||
        iter.data()->alias.equals(name)) {
      return iter.data();
    }
  }
  return NULL;
}


Symbol const *Grammar::findSymbolC(char const *name) const
{
  // try nonterminals
  Nonterminal const *nt = findNonterminalC(name);
  if (nt) {
    return nt;
  }

  // now try terminals; if it fails, we fail
  return findTerminalC(name);
}



Nonterminal *Grammar::getOrMakeNonterminal(LocString const &name)
{
  Nonterminal *nt = findNonterminal(name);
  if (nt != NULL) {
    return nt;
  }

  nt = new Nonterminal(name);
  nonterminals.append(nt);
  return nt;
}

Terminal *Grammar::getOrMakeTerminal(LocString const &name)
{
  Terminal *term = findTerminal(name);
  if (term != NULL) {
    return term;
  }

  term = new Terminal(name);
  terminals.append(term);
  return term;
}

Symbol *Grammar::getOrMakeSymbol(LocString const &name)
{
  Symbol *sym = findSymbol(name);
  if (sym != NULL) {
    return sym;
  }

  // Since name is not already defined, we don't know whether
  // it will be a nonterminal or a terminal.  For now, I will
  // use the lexical convention that nonterminals are
  // capitalized and terminals are not.
  if (isupper(name[0])) {
    return getOrMakeNonterminal(name);
  }
  else {
    return getOrMakeTerminal(name);
  }
}


int Grammar::getProductionIndex(Production const *prod) const
{
  int ret = productions.indexOf(prod);
  xassert(ret != -1);
  return ret;
}


sm_string symbolSequenceToString(SymbolList const &list)
{
  sm_stringBuilder sb;   // collects output

  bool first = true;
  SFOREACH_SYMBOL(list, sym) {
    if (!first) {
      sb << " ";
    }

    if (sym.data()->isTerminal()) {
      sb << sym.data()->asTerminalC().toString();
    }
    else {
      sb << sym.data()->name;
    }
    first = false;
  }

  return sb;
}


sm_string terminalSequenceToString(TerminalList const &list)
{
  // this works because access is read-only
  return symbolSequenceToString(reinterpret_cast<SymbolList const&>(list));
}


// ------------------ emitting C++ code ---------------------
#if 0     // not done
void Grammar::emitSelfCC(ostream &os) const
{
  os << "void buildGrammar(Grammar *g)\n"
        "{\n";

  FOREACH_OBJLIST(Terminal, terminals, termIter) {
    Terminal const *term = termIter.data();

    os << "g->declareToken(" << term->name
       << ", " << term->termIndex
       << ", " << quoted(term->alias)
       << ");\n";
  }

  FOREACH_OBJLIST(Nonterminal, nonterminals, ntIter) {
    Nonterminal const *nt = ntIter.data();

    os << ...
  }

  os << "}\n";

  // todo: more
}
#endif // 0
@h=tangler('elk/elk_grammar.h')
@select(h)
// grammar.h            see license.txt for copyright and terms of use
// representation and algorithms for context-free grammars

// Author: Scott McPeak, April 2000

// Unfortunately, representation and algorithm tend to get
// mixed together.  Separating them entirely is possible,
// but syntactically inconvenient.  So, instead, I try to
// document the separation in comments.  Specifically,
// sections beginning with ---- representation ---- are data
// for representation of the underlying concept, while
// sections with ---- annotation ---- are data created by
// algorithms manipulating the data.

// Another measure is I've split all grammar-wide algorithm
// stuff into GrammarAnalysis (gramanl.h).  Things should
// only be put into Grammar if they are directly related
// to the grammar representation.  (However, constitutent
// objects like Production will continue to be a mix.)

#ifndef __GRAMMAR_H
#define __GRAMMAR_H

#include <iostream.h>    // ostream

#include "sm_str.h"
#include "sm_objlist.h"
#include "sm_sobjlist.h"
#include "elk_util.h"
#include "ast_locstr.h"
#include "sm_strobjdict.h"
#include "sm_owner.h"
#include "elk_asockind.h"

class StrtokParse;       // strtokp.h

// fwds defined below
class Symbol;
class Terminal;
class Nonterminal;
class Production;
class DottedProduction;
class Grammar;

// transitional definitions
typedef StringObjDict<LocString> LitCodeDict;
typedef LocString LiteralCode;


// everywhere in the Grammar specification we have a StringRef, it
// refers to this sm_string table
extern StringTable grammarStringTable;


// ---------------- Symbol --------------------
// either a nonterminal or terminal symbol
class Symbol {
// ------ representation ------
public:
  LocString const name;     // symbol's name in grammar
  bool const isTerm;        // true: terminal (only on right-hand sides of productions)
                            // false: nonterminal (can appear on left-hand sides)
  bool const isEmptyString; // true only for the emptyString nonterminal

  StringRef type;           // C type of semantic value

  StringRef dupParam;       // name of parameter to 'dup'
  LocString dupCode;        // code to duplicate a semantic value

  StringRef delParam;       // param name; may be NULL to indicate not used
  LocString delCode;        // code
  
// ----------- annotation ------------
public:
  bool reachable;           // computed by constructLRItemSets; true when nonterminal reachable from start symbol

protected:  // funcs
  virtual void internalPrintDDM(ostream &os) const;

public:      // funcs
  Symbol(LocString const &n, bool t, bool e = false);
  virtual ~Symbol();

  Symbol(Flatten&);
  void xfer(Flatten &flat);

  // symmetric selectors
  bool isTerminal() const { return isTerm; }
  bool isNonterminal() const { return !isTerm; }

  // both terminals and nonterminals have ids; this gets the
  // id for whichever kind this object happens to be
  int getTermOrNontermIndex() const;

  // casting
  Terminal const &asTerminalC() const;       // checks 'isTerminal' for cast safety
  Terminal &asTerminal()
    { return const_cast<Terminal&>(asTerminalC()); }

  Nonterminal const &asNonterminalC() const;
  Nonterminal &asNonterminal()
    { return const_cast<Nonterminal&>(asNonterminalC()); }

  // cast or NULL
  Terminal const *ifTerminalC() const;
  Terminal *ifTerminal()
    { return const_cast<Terminal*>(ifTerminalC()); }

  Nonterminal const *ifNonterminalC() const;
  Nonterminal *ifNonterminal() 
    { return const_cast<Nonterminal*>(ifNonterminalC()); }

  // debugging
  // print as '$name: isTerminal=$isTerminal' (no newline)
  virtual void print(ostream &os) const;
  OSTREAM_OPERATOR(Symbol)

  // print 'token[type] name { dup.. del.. merge.. }' (with newlines)
  void printDDM(ostream &os) const;

  // true if any of the handlers were specified
  virtual bool anyDDM() const;

  virtual sm_string toString() const { return sm_string(name); }
};

// I have several needs for serf lists of symbols, so let's use this for now
typedef SObjList<Symbol> SymbolList;
typedef SObjListIter<Symbol> SymbolListIter;
typedef SObjListMutator<Symbol> SymbolListMutator;

#define FOREACH_SYMBOL(list, iter) FOREACH_OBJLIST(Symbol, list, iter)
#define MUTATE_EACH_SYMBOL(list, iter) MUTATE_EACH_OBJLIST(Symbol, list, iter)
#define SFOREACH_SYMBOL(list, iter) SFOREACH_OBJLIST(Symbol, list, iter)
#define SMUTATE_EACH_SYMBOL(list, iter) SMUTATE_EACH_OBJLIST(Symbol, list, iter)

// format: "s1 s2 s3"
sm_string symbolSequenceToString(SymbolList const &list);


// ---------------- Terminal --------------------
// something that only appears on the right-hand side of
// productions, and is an element of the source language
// NOTE:  This is really a terminal *class*, in that it's possible
// for several different tokens to be classified into the same
// terminal class (e.g. "foo" and "bar" are both identifiers)
class Terminal : public Symbol {
// -------- representation ---------
public:     // data
  // whereas 'name' is the canonical name for the terminal class,
  // this field is an alias; for example, if the canonical name is
  // L2_EQUALEQUAL, the alias might be "=="; the alias should *not*
  // include actual double-quote characters
  // if the alias is "", there is no alias
  LocString alias;

  // parsgen-time conflict resolution: if a shift/reduce conflict
  // occurs between a production and a symbol, both with specified
  // precedence (not 0), then the one with the numerically higher
  // precedence will be used
  int precedence;

  // if, in the above scenario, the precedence values are the same,
  // then the associativity kind will be used to decide which to use
  AssocKind associativity;

  StringRef classifyParam;      // name of parameter to 'classify'
  LocString classifyCode;       // code to reclassify a token type

// ------ annotation ------
public:     // data
  // terminal class index - this terminal's id; -1 means unassigned
  int termIndex;

protected:  // funcs  
  virtual void internalPrintDDM(ostream &os) const;

public:     // funcs
  Terminal(LocString const &name)        // canonical name for terminal class
    : Symbol(name, true /*terminal*/),
      alias(),
      precedence(0),
      associativity(AK_NONASSOC),
      classifyParam(NULL),
      termIndex(-1)
  {}

  Terminal(Flatten &flat);
  void xfer(Flatten &flat);

  virtual void print(ostream &os) const;
  OSTREAM_OPERATOR(Terminal)

  virtual bool anyDDM() const;

  // return alias if defined, name otherwise
  virtual sm_string toString(bool quoteAliases = false) const;
};

typedef SObjList<Terminal> TerminalList;
typedef SObjListIter<Terminal> TerminalListIter;

#define FOREACH_TERMINAL(list, iter) FOREACH_OBJLIST(Terminal, list, iter)
#define MUTATE_EACH_TERMINAL(list, iter) MUTATE_EACH_OBJLIST(Terminal, list, iter)
#define SFOREACH_TERMINAL(list, iter) SFOREACH_OBJLIST(Terminal, list, iter)
#define SMUTATE_EACH_TERMINAL(list, iter) SMUTATE_EACH_OBJLIST(Terminal, list, iter)

// casting aggregates
inline ObjList<Symbol> const &toObjList(ObjList<Terminal> const &list)
  { return reinterpret_cast< ObjList<Symbol>const& >(list); }

// format: "t1 t2 t3"
sm_string terminalSequenceToString(TerminalList const &list);


// ----------------- TerminalSet -------------------
// used for the lookahead sets of LR items, and for the First()
// sets of production RHSs
class TerminalSet {
private:    // data
  unsigned char *bitmap;      // (owner) bitmap of terminals, indexed by
                              // terminal id; lsb of byte 0 is index 0
  int bitmapLen;              // # of bytes in 'bitmap'

public:     // data
  // printing customization: when non-NULL only print tokens if
  // it includes this token, and then *only* print this one
  static Terminal const *suppressExcept;

private:    // funcs
  void init(int numTerms);
  unsigned char *getByte(int terminalId) const;
  int getBit(int terminalId) const
    { return ((unsigned)terminalId % 8); }

public:     // funcs
  TerminalSet(int numTerms=0);                   // allocate new set, initially empty
  TerminalSet(TerminalSet const &obj);
  ~TerminalSet();

  TerminalSet& operator= (TerminalSet const &obj)
    { copy(obj); return *this; }

  TerminalSet(Flatten&);
  void xfer(Flatten &flat);

  // call this to re-allocate at a new size; set is emptied
  void reset(int numTerms);
                                               
  // true when the # of symbols is 0; an unfinished state
  bool nullMap() const { return bitmap==NULL; }

  bool contains(int terminalId) const;
  
  // NOTE: can only compare dotted productions which have the
  // same number of symbols (assertion fail otherwise)
  bool isEqual(TerminalSet const &obj) const;

  void add(int terminalId);
  void remove(int terminalId);
  void clear();

  void copy(TerminalSet const &obj);      // lengths must be the same
  bool merge(TerminalSet const &obj);     // union; returns true if merging changed set

  void print(ostream &os, Grammar const &g) const;
};


// ---------------- Nonterminal --------------------
// something that can appear on the left-hand side of a production
// (or, emptyString, since we classify that as a nonterminal also)
class Nonterminal : public Symbol {
// ---------- representation --------
public:
  StringRef mergeParam1;    // param name for first alternative
  StringRef mergeParam2;    // and 2nd alt
  LocString mergeCode;      // code to resolve then

  StringRef keepParam;      // name of parameter to 'keep'
  LocString keepCode;       // code to decide whether to keep a reduction

  bool maximal;             // if true, use maximal munch disambiguation
  
  SObjList<Nonterminal> subsets;      // preferred subsets (for scannerless)

protected:  // funcs
  virtual void internalPrintDDM(ostream &os) const;

public:     // funcs
  Nonterminal(LocString const &name, bool isEmptyString=false);
  virtual ~Nonterminal();

  Nonterminal(Flatten &flat);
  void xfer(Flatten &flat);
  void xferSerfs(Flatten &flat, Grammar &g);

  virtual void print(ostream &os, Grammar const *grammer = NULL) const;
  OSTREAM_OPERATOR(Nonterminal)

  virtual bool anyDDM() const;

// ------ annotation ------
public:     // data
  int ntIndex;           // nonterminal index; see Grammar::computeWhatCanDeriveWhat
  bool cyclic;           // true if this can derive itself in 1 or more steps
  TerminalSet first;     // set of terminals that can be start of a sm_string derived from 'this'
  TerminalSet follow;    // set of terminals that can follow a sm_string derived from 'this'
  Nonterminal *superset; // inverse of 'subsets'
};

typedef SObjList<Nonterminal> NonterminalList;
typedef SObjListIter<Nonterminal> NonterminalListIter;

#define FOREACH_NONTERMINAL(list, iter) FOREACH_OBJLIST(Nonterminal, list, iter)
#define MUTATE_EACH_NONTERMINAL(list, iter) MUTATE_EACH_OBJLIST(Nonterminal, list, iter)
#define SFOREACH_NONTERMINAL(list, iter) SFOREACH_OBJLIST(Nonterminal, list, iter)
#define SMUTATE_EACH_NONTERMINAL(list, iter) SMUTATE_EACH_OBJLIST(Nonterminal, list, iter)

// casting aggregates
inline ObjList<Symbol> const &toObjList(ObjList<Nonterminal> const &list)
  { return reinterpret_cast< ObjList<Symbol>const& >(list); }


// ---------------- Production --------------------
// a rewrite rule
class Production {
// ------ representation ------
public:     // types
  class RHSElt {
  public:
    Symbol *sym;                // (serf) rhs element symbol

    // tags applied to the symbols for purposes of unambiguous naming in
    // actions, and for self-commenting value as role indicators; an
    // empty tag ("") is allowed and means there is no tag
    LocString tag;             // tag for this symbol; can be ""

  public:
    RHSElt(Symbol *s, LocString const &t) : sym(s), tag(t) {}
    ~RHSElt();

    RHSElt(Flatten&);
    void xfer(Flatten &flat);
    void xferSerfs(Flatten &flat, Grammar &g);
  };

public:     // data
  // fundamental context-free grammar (CFG) component
  Nonterminal * const left;     // (serf) left hand side; must be nonterminal
  ObjList<RHSElt> right;        // right hand side; terminals & nonterminals
  int precedence;               // precedence level for disambiguation (0 for none specified)

  // user-supplied reduction action code
  LocString action;

private:    // funcs
  void computeDerived();

public:     // funcs
  Production(Nonterminal *left, char const *leftTag);
  ~Production();

  Production(Flatten &flat);
  void xfer(Flatten &flat);
  void xferSerfs(Flatten &flat, Grammar &g);

  // length *not* including emptySymbol, if present
  // UPDATE: I'm now disallowing emptySymbol from ever appearing in 'right'
  int rhsLength() const { return rhsLen; }

  // number of nonterminals on RHS
  int numRHSNonterminals() const;

  // true if the given symbol appears in 'right'
  bool rhsHasSymbol(Symbol const *sym) const;

  // retrieve the RHS as a list of symbols, rather than as a list of RHSElts
  void getRHSSymbols(SymbolList &output) const;

  // append a RHS symbol
  void append(Symbol *sym, LocString const &tag);

  // call this when production is built, so it can compute annotations
  // (this is called by GrammarAnalysis::initializeAuxData, from
  // inside runAnalyses)
  void finished(int numTerms);

  // find a symbol by tag; returns 1 for first RHS symbol, 2 for
  // second, etc.; returns -1 if the tag doesn't match anything
  int findTag(StringRef tag) const;

  // given an index as returned by 'findTaggedSymbol', translate that
  // back into a tag
  sm_string symbolTag(int symbolIndex) const;

  // or translate a symbol index into a symbol
  Symbol const *symbolByIndexC(int symbolIndex) const;
  Symbol *symbolByIndex(int symbolIndex)
    { return const_cast<Symbol*>(symbolByIndexC(symbolIndex)); }

  #if 0
  // retrieve an item
  DottedProduction const *getDProdC(int dotPlace) const;
  DottedProduction *getDProd(int dotPlace)
    { return const_cast<DottedProduction*>(getDProdC(dotPlace)); }
  #endif // 0

  // print 'A -> B c D' (no newline)
  sm_string toString(bool printType = true, bool printIndex = true) const;

  // this one prints 'B c D' for above example rule
  sm_string rhsString(bool printTags = true, bool quoteAliases = false) const;

  void print(ostream &os) const;
  OSTREAM_OPERATOR(Production)

  // print entire input syntax, with newlines, e.g.
  //   A -> B c D { return foo; }
  sm_string toStringMore(bool printCode) const;

// ------ annotation ------
private:    // data
  int rhsLen;                   // right.count()

public:     // data
  int prodIndex;                // unique production id
  TerminalSet firstSet;         // First(RHS); computed by GrammarAnalysis::computeFirst
};

typedef SObjList<Production> ProductionList;
typedef SObjListIter<Production> ProductionListIter;

#define FOREACH_PRODUCTION(list, iter) FOREACH_OBJLIST(Production, list, iter)
#define MUTATE_EACH_PRODUCTION(list, iter) MUTATE_EACH_OBJLIST(Production, list, iter)
#define SFOREACH_PRODUCTION(list, iter) SFOREACH_OBJLIST(Production, list, iter)
#define SMUTATE_EACH_PRODUCTION(list, iter) SMUTATE_EACH_OBJLIST(Production, list, iter)

typedef ObjList<Production::RHSElt> RHSEltList;
typedef ObjListIter<Production::RHSElt> RHSEltListIter;
typedef ObjListMutator<Production::RHSElt> RHSEltListMutator;


// ---------------- Grammar --------------------
// represent a grammar: nonterminals, terminals, productions, and start-symbol
class Grammar {
// ------ representation ------
public:     // data
  ObjList<Nonterminal> nonterminals;    // (owner list)
  ObjList<Terminal> terminals;          // (owner list)
  ObjList<Production> productions;      // (owner list)
  Nonterminal *startSymbol;             // (serf) a particular nonterminal

  // the special terminal for the empty sm_string; does not appear in the
  // list of nonterminals or terminals for a grammar, but can be
  // referenced by productions, etc.; the decision to explicitly have
  // such a symbol, instead of letting it always be implicit, is
  // motivated by things like the derivability relation, where it's
  // nice to treat empty like any other symbol
  Nonterminal emptyString;

  // sections of verbatim code emitted into the interface file, before
  // the parser context class body
  ObjList<LocString> verbatim;

  // name of the class into which the action functions are placed
  LocString actionClassName;

  // verbatim action class declaration, and additional codes from
  // extension modules to append to it (but see note of 11/13/04
  // in grampar.cc)
  ObjList<LocString> actionClasses;

  // code emitted into the implementation file at the end
  ObjList<LocString> implVerbatim;

  // ---- declarative options ----
  // name of the target language; nominally "C++"
  sm_string targetLang;

  // when true, the default dup/del is what's expected for a
  // garbage-collected system: dup() is the identity function,
  // and del() is a no-op
  bool useGCDefaults;

  // when true, unspecified merge() functions abort()
  bool defaultMergeAborts;

  // expected numbers of various anomalies; -1 means no
  // expectation has been supplied; this informtion is used
  // to control what is reported after grammar analysis
  int expectedSR;                       // shift/reduce conflicts
  int expectedRR;                       // reduce/reduce conflicts
  int expectedUNRNonterms;              // # unreachable nonterminals
  int expectedUNRTerms;                 // # unreachable terminals

public:     // funcs
  Grammar();                            // set everything manually
  ~Grammar();

  // read/write as binary file
  void xfer(Flatten &flat);

  // simple queries
  int numTerminals() const;
  int numNonterminals() const;


  // ---- building a grammar ----
  // declare a new token exists, with name and optional alias;
  // return false if it's already declared
  bool declareToken(LocString const &symbolName, int code, 
                    LocString const &alias);

  // add a new production; the rhs arg list must be terminated with a NULL
  //void addProduction(Nonterminal *lhs, Symbol *rhs, ...);

  // add a pre-constructed production
  void addProduction(Production *prod);

  // ---------- outputting a grammar --------------
  // print the list of symbols with type annotations
  void printSymbolTypes(ostream &os) const;

  // print the current list of productions
  void printProductions(ostream &os, bool printCode=true) const;

  // emit C++ code to construct this grammar later
  void emitSelfCC(ostream &os) const;

  // ---- whole-grammar stuff ----
  // after adding all rules, check that all nonterminals have
  // at least one rule; also checks referential integrity
  // in actions and conditions; throw exception if there is a
  // problem
  void checkWellFormed() const;

  // output grammar in Bison's syntax
  // (coincidentally, when bison dumps its table with '-v', its table
  // dump syntax is similar to my input syntax)
  void printAsBison(ostream &os) const;

  // ---- symbol access ----
  #define SYMBOL_ACCESS(Thing)                              \
    /* retrieve, return NULL if not there */                \
    Thing const *find##Thing##C(char const *name) const;    \
    Thing *find##Thing(char const *name)                    \
      { return const_cast<Thing*>(find##Thing##C(name)); }  \
                                                            \
    /* retrieve, or create it if not already there */       \
    Thing *getOrMake##Thing(LocString const &name);

  SYMBOL_ACCESS(Symbol)        // findSymbolC, findSymbol, getOrMakeSymbol
  SYMBOL_ACCESS(Terminal)      // findTerminal{C,}, getOrMakeTerminal
  SYMBOL_ACCESS(Nonterminal)   // findNonterminal{C,}, getOrMakeNonterminal
  #undef SYMBOL_ACCESS

  // map a production to a unique index
  int getProductionIndex(Production const *prod) const;
};


#endif // __GRAMMAR_H

@h=tangler('elk/elk_grampar.codes.h')
@select(h)
# define BISON_GRAMPAR_TAB_H     /* tweak */
# define YYSTYPE yystype
# define YYSTYPE_IS_TRIVIAL 1
# define        TOK_INTEGER     257
# define        TOK_NAME        258
# define        TOK_STRING      259
# define        TOK_LIT_CODE    260
# define        TOK_LBRACE      261
# define        TOK_RBRACE      262
# define        TOK_COLON       263
# define        TOK_SEMICOLON   264
# define        TOK_ARROW       265
# define        TOK_LPAREN      266
# define        TOK_RPAREN      267
# define        TOK_COMMA       268
# define        TOK_TERMINALS   269
# define        TOK_TOKEN       270
# define        TOK_NONTERM     271
# define        TOK_FUN 272
# define        TOK_VERBATIM    273
# define        TOK_IMPL_VERBATIM       274
# define        TOK_PRECEDENCE  275
# define        TOK_OPTION      276
# define        TOK_EXPECT      277
# define        TOK_CONTEXT_CLASS       278
# define        TOK_SUBSETS     279
@h=tangler('elk/elk_grampar.h')
@select(h)
// grampar.h            see license.txt for copyright and terms of use
// declarations for bison-generated grammar parser

#ifndef __GRAMPAR_H
#define __GRAMPAR_H

#include "sm_typ.h"
#include "sm_sobjlist.h"
#include "sm_exc.h"
#include "sm_strsobjdict.h"
#include "ast_locstr.h"

// linkdepend: grampar.tab.cc

// fwd decl
class GrammarAST;         // gramast.ast
class TF_nonterm;         // gramast.ast
class GrammarLexer;       // ../ast/gramlex.h
class StringTable;        // strtable.h


// -------- rest of the program's view of parser ------------
// name of extra parameter to yyparse (i.e. the context in
// which the parser operates, instead of that being stored
// in some collection of globals)
#define YYPARSE_PARAM parseParam

// type of thing extra param points at
struct ParseParams {
  GrammarAST *treeTop;    // set when parsing finishes; AST tree top
  GrammarLexer &lexer;    // lexer we're using

public:
  ParseParams(GrammarLexer &L) :
    treeTop(NULL),
    lexer(L)
  {}
};

// caller interface to Bison-generated parser; starts parsing
// (whatever stream lexer is reading) and returns 0 for success and
// 1 for error; the extra parameter is available to actions to use
int grampar_yyparse(void *YYPARSE_PARAM);

// when this is set to true, bison parser emits info about
// actions as it's taking them (shared by all instances of
// bison-generated parsers in a given program)
extern int yydebug;


// ---------- Bison's view of the rest of the program --------
// Bison calls this to get each token; returns token code,
// or 0 for eof; semantic value for returned token can be
// put into '*lvalp'
// TODO: Paul Hilfinger reports there's a problem saying "union
// YYSTYPE"; he's using bison 1.34 I think, so I need to upgrade
// and see what the problem is (suspect my 'sed' pattern isn't
// matching, in the Makefile)
int grampar_yylex(union YYSTYPE *lvalp, void *parseParam);

// error printer
void grampar_yyerror(char const *message, void *parseParam);


// ---------------- grampar's parsing structures ---------------
class Grammar;    // fwd

// while walking the AST, we do a kind of recursive evaluation
// to handle things like inherited actions and self-updating
// (eval'd at grammar parse time) action expressions
class Environment {
public:      // data
  // grammar we're playing with (stored here because it's
  // more convenient than passing it to every fn separately)
  Grammar &g;

  // env in which we're nested, if any
  Environment *prevEnv;      // (serf)

  // maps from a nonterminal name to its declaration, if that
  // nonterminal has in fact been declared already
  StringSObjDict<TF_nonterm /*const*/> nontermDecls;

  // count of recoverable errors; only the one in the
  // topmost environment is used
  int errorCount;
  
  // reference to the one we're really using
  int &errors;

public:
  Environment(Grammar &G);             // new env
  Environment(Environment &prevEnv);   // nested env
  ~Environment();
};


// --------------- grampar's external interface -----------
// parse grammar file 'fname' into grammar 'g', throwing exceptions
// if there are problems
void readGrammarFile(Grammar &g, char const *fname);

// just do the parsing stage
GrammarAST *parseGrammarFile(char const *fname, bool useML);

// merge two grammar descriptions; neither argument is consumed,
// but subtrees of the 2nd argument get moved into the first tree
void mergeGrammar(GrammarAST *base, GrammarAST *ext);

// GrammarAST -> Grammar
void parseGrammarAST(Grammar &g, GrammarAST *treeTop);


// thrown when there is an error parsing the AST
class XASTParse : public xBase {
public:    // data
  // token at or near failure
  LocString failToken;

  // what is wrong
  sm_string message;

private:   // funcs
  static sm_string constructMsg(LocString const &tok, char const *msg);

public:    // funcs
  XASTParse(LocString const &tok, char const *msg);
  XASTParse(XASTParse const &obj);
  ~XASTParse();
};


#endif // __GRAMPAR_H
@h=tangler('elk/elk_grampar.tab.h')
@select(h)
#ifndef BISON_GRAMPAR_TAB_H    /* tweak */
# define BISON_GRAMPAR_TAB_H

#ifndef YYSTYPE
typedef union YYSTYPE {
  int num;
  LocString *str;

  ASTList<TopForm> *topFormList;
  TopForm *topForm;

  ASTList<TermDecl> *termDecls;
  TermDecl *termDecl;
  ASTList<TermType> *termTypes;
  TermType *termType;
  ASTList<PrecSpec> *precSpecs;

  ASTList<SpecFunc> *specFuncs;
  SpecFunc *specFunc;
  ASTList<LocString> *sm_stringList;

  ASTList<ProdDecl> *prodDecls;
  ProdDecl *prodDecl;
  ASTList<RHSElt> *rhsList;
  RHSElt *rhsElt;
} yystype;
# define YYSTYPE yystype
# define YYSTYPE_IS_TRIVIAL 1
#endif
# define        TOK_INTEGER     257
# define        TOK_NAME        258
# define        TOK_STRING      259
# define        TOK_LIT_CODE    260
# define        TOK_LBRACE      261
# define        TOK_RBRACE      262
# define        TOK_COLON       263
# define        TOK_SEMICOLON   264
# define        TOK_ARROW       265
# define        TOK_LPAREN      266
# define        TOK_RPAREN      267
# define        TOK_COMMA       268
# define        TOK_TERMINALS   269
# define        TOK_TOKEN       270
# define        TOK_NONTERM     271
# define        TOK_FUN 272
# define        TOK_VERBATIM    273
# define        TOK_IMPL_VERBATIM       274
# define        TOK_PRECEDENCE  275
# define        TOK_OPTION      276
# define        TOK_EXPECT      277
# define        TOK_CONTEXT_CLASS       278
# define        TOK_SUBSETS     279


#endif /* not BISON_GRAMPAR_TAB_H */
@h=tangler('elk/elk_lexerint.h')
@select(h)
// lexerint.h            see license.txt for copyright and terms of use
// LexerInterface, the interface the GLR parser uses
// to access the lexer's token stream

#ifndef LEXERINT_H
#define LEXERINT_H

#include "elk_useract.h"
#include "sm_srcloc.h"
#include "sm_str.h"

// This 'interface' is a collection of variables describing
// the current token.  I don't use a bunch of pure-virtual
// functions because of the cost of calling them; everything
// here will be in the inner loop of the parser.
class LexerInterface {
public:     // data
  // NOTE: All of these fields are *written* by the lexer, and
  // *read* by the parser.

  // token classification; this is what the parser will use to
  // make parsing decisions; this code must correspond to something
  // declared in the 'terminals' section of the grammar; when this
  // is 0, it is the final (end-of-file) token; the parser is allowed
  // to change this for its own purposes, and currently does so for
  // token reclassification
  int type;

  // semantic value; this is what will be passed to the reduction
  // actions when this token is on the right hand side of a rule
  SemanticValue sval;

  // source location of the token; this will only be used if the
  // parser has been compiled to automatically propagate it
  SourceLoc loc;

public:     // funcs
  LexerInterface()
    : type(0),
      sval(0),
      loc(SL_UNKNOWN)
  {}
  virtual ~LexerInterface() {}


  // retrieve the next token; the lexer should respond by filling in
  // the above fields with new values, to describe the next token; the
  // lexer indicates end of file by putting 0 into 'type'; when the
  // LexerInterface object is first passed to the parser, the above
  // fields should already be set correctly (i.e. the parser will make
  // its first call to 'nextToken' *after* processing the first token)
  typedef void (*NextTokenFunc)(LexerInterface *);

  // get the function which we'll call to get the next token
  //
  // Why the two-step approach?  Virtual method calls are more
  // expensive than simple indirect function calls, and this happens
  // in the inner parsing loop.  If C++ had a way to explicitly cache
  // the result of a method lookup this wouldn't be necessary.
  virtual NextTokenFunc getTokenFunc() const=0;

  
  // The following functions are called to help create diagnostic
  // reports.  They should describe the current token (the one
  // which the above fields refer to) in more-or-less human-readable
  // terms.

  // describe the token; for tokens with multiple spellings (e.g.
  // identifiers), this should include the actual token spelling
  // if possible; note that if the token has been reclassified,
  // then the 'type' field above might have been changed by the
  // parser, in which case this function should ideally print
  // a description which takes the new type into account
  virtual sm_string tokenDesc() const=0;

  // describe a token kind; this is different from tokenDesc(), since
  // it need not correspond to the token kind that was just yielded,
  // and hence any related lexeme data cannot be assumed to be
  // available; this is used during error diagnosis
  virtual sm_string tokenKindDesc(int kind) const=0;
};

#endif // LEXERINT_H
@h=tangler('elk/elk_mlsstr.h')
@select(h)
// mlsstr.h            see license.txt for copyright and terms of use
// handles lexically embedded ML
// based on ccsstr.h

#ifndef MLSSTR_H
#define MLSSTR_H

#include "ast_embedded.h"

class MLSubstrateTest;

class MLSubstrate : public EmbeddedLang {
private:
  enum State {
    ST_NORMAL,       // normal text
    ST_STRING,       // inside a sm_string literal
    ST_CHAR,         // inside a char literal
    ST_COMMENT,      // inside a comment
    NUM_STATES
  } state;
  int nesting;       // depth of paren/bracket/brace nesting
  int comNesting;    // depth of comment nesting (in ST_COMMENT)
  char prev;         // previous character

  // so test code can interrogate internal state
  friend class MLSubstrateTest;

public:
  MLSubstrate(ReportError *err = NULL);
  virtual ~MLSubstrate();

  // EmbeddedLang entry points (see gramlex.h for description
  // of each function)
  virtual void reset(int initNest = 0);
  virtual void handle(char const *str, int len, char finalDelim);
  virtual bool zeroNesting() const;
  virtual sm_string getFuncBody() const;
  virtual sm_string getDeclName() const;
};

#endif // MLSSTR_H
@h=tangler('elk/elk_ownerspec.h')
@select(h)
// ownerspec.h            see license.txt for copyright and terms of use
// specification of "owner pointer", as a C++ template class

// I made this as an experiment.. it's really part of the
// verifier project...
#error This is not intended to be used

template <class T>
class OwnerPtr {
private:
  T *ptr;
  
  enum State { OP_NULL, OP_DEAD, OP_OWNING };
  State state;
  
public:
  OwnerPtr() : ptr(NULL), state(OP_NULL) {}

  OwnerPtr(T *src) : ptr(src), state(src? OP_OWNING : OP_NULL) {}

  OwnerPtr(OwnerPtr &src) {
    ptr = src.ptr;
    state = src.state;
    src.state = OP_DEAD;
  }

  ~OwnerPtr() {
    assert(state != OP_OWNING);
  }

  OwnerPtr& operator= (OwnerPtr &src) {
    if (this != &src) {
      assert(state != OP_OWNING);
      ptr = src.ptr;
      state = src.state;
      src.state = OP_DEAD;
    }
    return *this;
  }

  OwnerPtr& operator= (T *src) {
    assert(state != OP_OWNING);
    ptr = src;
    state = src? OP_OWNING : OP_NULL;
    return *this;
  }

  bool operator== (T *p) {
    assert(state != OP_DEAD);
    return ptr == p;
  }

  // yield serf for possible further use
  operator T* () {
    assert(state != OP_DEAD);
    return ptr;
  }

  // use directly
  T& operator* () {
    assert(state == OP_OWNING);
    return *ptr;
  }
  T* operator-> () {
    assert(state == OP_OWNING);
    return ptr;
  }
};






@h=tangler('elk/elk_parsetables.h')
@select(h)
// parsetables.h            see license.txt for copyright and terms of use
// ParseTables, a class to contain the tables need by the
// LR/GLR parsing algorithm

#ifndef PARSETABLES_H
#define PARSETABLES_H

#include "sm_array.h"
#include "elk_glrconfig.h"
#include <iostream.h>     // ostream

class Flatten;            // flatten.h
class EmitCode;           // emitcode.h
class Symbol;             // grammar.h
class Bit2d;              // bit2d.h


// integer id for an item-set DFA state; I'm using an 'enum' to
// prevent any other integers from silently flowing into it
enum StateId { STATE_INVALID=-1 };

inline ostream& operator<< (ostream &os, StateId id)
  { return os << (int)id; }


// encodes an action in 'action' table; see 'actionTable'
#if ENABLE_CRS_COMPRESSION
  // high bits encoding
  enum ActionEntryKind {
    AE_MASK      = 0xC0,    // selection mask
    AE_SHIFT     = 0x00,    // 00 = shift
    AE_REDUCE    = 0x40,    // 01 = reduce
    AE_AMBIGUOUS = 0x80,    // 10 = ambiguous
    AE_ERROR     = 0xC0,    // 11 = error (if EEF is off)
    AE_MAXINDEX  = 63       // maximum value of lower bits
  };

  // remaining 6 bits:
  //
  //   shift: desination state, encoded as an offset from the
  //   first state that that terminal can reach
  //
  //   reduce: production, encoded as an index into a per-state
  //   array of distinct production indices
  //
  //   ambiguous: for each state, have an array of ActionEntries.
  //   ambiguous entries index into this array.  first indexed
  //   entry is the count of how many actions follow
  typedef unsigned char ActionEntry;
  ActionEntry makeAE(ActionEntryKind k, int index);
  #define errorActionEntry ((ActionEntry)AE_ERROR)
#else
  // each entry is one of:
  //   +N+1, 0 <= N < numStates:         shift, and go to state N
  //   -N-1, 0 <= N < numProds:          reduce using production N
  //   numStates+N+1, 0 <= N < numAmbig: ambiguous, use ambigAction N
  //   0:                                error
  // (there is no 'accept', acceptance is handled outside this table)
  typedef signed short ActionEntry;
  #define errorActionEntry ((ActionEntry)0)
#endif


// encodes a destination state in 'gotoTable'
#if ENABLE_CRS_COMPRESSION
  // entry is an offset from the first state that can be reached
  // by shifting the nonterminal
  typedef unsigned char GotoEntry;
#else
  // entry is the to go to after shifting the nonterminal
  typedef unsigned short GotoEntry;
#endif
#define errorGotoEntry ((GotoEntry)~0)


// name a terminal using an index
typedef unsigned char TermIndex;

// name a nonterminal using an index
typedef unsigned char NtIndex;

// name a production using an index
typedef unsigned short ProdIndex;

// an addressed cell in the 'errorBits' table
typedef unsigned char ErrorBitsEntry;


// encodes either terminal index N (as N+1) or
// nonterminal index N (as -N-1), or 0 for no-symbol
typedef signed short SymbolId;
inline bool symIsTerm(SymbolId id) { return id > 0; }
inline int symAsTerm(SymbolId id) { return id-1; }
inline bool symIsNonterm(SymbolId id) { return id < 0; }
inline NtIndex symAsNonterm(SymbolId id) { return (NtIndex)(-(id+1)); }
SymbolId encodeSymbolId(Symbol const *sym);       // gramanl.cc


// assign, but check for truncation
template <class DEST, class SRC>
inline void checkAssign(DEST &d, SRC s)
{
  d = (DEST)s;
  xassert(d == s);
}


// the parse tables are the traditional action/goto, plus the list
// of ambiguous actions, plus any more auxilliary tables useful during
// run-time parsing
class ParseTables {
private:    // types
  // data about an intermediate state of parse table construction;
  // once the table is finished, this data gets consolidated into the
  // actual tables, and then thrown away
  class TempData {
  public:   // data
    // nascent ambigTable
    ArrayStack<ActionEntry> ambigTable;

    // nascent bigProductionList
    ArrayStack<ProdIndex> bigProductionList;
    
    // nascent productionsForState, except using integer offsets from
    // start of 'bigProductionList' instead of direct pointers into it
    ArrayStack<int> productionsForState;

    // nascent versions of ambig tables, again with integer offsets
    ArrayStack<int> ambigStateTable;

  public:   // funcs
    TempData(int numStates);
    ~TempData();
  };

public:     // types
  // per-production info
  struct ProdInfo {
    unsigned char rhsLen;                // # of RHS symbols
    NtIndex lhsIndex;                    // 'ntIndex' of LHS
  };

protected:  // data
  // when this is false, all of the below "(owner*)" annotations are
  // actually "(serf)", i.e. this object does *not* own any of the
  // tables (see emitConstructionCode())
  bool owning;

  // non-NULL during construction
  TempData *temp;                        // (nullable owner)

  // # terminals, nonterminals in grammar
  int numTerms;
  int numNonterms;

  // # of parse states
  int numStates;

  // # of productions in the grammar
  int numProds;

  // action table, indexed by (state*actionCols + lookahead)
  int actionCols;
  ActionEntry *actionTable;              // (owner*)

  // goto table, indexed by (state*gotoCols + nontermId)
  int gotoCols;
  GotoEntry *gotoTable;                  // (owner*)

  // map production id to information about that production
  ProdInfo *prodInfo;                    // (owner*)

  // map a state id to the symbol (terminal or nonterminal) which is
  // shifted to arrive at that state
  SymbolId *stateSymbol;                 // (owner*)

  // ambiguous actions: one big list, for allocation purposes; then
  // the actions encode indices into this table; the first indexed
  // entry gives the # of actions, and is followed by that many
  // actions, each interpreted the same way ordinary 'actionTable'
  // entries are
  int ambigTableSize;
  ActionEntry *ambigTable;               // (nullable owner*)

  // total order on nonterminals for use in choosing which to
  // reduce to in the RWL algorithm; index into this using a
  // nonterminal index, and it yields the ordinal for that
  // nonterminal (so these aren't really NtIndex's, but they're
  // exactly as wide, so I use NtIndex anyway)
  //
  // The order is consistent with the requirement that if
  //   A ->+ B
  // then B will be earlier in the order (assuming acyclicity).
  // That way, we'll do all reductions to B before any to A (for
  // reductions spanning the same set of ground terminals), and
  // therefore will merge all alternatives for B before reducing
  // any of them to A.
  NtIndex *nontermOrder;                 // (owner*)

  // --------------------- table compression ----------------------

  // table compression techniques taken from:
  //   [DDH] Peter Dencker, Karl Drre, and Johannes Heuft.
  //   Optimization of Parser Tables for Portable Compilers.
  //   In ACM TOPLAS, 6, 4 (1984) 546-572.
  //   http://citeseer.nj.nec.com/context/27540/0 (not in database)
  //   ~/doc/papers/p546-dencker.pdf (from ACM DL)

  // Code Reduction Scheme (CRS):
  //
  // Part (a):  The states are numbered such that all states that
  // are reached by transitions on a given symbol are contiguous.
  // See gramanl.cc, GrammarAnalysis::renumberStates().  Then, we
  // simply need a map from the symbol index to the first state
  // that is reached along that symbol.
  StateId *firstWithTerminal;            // (nullable owner*) termIndex -> state
  StateId *firstWithNonterminal;         // (nullable owner*) ntIndex -> state
  //
  // Part (b):  The production indices that appear on a given row
  // are collected together.  (This is called (c) by [DDH]; I don't
  // have a counterpart to their (b).)
  int bigProductionListSize;
  ProdIndex *bigProductionList;          // (nullable owner*) array into which 'productionsForState' points
  ProdIndex **productionsForState;       // (nullable owner to serf) state -> stateProdIndex -> prodIndex
  //
  // Part (c):  Pointers into 'ambigTable' are are collected together in
  // per-state lists as well.
  ActionEntry **ambigStateTable;         // (nullable owner) state -> (+ambigStateTableIndex -> ActionEntry*)

  // Error Entry Factoring (EEF):
  //
  // Factor out all the error entries into their own bitmap.  Then
  // regard error entries in the original tables as "insignificant".
  //
  // 'errorBits' is a map of where the error actions are in the action
  // table.  It is indexed through 'errorBitsPointers':
  //   byte = errorBitsPointers[stateId][lookahead >> 3];
  //   if ((byte >> (lookahead & 7)) & 1) then ERROR
  int errorBitsRowSize;                  // bytes per row
  int uniqueErrorRows;                   // distinct rows
  ErrorBitsEntry *errorBits;             // (nullable owner*)
  ErrorBitsEntry **errorBitsPointers;    // (nullable owner ptr to serfs)

  // Graph Coloring Scheme (GCS):
  //
  // Merge lines and columns that have identical significant entries.
  // This is done as two-pass graph coloring.  They give a specific
  // heuristic.
  //
  // this is a map to be applied to terminal indices before being
  // used to access the compressed action table; it maps the terminal
  // id (as reported by the lexer) to the proper action table column
  TermIndex *actionIndexMap;             // (nullable owner*)
  //
  // this is a map from states to the beginning of the action table
  // row that pertains to that state; it effectively factors the
  // states into equivalence classes
  int actionRows;                        // rows in actionTable[]
  ActionEntry **actionRowPointers;       // (nullable owner ptr to serfs)
  //
  // index map for the goto table
  NtIndex *gotoIndexMap;                 // (nullable owner*)
  //
  // row map for the goto table
  int gotoRows;
  GotoEntry **gotoRowPointers;           // (nullable owner ptr to serfs)

public:     // data
  // These are public because if they weren't, I'd just have a stupid
  // getter/setter pattern that exposes them anyway.

  // start state id
  StateId startState;

  // index of the production which will finish a parse; it's the
  // final reduction executed
  int finalProductionIndex;

private:    // funcs
  void alloc(int numTerms, int numNonterms, int numStates, int numProds,
             StateId start, int finalProd);

  // index tables
  ActionEntry &actionEntry(StateId stateId, int termId)
    { return actionTable[stateId*actionCols + termId]; }
  int actionTableSize() const
    { return actionRows * actionCols; }

  GotoEntry &gotoEntry(StateId stateId, int nontermId)
    { return gotoTable[stateId*gotoCols + nontermId]; }
  int gotoTableSize() const
    { return gotoRows * gotoCols; }

  void appendAmbig(ArrayStack<ActionEntry> const &set);
  bool compareAmbig(ArrayStack<ActionEntry> const &set, int startIndex);

  void fillInErrorBits(bool setPointers);
  int colorTheGraph(int *color, Bit2d &graph);

protected:  // funcs
  // the idea is that 'emitConstructionCode' will emit code that
  // defines a subclass of 'ParseTables'; that's why so many of the
  // data members are protected: the subclass can then access them
  // directly, which is very convenient when trying to construct the
  // tables from static data
  ParseTables(bool owning);    // only legal when owning==false

public:     // funcs
  ParseTables(int numTerms, int numNonterms, int numStates, int numProds,
              StateId start, int finalProd);
  ~ParseTables();

  // simple queries
  int getNumTerms() const { return numTerms; }
  int getNumNonterms() const { return numNonterms; }
  int getNumStates() const { return numStates; }
  int getNumProds() const { return numProds; }

  // finish construction; do this before emitting code
  void finishTables();

  // write the tables out as C++ source that can be compiled into
  // the program that will ultimately do the parsing
  void emitConstructionCode(EmitCode &out, char const *className, char const *funcName);

  // this does the same thing for ML, and is implemented in genml.cc
  void emitMLConstructionCode(EmitCode &out, char const *className, char const *funcName);


  // -------------------- table construction ------------------------
  // CRS dest-state origin tables
  void setFirstWithTerminal(int termId, StateId s) {
    xassert((unsigned)termId < (unsigned)numTerms);
    firstWithTerminal[termId] = s;
  }
  void setFirstWithNonterminal(int nontermId, StateId s) {
    xassert((unsigned)nontermId < (unsigned)numNonterms);
    firstWithNonterminal[nontermId] = s;
  }

  void setActionEntry(StateId stateId, int termId, ActionEntry act)
    { actionEntry(stateId, termId) = act; }
  void setGotoEntry(StateId stateId, int nontermId, GotoEntry got)
    { gotoEntry(stateId, nontermId) = got; }

  // encode actions
  ActionEntry encodeShift(StateId destState, int shiftedTermId);
  ActionEntry encodeReduce(int prodId, StateId inWhatState);
  ActionEntry encodeAmbig(ArrayStack<ActionEntry> const &set,
                          StateId inWhatState);
  ActionEntry encodeError() const;
  ActionEntry validateAction(int code) const;

  // encode gotos
  GotoEntry encodeGoto(StateId stateId, int shiftedNontermId) const;
  GotoEntry encodeGotoError() const
    { return errorGotoEntry; }
  GotoEntry validateGoto(int code) const;

  // misc
  void setProdInfo(int prodId, int rhsLen, int ntIndex) {
    checkAssign(prodInfo[prodId].rhsLen, rhsLen);
    checkAssign(prodInfo[prodId].lhsIndex, ntIndex);
  }
  void setStateSymbol(StateId state, SymbolId sym) {
    stateSymbol[state] = sym;
  }
  NtIndex *getWritableNontermOrder() {
    // expose this directly, due to the way the algorithm that
    // computes it is written
    return nontermOrder;
  }

  // table compressors
  void computeErrorBits();
  void mergeActionColumns();
  void mergeActionRows();
  void mergeGotoColumns();
  void mergeGotoRows();


  // -------------------- table queries ---------------------------
  // return true if the action is an error
  bool actionEntryIsError(StateId stateId, int termId) {
    #if ENABLE_EEF_COMPRESSION
      // check with the error table
      return ( errorBitsPointers[stateId][termId >> 3]
                 >> (termId & 7) ) & 1;
    #else
      return isErrorAction(actionEntry(stateId, termId));
    #endif
  }

  // query action table, without checking the error bitmap
  ActionEntry getActionEntry_noError(StateId stateId, int termId) {
    #if ENABLE_GCS_COMPRESSION
      #if ENABLE_GCS_COLUMN_COMPRESSION
        return actionRowPointers[stateId][actionIndexMap[termId]];
      #else
        return actionRowPointers[stateId][termId];
      #endif
    #else
      return actionEntry(stateId, termId);
    #endif
  }

  // query the action table, yielding an action that might be
  // an error action
  ActionEntry getActionEntry(StateId stateId, int termId) {
    #if ENABLE_EEF_COMPRESSION
      if (actionEntryIsError(stateId, termId)) {
        return errorActionEntry;
      }
    #endif

    return getActionEntry_noError(stateId, termId);
  }

  // decode actions
  #if !ENABLE_CRS_COMPRESSION
    bool isShiftAction(ActionEntry code) const
      { return code > 0 && code <= numStates; }
    static StateId decodeShift(ActionEntry code, int /*shiftedTerminal*/)
      { return (StateId)(code-1); }
    static bool isReduceAction(ActionEntry code)
      { return code < 0; }
    static int decodeReduce(ActionEntry code, StateId /*inState*/)
      { return -(code+1); }
    static bool isErrorAction(ActionEntry code)
      { return code == 0; }

    // ambigAction is only other choice; this yields a pointer to
    // an array of actions, the first of which says how many actions
    // there are
    ActionEntry *decodeAmbigAction(ActionEntry code, StateId /*inState*/) const
      { return ambigTable + (code-1-numStates); }

  #else
    static bool isShiftAction(ActionEntry code) {
      return (code & AE_MASK) == AE_SHIFT;
    }
    StateId decodeShift(ActionEntry code, int shiftedTerminal) {
      return (StateId)(firstWithTerminal[shiftedTerminal] + (code & AE_MAXINDEX));
    }
    static bool isReduceAction(ActionEntry code) {
      return (code & AE_MASK) == AE_REDUCE;
    }
    int decodeReduce(ActionEntry code, StateId inState) {
      return productionsForState[inState][code & AE_MAXINDEX];
    }
    static bool isErrorAction(ActionEntry code) {
      return code == AE_ERROR;
    }

    ActionEntry *decodeAmbigAction(ActionEntry code, StateId inState) const {
      return ambigStateTable[inState] + (code & AE_MAXINDEX);
    }
  #endif

  // decode gotos
  GotoEntry getGotoEntry(StateId stateId, int nontermId) {
    #if ENABLE_GCS_COMPRESSION
      #if ENABLE_GCS_COLUMN_COMPRESSION
        return gotoRowPointers[stateId][gotoIndexMap[nontermId]];
      #else
        return gotoRowPointers[stateId][nontermId];
      #endif
    #else
      return gotoEntry(stateId, nontermId);
    #endif
  }

  bool isErrorGoto(GotoEntry code)
    { return code == errorGotoEntry; }

  StateId decodeGoto(GotoEntry code, int shiftedNonterminal) {
    #if ENABLE_CRS_COMPRESSION
      return (StateId)(firstWithNonterminal[shiftedNonterminal] + code);
    #else
      return (StateId)code;
    #endif
  }

  // nonterminal order
  int nontermOrderSize() const
    { return numNonterms; }
  NtIndex getNontermOrdinal(NtIndex idx) const
    { return nontermOrder[idx]; }

  // misc
  ProdInfo const &getProdInfo(int prodIndex) const
    { return prodInfo[prodIndex]; }
  int getStateSymbol(StateId id) const
    { return stateSymbol[id]; }

  // query compression options based on which fields are not NULL; do
  // *not* use the compile-time flags, because we're trying to detect
  // mismatch between compiler flags used at different times
  bool eef_enabled() const
    { return !!errorBits; }
  bool gcs_enabled() const
    { return !!actionRowPointers; }
  bool gcsc_enabled() const
    { return !!actionIndexMap; }
  bool crs_enabled() const
    { return !!firstWithTerminal; }
};


// NOTE: At one point (before 7/27/03), I had the ability to read and
// write parse tables to files, *not* using the C++ compiler to store
// tables as static data.  I removed it because I wasn't using it, and
// it was hindering table evolution.  But as the tables stabilize
// again, if the need arises, one could go get (from CVS) the code
// that did it and fix it up to work again.


#endif // PARSETABLES_H
@h=tangler('elk/elk_ptreeact.h')
@select(h)
// ptreeact.h            see license.txt for copyright and terms of use
// a generic set of user actions that build parse trees for any grammar

#ifndef PTREEACT_H
#define PTREEACT_H

#include "elk_lexerint.h"
#include "elk_useract.h"

class ParseTables;         // parsetables.h


// lexer to yield PTreeNodes for tokens
class ParseTreeLexer : public LexerInterface {
private:
  LexerInterface *underlying;   // for getting token descriptions
  NextTokenFunc underToken;     // for getting tokens
  UserActions *actions;         // for getting symbol names

private:
  void copyFields();

public:
  ParseTreeLexer(LexerInterface *u, UserActions *a);

  static void nextToken(LexerInterface *lex);
  virtual NextTokenFunc getTokenFunc() const
    { return &ParseTreeLexer::nextToken; }

  virtual sm_string tokenDesc() const;
  virtual sm_string tokenKindDesc(int kind) const;
};


// layer these actions on top of the generated actions to
// build parse trees for the reductions
class ParseTreeActions : public TrivialUserActions {
private:
  UserActions *underlying;   // for getting symbol names
  ParseTables *tables;       // for finding out production lengths

public:
  ParseTreeActions(UserActions *u, ParseTables *t)
    : underlying(u), tables(t) {}

  static SemanticValue reduce(
    UserActions *context,
    int productionId,
    SemanticValue const *svals
    SOURCELOCARG( SourceLoc loc ) );
  virtual ReductionActionFunc getReductionAction()
    { return &ParseTreeActions::reduce; }

  virtual SemanticValue mergeAlternativeParses(
    int ntIndex, SemanticValue left, SemanticValue right
    SOURCELOCARG( SourceLoc loc ) );

  virtual char const *terminalName(int termId);
  virtual char const *nonterminalName(int termId);
  
  ParseTables *getTables() { return tables; }
};


#endif // PTREEACT_H
@h=tangler('elk/elk_ptreenode.h')
@select(h)
// ptreenode.h            see license.txt for copyright and terms of use
// parse tree node for experimental grammars (this isn't somthing
// Elkhound as a whole knows about--it doesn't make trees unless
// the user actions do)

#ifndef PTREENODE_H
#define PTREENODE_H

#include <stddef.h>     // NULL
#include <iostream.h>   // ostream

// for storing counts of parse trees; I try to make the code work for
// either 'int' or 'double' in this spot (e.g. I assign 0 to it
// instead of 0.0), even though 'int' overflows quickly for the highly
// ambiguous grammars
typedef double TreeCount;

class PTreeNode {
public:    // types
  // max # of children (when this is increased, more constructors
  // for PTreeNode should be added)
  enum { MAXCHILDREN = 10 };
  
  // printing options
  enum PrintFlags {
    PF_NONE    = 0,       // default, print types as-is
    PF_EXPAND  = 1,       // types are just LHS, dig down to find RHSs
    PF_ADDRS   = 2,       // print node virtual addresses to see sharing
  };

public:    // data
  // textual repr. of the production applied; possibly useful for
  // printing the tree, or during debugging
  char const *type;

  // instead of making explicit merge nodes (which runs afoul of the
  // yield-then-merge problem), just link alternatives together using
  // this link; this is NULL when there are no alternatives, or for
  // the last node in a list of alts
  PTreeNode *merged;

  // array of children; these aren't owner pointers because
  // we might have arbitrary sharing for some grammars
  int numChildren;
  PTreeNode *children[MAXCHILDREN];

  // # of parse trees of which this is the root; effectively this
  // memoizes the result to avoid an exponential blowup counting
  // the trees; when this value is 0, it means the count has not
  // yet been computed (any count must be positive)
  TreeCount count;

  // count of # of allocated nodes; useful for identifying when
  // we're making too many
  static int allocCount;

  // count # of times addAlternative is called; this will tell
  // the total number of local ambiguities that need to be resolved
  static int alternativeCount;

private:     // funcs
  // init fields which don't depend on ctor args
  void init();

  // helpers
  static void indent(ostream &out, int n);
  void innerPrintTree(ostream &out, int indentation, PrintFlags pf) const;
  int countMergedList() const;

public:      // funcs
  // now lots of constructors so we have one for each possible
  // number of children; the calls are automatically inserted
  // by a perl script ('make-trivparser.pl') or by the grammar
  // transformation GrammarAnalysis::addTreebuildingActions()
  PTreeNode(char const *t)
    : type(t), numChildren(0), count(0) { init(); }
  PTreeNode(char const *t, PTreeNode *ch0)
    : type(t), numChildren(1), count(0) { init(); children[0] = ch0; }
  PTreeNode(char const *t, PTreeNode *ch0, PTreeNode *ch1)
    : type(t), numChildren(2), count(0) { init(); children[0] = ch0; children[1] = ch1; }
  PTreeNode(char const *t, PTreeNode *ch0, PTreeNode *ch1, PTreeNode *ch2)
    : type(t), numChildren(3), count(0) { init(); children[0] = ch0; children[1] = ch1; children[2] = ch2; }
  PTreeNode(char const *t, PTreeNode *ch0, PTreeNode *ch1, PTreeNode *ch2, PTreeNode *ch3)
    : type(t), numChildren(4), count(0) { init(); children[0] = ch0; children[1] = ch1; children[2] = ch2; children[3] = ch3; }
  PTreeNode(char const *t, PTreeNode *ch0, PTreeNode *ch1, PTreeNode *ch2, PTreeNode *ch3, PTreeNode *ch4)
    : type(t), numChildren(5), count(0) { init(); children[0] = ch0; children[1] = ch1; children[2] = ch2; children[3] = ch3; children[4] = ch4; }
  // be sure to update MAXCHILDREN, above, if you add constructors
  // which accept more children

  ~PTreeNode() { allocCount--; }

  // count the number of trees encoded (taking merge nodes into
  // account) in the tree rooted at 'this'
  TreeCount countTrees();

  // print the entire parse forest using indentation to represent
  // nesting, and duplicating printing of shared subtrees within
  // ambiguous regions
  void printTree(ostream &out, PrintFlags pf = PF_NONE) const;

  // add an alternative to the current 'merged' list
  void addAlternative(PTreeNode *alt);
};

#endif // PTREENODE_H
@h=tangler('elk/elk_rcptr.h')
@select(h)
// rcptr.h            see license.txt for copyright and terms of use
// a stab at a reference-counting pointer

// the object pointed-at must support this interface:
//   // increment reference count
//   void incRefCt();
//   
//   // decrement refcount, and if it becomes 0, delete yourself
//   void decRefCt();

#ifndef __RCPTR_H
#define __RCPTR_H

#include "sm_typ.h"

#if 0
  #include <stdio.h>    // printf, temporary
  #define DBG(fn) printf("%s(%p)\n", fn, ptr)
#else
  #define DBG(fn)
#endif

template <class T>
class RCPtr {
private:    // data
  T *ptr;                // the real pointer

private:    // funcs
  void inc() { DBG("inc"); if (ptr) { ptr->incRefCt(); } }
  void dec() { DBG("dec"); if (ptr) { ptr->decRefCt(); ptr=NULL; } }

public:     // funcs
  explicit RCPtr(T *p = NULL) : ptr(p) { DBG("ctor"); inc(); }
  explicit RCPtr(RCPtr const &obj) : ptr(obj.ptr) { DBG("cctor"); inc(); }
  ~RCPtr() { DBG("dtor"); dec(); }

  // point at something new (setting to NULL is an option)
  void operator= (T *p) { DBG("op=ptr"); dec(); ptr=p; inc(); }
  void operator= (RCPtr<T> const &obj)
    { DBG("op=obj"); dec(); ptr=obj.ptr; inc(); }

  // some operators that make Owner behave more or less like
  // a native C++ pointer
  operator T const * () const { DBG("opcT*"); return ptr; }
  T const & operator* () const { DBG("opc*"); return *ptr; }
  T const * operator-> () const { DBG("opc->"); return ptr; }

  bool operator==(T *p) const { return ptr == p; }
  bool operator!=(T *p) const { return !this->operator==(p); }

  bool operator==(RCPtr<T> const &obj) const { return ptr == obj.ptr; }
  bool operator!=(RCPtr<T> const &obj) const { return !this->operator==(obj); }

  operator T* () { DBG("opT*"); return ptr; }
  operator T const * () { DBG("opcT*"); return ptr; }
  T& operator* () { DBG("op*"); return *ptr; }
  T* operator-> () { DBG("op->"); return ptr; }

  // escape hatch for when operators flake out on us
  T *get() { DBG("get"); return ptr; }
  T const *getC() const { DBG("getC"); return ptr; }
  
  // sometimes, in performance-critical code, I need fine control
  // over the refcount operations; this lets me change 'ptr', the
  // assumption being I'll update the refct manually
  void setWithoutUpdateRefct(T *p) { ptr=p; }
};


#endif // __RCPTR_H
@h=tangler('elk/elk_useract.h')
@select(h)
// useract.h            see license.txt for copyright and terms of use
// interface to an object containing user-defined action functions

// the code appears in the .cc file generated by 'gramanl' from
// an associated .gr file

// the comments below are guidelines on writing grammar actions, since
// those grammar actions are composed to form the single-entry
// functions documented below

#ifndef USERACT_H
#define USERACT_H

#include "elk_glrconfig.h"
#include "sm_str.h"
#include "sm_srcloc.h"

class ParseTables;         // parsetables.h

// user-supplied semantic values:
//  - Semantic values are an arbitrary word, that the user can then
//    use as a pointer or an integer or whatever.  The parser
//    generator inserts the appropriate casts, so the actual type
//    I use here shouldn't ever be visible to the user.
//  - Usually, SemanticValues that are used as pointers are considered
//    to be owner pointers, but only in the sense that del() will be
//    called.  It's up to the user to decide if del() actually does
//    anything.
typedef unsigned long SemanticValue;

// name of a null sval; can't use "NULL" because of __null weirdness in gcc-3...
#define NULL_SVAL 0


// package of functions; the user will create an instance of a class
// derived from this, and the parser will carry it along to invoke
// the various action functions
class UserActions {
public:
  // allow abstract user to delete
  virtual ~UserActions();

  // user-supplied reduction actions
  //  - production 'id' is being used to reduce
  //  - 'svals' contains an array of semantic values yielded by the RHS
  //    symbols, such that the 0th element is the leftmost RHS element;
  //    the pointers in the array are owner pointers (the array ptr itself
  //    is a serf)
  //  - 'loc' is the location of the left edge of the parse subtree
  //  - this fn returns the semantic value for the reduction; this return
  //    value is an owner pointer
  typedef SemanticValue (*ReductionActionFunc)(
    UserActions *context,         // parser context class object
    int productionId,             // production being used to reduce
    SemanticValue const *svals    // array of semantic values
    SOURCELOCARG( SourceLoc loc ) );
                                                     
  // get the actual function; two-step to avoid virtual call in inner loop
  virtual ReductionActionFunc getReductionAction()=0;

  // duplication of semantic values:
  //  - the given 'sval' is about to be passed to a reduction action
  //    function.  the user must return a value to be stored in place
  //    of the old one, in case it is needed to pass to another action
  //    function in case of local ambiguity; 'sval' is a serf
  //  - the return value will be yielded (if necessary) to the next
  //    consumer action function, and is an owner ptr
  //  - some possible strategies:
  //    - return NULL, in which case it is probably an error for the
  //      value to be passed to another action (i.e. the grammar needs
  //      to be LALR(1) near this semantic value); in this case, 'del'
  //      will not be called on the NULL value
  //    - increment a reference count and return 'sval'
  //    - do nothing, and rely on some higher-level allocation scheme
  //      such as full GC, or regions
  virtual SemanticValue duplicateTerminalValue(
    int termId, SemanticValue sval)=0;
  virtual SemanticValue duplicateNontermValue(
    int nontermId, SemanticValue sval)=0;

  // a semantic value didn't get passed to an action function, either
  // because it was never used at all (e.g. a semantic value for a
  // punctuator token, which the user can simply ignore), or because we
  // duplicated it in anticipation of a possible local ambiguity, but
  // then that parse turned out not to happen, so we're cancelling
  // the dup now; 'sval' is an owner pointer
  virtual void deallocateTerminalValue(int termId, SemanticValue sval)=0;
  virtual void deallocateNontermValue(int nontermId, SemanticValue sval)=0;

  // this is called when there are two interpretations for the same
  // sequence of ground terminals, culminating in two different reductions
  // deriving the same left-hand-side nonterminal (identified by 'ntIndex');
  // it should return a value to be used in the place where they conflict'
  // both 'left' and 'right' are owner pointers, and the return value
  // is also an owner pointer
  //
  // NOTE: the 'left' value is always the node which came first, and
  // might even have been yielded to another reduction already
  // (depending on the grammar), whereas the 'right' value is always a
  // node which was just created, and has definitely *not* been
  // yielded to anything (this fact is critical to solving the general
  // yield-then-merge problem)
  virtual SemanticValue mergeAlternativeParses(
    int ntIndex, SemanticValue left, SemanticValue right
    SOURCELOCARG( SourceLoc loc )
  )=0;

  // after every reduction, the semantic value is passed to this function,
  // which returns 'false' if the reduction should be cancelled; if it
  // does return false, then 'sval' is an owner pointer (the parser engine
  // will drop the value on the floor)
  virtual bool keepNontermValue(int nontermId, SemanticValue sval)=0;

  // every time a token is pulled from the lexer, this reclassifier is
  // used to give the user a chance to reinterpret the token, before it
  // is used for reduction lookahead comparisons; it returns the
  // reclassified token type, or 'oldTokenType' to leave it unchanged
  typedef int (*ReclassifyFunc)(UserActions *ths, int oldTokenType, SemanticValue sval);

  // get the reclassifier
  virtual ReclassifyFunc getReclassifier()=0;

  // descriptions of symbols with their semantic values; this is useful
  // for the ACTION_TRACE function of the parser
  virtual sm_string terminalDescription(int termId, SemanticValue sval)=0;
  virtual sm_string nonterminalDescription(int nontermId, SemanticValue sval)=0;

  // get static names for all of the symbols
  virtual char const *terminalName(int termId)=0;
  virtual char const *nonterminalName(int termId)=0;

  // get the parse tables for this grammar; the default action
  // complains that no tables are defined
  virtual ParseTables *makeTables();
};


// for derived classes, the list of functions to be declared
// (this macro is used by the generated code)
#define USER_ACTION_FUNCTIONS                                          \
  virtual ReductionActionFunc getReductionAction();                    \
                                                                       \
  virtual SemanticValue duplicateTerminalValue(                        \
    int termId, SemanticValue sval);                                   \
  virtual SemanticValue duplicateNontermValue(                         \
    int nontermId, SemanticValue sval);                                \
                                                                       \
  virtual void deallocateTerminalValue(                                \
    int termId, SemanticValue sval);                                   \
  virtual void deallocateNontermValue(                                 \
    int nontermId, SemanticValue sval);                                \
                                                                       \
  virtual SemanticValue mergeAlternativeParses(                        \
    int ntIndex, SemanticValue left, SemanticValue right               \
    SOURCELOCARG( SourceLoc loc )                                      \
  );                                                                   \
                                                                       \
  virtual bool keepNontermValue(int nontermId, SemanticValue sval);    \
                                                                       \
  virtual ReclassifyFunc getReclassifier();                            \
                                                                       \
  virtual sm_string terminalDescription(int termId, SemanticValue sval);  \
  virtual sm_string nonterminalDescription(int nontermId, SemanticValue sval);  \
                                                                       \
  virtual char const *terminalName(int termId);                        \
  virtual char const *nonterminalName(int termId);


// a useraction class which has only trivial actions
class TrivialUserActions : public UserActions {
public:
  USER_ACTION_FUNCTIONS

  static SemanticValue doReductionAction(
    UserActions *ths,
    int productionId, SemanticValue const *svals
    SOURCELOCARG( SourceLoc loc ) );

  static int reclassifyToken(UserActions *ths, 
    int oldTokenType, SemanticValue sval);
};


#endif // USERACT_H
@h=tangler('elk/elk_util.h')
@select(h)
// util.h            see license.txt for copyright and terms of use
// collection of utility macros and functions that are
// candidates for adding to the smbase library

#ifndef __UTIL_H
#define __UTIL_H

#include "sm_trace.h"

// given a method called 'print', define an operator to use it
#define OSTREAM_OPERATOR(MyClass)                                \
  friend ostream &operator << (ostream &os, MyClass const &ths)  \
    { ths.print(os); return os; }


// I'm experimenting with the idea of making my control structures
// more declarative
#define INTLOOP(var, start, maxPlusOne) \
  for (int var = start; var < maxPlusOne; var++)


// experiment: given (a reference to), an owner pointer, yield the pointer
// value after nullifying the given pointer
template <class T>
inline T *transferOwnership(T *&ptr)
{
  T *ret = ptr;
  ptr = NULL;
  return ret;
}


// print a value under the debug trace (name: Trace VALue)
#define TVAL(expr) \
  trace("debug") << #expr ": " << (expr) << endl


#endif // __UTIL_H
@h=tangler('elk/elk_asockind.cpp')
@select(h)
// asockind.cc            see license.txt for copyright and terms of use
// code for asockind.h

#include "elk_asockind.h"
#include "sm_xassert.h"

sm_string toString(AssocKind k)
{
  static char const * const arr[NUM_ASSOC_KINDS] = {
    "AK_LEFT", "AK_RIGHT", "AK_NONASSOC"
  };
  xassert((unsigned)k < NUM_ASSOC_KINDS);
  return sm_string(arr[k]);
}
@h=tangler('elk/elk_cyctimer.cpp')
@select(h)
// cyctimer.cc            see license.txt for copyright and terms of use
// code for cyctimer.h

#include "elk_cyctimer.h"
#include "sm_cycles.h"
#include "sm_nonport.h"

#include <stdio.h>       // sprintf


CycleTimer::CycleTimer()
{
  // I make the cycle timer the inner of the two, since presumably
  // it's more precise, so shouldn't measure the time taken to issue
  // the getMilliseconds() call (which might involve a system call
  // on some systems)
  startMilliseconds = getMilliseconds();
  startCycles = getCycles_ll();
}


sm_string CycleTimer::elapsed() const
{
  unsigned long long cycles = getCycles_ll() - startCycles;
  unsigned long ms = getMilliseconds() - startMilliseconds;

  // I print the cycles with an underscore separating the millions
  // from the rest because it's easier to read that way (and because
  // on a 1GHz machine, like mine, it's where the decimal point goes
  // when interpreting it as milliseconds)
  char buf[80];
  sprintf(buf, "%lu ms, %llu_%06llu cycles",
               ms, cycles/1000000, cycles%1000000);

  return sm_string(buf);     // makes a copy
}


// --------------------- test code ----------------
#ifdef TEST_CYCTIMER

#include <unistd.h>    // sleep

int main()
{
  {
    CycleTimer timer;
    sm_string s = timer.elapsed();
    printf("short time: %s\n", s.pcharc());
  }

  {
    CycleTimer timer;
    sleep(1);
    sm_string s = timer.elapsed();
    printf("one second: %s\n", s.pcharc());
  }
  
  {
    CycleTimer timer;
    sleep(2);
    sm_string s = timer.elapsed();
    printf("two seconds: %s\n", s.pcharc());
  }

  return 0;
}


#endif // TEST_CYCTIMER
@h=tangler('elk/elk_emitcode.cpp')
@select(h)
// emitcode.cc            see license.txt for copyright and terms of use
// code for emitcode.h

#include "elk_emitcode.h"
#include "sm_syserr.h"
#include "sm_srcloc.h"
#include "sm_trace.h"

EmitCode::EmitCode(char const *f)
  : sm_stringBuilder(),
    os(f),
    fname(f),
    line(1)
{
  if (!os) {
    xsyserror("open", fname);
  }
}

EmitCode::~EmitCode()
{
  flush();
}


int EmitCode::getLine()
{
  flush();
  return line;
}


void EmitCode::flush()
{
  // count newlines
  char const *p = pcharc();
  while (*p) {
    if (*p == '\n') {
      line++;
    }
    p++;
  }

  os << *this;
  setlength(0);
}


char const *hashLine()
{                   
  if (tracingSys("nolines")) {
    // emit with comment to disable its effect
    return "// #line ";
  }
  else {
    return "#line "; 
  }
}


// note that #line must be preceeded by a newline
sm_string lineDirective(SourceLoc loc)
{
  char const *fname;
  int line, col;
  sourceLocManager->decodeLineCol(loc, fname, line, col);

  return sm_stringc << hashLine() << line << " \"" << fname << "\"\n";
}

sm_stringBuilder &restoreLine(sm_stringBuilder &sb)
{
  // little hack..
  EmitCode &os = (EmitCode&)sb;

  // +1 because we specify what line will be *next*
  int line = os.getLine()+1;
  return os << hashLine() << line
            << " \"" << os.getFname() << "\"\n";
}
@h=tangler('elk/elk_genml.cpp')
@select(h)
// genml.cc            see license.txt for copyright and terms of use
// code for genml.h
// first half based on 'emitActionCode' and friends from gramanl.cc
// second half based on 'emitConstructionCode' from parsetables.cc

#include "elk_genml.h"
#include "elk_gramanl.h"
#include "elk_emitcode.h"
#include "elk_parsetables.h"
#include "sm_exc.h"
#include "sm_strutil.h"


// NOTE: The as following code is largely copied from elsewhere,
// including comments, the comments may be in some places not
// perfectly in correspondence with the code.



// prototypes for this section; some of them accept Grammar simply
// because that's all they need; there's no problem upgrading them
// to GrammarAnalysis
void emitMLDescriptions(GrammarAnalysis const &g, EmitCode &out);
void emitMLActionCode(GrammarAnalysis const &g, char const *mliFname,
                      char const *mlFname, char const *srcFname);
void emitMLUserCode(EmitCode &out, LocString const &code, bool braces = true);
void emitMLActions(Grammar const &g, EmitCode &out, EmitCode &dcl);
void emitMLDupDelMerge(GrammarAnalysis const &g, EmitCode &out, EmitCode &dcl);
void emitMLFuncDecl(Grammar const &g, EmitCode &out, EmitCode &dcl,
                    char const *rettype, char const *params);
void emitMLDDMInlines(Grammar const &g, EmitCode &out, EmitCode &dcl,
                      Symbol const &sym);
void emitMLSwitchCode(Grammar const &g, EmitCode &out,
                      char const *signature, char const *switchVar,
                      ObjList<Symbol> const &syms, int whichFunc,
                      char const *templateCode, char const *actUpon);


// ------------- first half: action emission ----------------
#if 0   // not needed
// yield the name of the inline function for this production; naming
// design motivated by desire to make debugging easier
sm_string actionFuncName(Production const &prod)
{
  return sm_stringc << "action" << prod.prodIndex
                 << "_" << prod.left->name;
}                    
#endif // 0


// emit the user's action code to a file
void emitMLActionCode(GrammarAnalysis const &g, char const *mliFname,
                      char const *mlFname, char const *srcFname)
{
  EmitCode dcl(mliFname);
  if (!dcl) {
    throw_XOpen(mliFname);
  }

  // prologue
  dcl << "(* " << mliFname << " *)\n"
      << "(* *** DO NOT EDIT BY HAND *** *)\n"
      << "(* automatically generated by elkhound, from " << srcFname << " *)\n"
      << "\n"
      ;

  // insert the stand-alone verbatim sections
  {FOREACH_OBJLIST(LocString, g.verbatim, iter) {
    emitMLUserCode(dcl, *(iter.data()), false /*braces*/);
  }}

  #if 0    // not implemented
  // insert each of the context class definitions; the last one
  // is the one whose name is 'g.actionClassName' and into which
  // the action functions are inserted as methods
  {
    int ct=0;
    FOREACH_OBJLIST(LocString, g.actionClasses, iter) {
      if (ct++ > 0) {
        // end the previous class; the following body will open
        // another one, and the brace following the action list
        // will close the last one
        dcl << "};\n";
      }

      dcl << "\n"
          << "// parser context class\n"
          << "class ";
      emitUserCode(dcl, *(iter.data()), false /*braces*/);
  }}                         

  // we end the context class with declarations of the action functions
  dcl << "\n"
      << "private:\n"
      << "  USER_ACTION_FUNCTIONS      // see useract.h\n"
      << "\n"
      << "  // declare the actual action function\n"
      << "  static SemanticValue doReductionAction(\n"
      << "    " << g.actionClassName << " *ths,\n"
      << "    int productionId, SemanticValue const *semanticValues"
         SOURCELOC( << ",\n  SourceLoc loc" )
      << ");\n"
      << "\n"
      << "  // declare the classifier function\n"
      << "  static int reclassifyToken(\n"
      << "    " << g.actionClassName << " *ths,\n"
      << "    int oldTokenType, SemanticValue sval);\n"
      << "\n"
      ;
  #endif // 0

  // all that goes into the interface is the name of the
  // tUserActions and tParseTables objects
  dcl << "val " << g.actionClassName << "ParseTables: Parsetables.tParseTables\n";
  dcl << "val " << g.actionClassName << "UserActions: Useract.tUserActions\n";

  EmitCode out(mlFname);
  if (!out) {
    throw_XOpen(mlFname);
  }

  out << "(* " << mlFname << " *)\n";
  out << "(* *** DO NOT EDIT BY HAND *** *)\n";
  out << "(* automatically generated by gramanl, from " << srcFname << " *)\n";
  out << "\n"
      << "open Useract      (* tSemanticValue *)\n"
      << "open Parsetables  (* tParseTables *)\n"
      << "\n"
      << "\n"
      ;
  
  // stand-alone verbatim sections go into .ml file *also*
  {FOREACH_OBJLIST(LocString, g.verbatim, iter) {
    emitMLUserCode(out, *(iter.data()), false /*braces*/);
  }}

  #if 0   // not implemented and/or not needed
    #ifdef NO_GLR_SOURCELOC
      // we need to make sure the USER_ACTION_FUNCTIONS use
      // the declarations consistent with how we're printing
      // the definitions
      out << "#ifndef NO_GLR_SOURCELOC\n";
      out << "  #define NO_GLR_SOURCELOC\n";
      out << "#endif\n";
    #else
      out << "// GLR source location information is enabled\n";
    #endif
    out << "\n";
    out << "#include \"" << hFname << "\"     // " << g.actionClassName << "\n";
    out << "#include \"elk_parsetables.h\" // ParseTables\n";
    out << "#include \"sm_srcloc.h\"      // SourceLoc\n";
    out << "\n";
    out << "#include <assert.h>      // assert\n";
    out << "#include <iostream.h>    // cout\n";
    out << "#include <stdlib.h>      // abort\n";
    out << "\n";

    NOSOURCELOC(
      out << "// parser-originated location information is disabled by\n"
          << "// NO_GLR_SOURCELOC; any rule which refers to 'loc' will get this one\n"
          << "static SourceLoc loc = SL_UNKNOWN;\n"
          << "\n\n";
    )
  #endif // 0

  emitMLDescriptions(g, out);
  // 'emitMLDescriptions' prints two newlines itself..

  emitMLActions(g, out, dcl);
  out << "\n";
  out << "\n";

  emitMLDupDelMerge(g, out, dcl);
  out << "\n";
  out << "\n";

  // wrap all the action stuff up as a struct
  out << "let " << g.actionClassName << "UserActions = {\n";
  #define COPY(name) \
    out << "  " #name " = " #name "Func;\n";
  COPY(reductionAction)
  COPY(duplicateTerminalValue)
  COPY(duplicateNontermValue)
  COPY(deallocateTerminalValue)
  COPY(deallocateNontermValue)
  COPY(mergeAlternativeParses)
  COPY(keepNontermValue)
  COPY(terminalDescription)
  COPY(nonterminalDescription)
  COPY(terminalName)
  COPY(nonterminalName)
  #undef COPY
  out << "}\n"
      << "\n"
      << "\n"
      ;

  g.tables->finishTables();
  g.tables->emitMLConstructionCode(out, g.actionClassName, "makeTables");

  #if 0   // not implemented
    // I put this last in the context class, and make it public
    dcl << "\n"
        << "// the function which makes the parse tables\n"
        << "public:\n"
        << "  virtual ParseTables *makeTables();\n"
        << "};\n"
        << "\n"
        << "#endif // " << latchName << "\n"
        ;
  #endif // 0

  // finish the implementation file with the impl_verbatim sections
  FOREACH_OBJLIST(LocString, g.implVerbatim, iter) {
    emitMLUserCode(out, *(iter.data()), false /*braces*/);
  }
}


void emitMLUserCode(EmitCode &out, LocString const &code, bool braces)
{
  out << "\n";
  if (false/*TODO:fix*/ && code.validLoc()) {
    out << lineDirective(code.loc);
  }

  // 7/27/03: swapped so that braces are inside the line directive
  if (braces) {
    out << "(";
  }

  out << code;

  // the final brace is on the same line so errors reported at the
  // last brace go to user code
  if (braces) {
    out << " )";
  }

  if (false/*TODO:fix*/ && code.validLoc()) {
    out << "\n" << restoreLine;
  }
  else {
    out << "\n";
  }
}


// bit of a hack: map "void" to "SemanticValue" so that the compiler
// won't mind when I try to declare parameters of that type
static char const *notVoid(char const *type)
{
  if (0==strcmp(type, "void")) {     // ML: Q: should this now be "unit"?
    return "tSemanticValue";
  }
  else {
    return type;
  }
}


// yield the given type, but if it's NULL, then yield
// something to use instead
static char const *typeString(char const *type, LocString const &tag)
{
  if (!type) {
    cout << tag.locString() << ": Production tag \"" << tag
         << "\" on a symbol with no type.\n";
    return "__error_no_type__";     // will make compiler complain
  }
  else {
    return notVoid(type);
  }
}


void emitMLDescriptions(GrammarAnalysis const &g, EmitCode &out)
{
  // emit a map of terminal ids to their names
  {
    out << "let termNamesArray: sm_string array = [|\n";
    for (int code=0; code < g.numTerminals(); code++) {
      Terminal const *t = g.getTerminal(code);
      if (!t) {
        // no terminal for that code
        out << "  \"(no terminal)\";  (* " << code << " *)\n";
      }
      else {
        out << "  \"" << t->name << "\";  (* " << code << " *)\n";
      }
    }
    out << "  \"\"   (* dummy final value for ';' separation *)\n"
        << "|]\n"
        << "\n";
  }

  // emit a function to describe terminals; at some point I'd like to
  // extend my grammar format to allow the user to supply
  // token-specific description functions, but for now I will just
  // use the information easily available the synthesize one;
  // I print "sval % 100000" so I get a 5-digit number, which is
  // easy for me to compare for equality without adding much clutter
  //
  // ML: I could do something like this using Obj, but I'd rather
  // not abuse that interface unnecessarily.
  out << "let terminalDescriptionFunc (termId:int) (sval:tSemanticValue) : sm_string =\n"
      << "begin\n"
      << "  termNamesArray.(termId)\n"
      << "end\n"
      << "\n"
      << "\n"
      ;

  // emit a map of nonterminal ids to their names
  {
    out << "let nontermNamesArray: sm_string array = [|\n";
    for (int code=0; code < g.numNonterminals(); code++) {
      Nonterminal const *nt = g.getNonterminal(code);
      if (!nt) {
        // no nonterminal for that code
        out << "  \"(no nonterminal)\";  (* " << code << " *)\n";
      }
      else {
        out << "  \"" << nt->name << "\";  (* " << code << " *)\n";
      }
    }
    out << "  \"\"   (* dummy final value for ';' separation *)\n"
        << "|]\n"
        << "\n";
  }

  // and a function to describe nonterminals also
  out << "let nonterminalDescriptionFunc (nontermId:int) (sval:tSemanticValue)\n"
      << "  : sm_string =\n"
      << "begin\n"
      << "  nontermNamesArray.(nontermId)\n"
      << "end\n"
      << "\n"
      << "\n"
      ;

  // emit functions to get access to the static maps
  out << "let terminalNameFunc (termId:int) : sm_string =\n"
      << "begin\n"
      << "  termNamesArray.(termId)\n"
      << "end\n"
      << "\n"
      << "let nonterminalNameFunc (nontermId:int) : sm_string =\n"
      << "begin\n"
      << "  nontermNamesArray.(nontermId)\n"
      << "end\n"
      << "\n"
      << "\n"
      ;
}


void emitMLActions(Grammar const &g, EmitCode &out, EmitCode &dcl)
{
  out << "(* ------------------- actions ------------------ *)\n"
      << "let reductionActionArray : (tSemanticValue array -> tSemanticValue) array = [|\n"
      << "\n"
      ;

  // iterate over productions, emitting action function closures
  {FOREACH_OBJLIST(Production, g.productions, iter) {
    Production const &prod = *(iter.data());

    // there's no syntax for a typeless nonterminal, so this shouldn't
    // be triggerable by the user
    xassert(prod.left->type);

    // put the production in comments above the defn
    out << "(* " << prod.toString() << " *)\n";

    out << "(fun svals ->\n";

    // iterate over RHS elements, emitting bindings for each with a tag
    int index=-1;
    FOREACH_OBJLIST(Production::RHSElt, prod.right, rhsIter) {
      Production::RHSElt const &elt = *(rhsIter.data());
      index++;
      if (elt.tag.length() == 0) continue;

      // example:
      //   let e1 = (Obj.obj svals.(0) : int) in
      out << "  let " << elt.tag << " = (Obj.obj svals.(" << index << ") : "
          << typeString(elt.sym->type, elt.tag) << ") in\n";
    }
    
    // give a name to the yielded value so we can ensure it conforms to
    // the declared type
    out << "  let __result: " << prod.left->type << " =";

    // now insert the user's code, to execute in this environment of
    // properly-typed semantic values
    emitMLUserCode(out, prod.action, true /*braces*/);

    out << "  in (Obj.repr __result)\n"     // cast to tSemanticValue
        << ");\n"
        << "\n"
        ;
  }}

  // finish the array; one dummy element for ';' separation
  out << "(fun _ -> (failwith \"bad production index\"))   (* no ; *)"
      << "\n"
      << "|]\n"
      << "\n"  
      ;

  // main action function; uses the array emitted above
  out << "let reductionActionFunc (productionId:int) (svals: tSemanticValue array)\n"
      << "  : tSemanticValue =\n"
      << "begin\n"
      << "  (reductionActionArray.(productionId) svals)\n"
      << "end\n"
      << "\n"
      ;


  #if 0  // shouldn't be needed
  if (0==strcmp(prod.left->type, "void")) {
    // cute hack: turn the expression into a comma expression, with
    // the value returned being 0
    out << ", 0";
  }
  #endif // 0
}


void emitMLDupDelMerge(GrammarAnalysis const &g, EmitCode &out, EmitCode &dcl)
{
  out << "(* ---------------- dup/del/merge/keep nonterminals --------------- *)\n"
      << "\n";

  // emit inlines for dup/del/merge of nonterminals
  FOREACH_OBJLIST(Nonterminal, g.nonterminals, ntIter) {
    emitMLDDMInlines(g, out, dcl, *(ntIter.data()));
  }

  // emit dup-nonterm
  emitMLSwitchCode(g, out,
    "let duplicateNontermValueFunc (nontermId:int) (sval:tSemanticValue) : tSemanticValue",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    0 /*dupCode*/,
    "      (Obj.repr (dup_$symName ((Obj.obj sval) : $symType)))\n",
    NULL);

  // emit del-nonterm
  emitMLSwitchCode(g, out,
    "let deallocateNontermValueFunc (nontermId:int) (sval:tSemanticValue) : unit",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    1 /*delCode*/,
    "      (del_$symName ((Obj.obj sval) : $symType));\n",
    "deallocate nonterm");

  // emit merge-nonterm
  emitMLSwitchCode(g, out,
    "let mergeAlternativeParsesFunc (nontermId:int) (left:tSemanticValue)\n"
    "                               (right:tSemanticValue) : tSemanticValue",
    // SOURCELOC?
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    2 /*mergeCode*/,
    "      (Obj.repr (merge_$symName ((Obj.obj left) : $symType) ((Obj.obj right) : $symType)))\n",
    "merge nonterm");

  // emit keep-nonterm
  emitMLSwitchCode(g, out,
    "let keepNontermValueFunc (nontermId:int) (sval:tSemanticValue) : bool",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    3 /*keepCode*/,
    "      (keep_$symName ((Obj.obj sval) : $symType))\n",
    NULL);


  out << "\n";
  out << "(* ---------------- dup/del/classify terminals --------------- *)";
  // emit inlines for dup/del of terminals
  FOREACH_OBJLIST(Terminal, g.terminals, termIter) {
    emitMLDDMInlines(g, out, dcl, *(termIter.data()));
  }

  // emit dup-term
  emitMLSwitchCode(g, out,
    "let duplicateTerminalValueFunc (termId:int) (sval:tSemanticValue) : tSemanticValue",
    "termId",
    (ObjList<Symbol> const&)g.terminals,
    0 /*dupCode*/,
    "      (Obj.repr (dup_$symName ((Obj.obj sval) : $symType)))\n",
    NULL);

  // emit del-term
  emitMLSwitchCode(g, out,
    "let deallocateTerminalValueFunc (termId:int) (sval:tSemanticValue) : unit",
    "termId",
    (ObjList<Symbol> const&)g.terminals,
    1 /*delCode*/,
    "      (del_$symName ((Obj.obj sval) : $symType));\n",
    "deallocate terminal");

  // emit classify-term
  emitMLSwitchCode(g, out,
    "let reclassifyTokenFunc (oldTokenType:int) (sval:tSemanticValue) : int",
    "oldTokenType",
    (ObjList<Symbol> const&)g.terminals,
    4 /*classifyCode*/,
    "      (classify_$symName ((Obj.obj sval) : $symType))\n",
    NULL);
}


// emit both the function decl for the .h file, and the beginning of
// the function definition for the .cc file
void emitMLFuncDecl(Grammar const &g, EmitCode &out, EmitCode &dcl,
                    char const *rettype, char const *params)
{
  out << "(*inline*) let " << params << ": " << rettype << " =";
}


void emitMLDDMInlines(Grammar const &g, EmitCode &out, EmitCode &dcl,
                      Symbol const &sym)
{
  Terminal const *term = sym.ifTerminalC();
  Nonterminal const *nonterm = sym.ifNonterminalC();

  if (sym.dupCode) {
    emitMLFuncDecl(g, out, dcl, sym.type,
      sm_stringc << "dup_" << sym.name
              << " (" << sym.dupParam << ": " << sym.type << ") ");
    emitMLUserCode(out, sym.dupCode);
    out << "\n";
  }

  if (sym.delCode) {
    emitMLFuncDecl(g, out, dcl, "unit",
      sm_stringc << "del_" << sym.name
              << " (" << (sym.delParam? sym.delParam : "_")
              << ": " << sym.type << ") ");
    emitMLUserCode(out, sym.delCode);
    out << "\n";
  }

  if (nonterm && nonterm->mergeCode) {
    emitMLFuncDecl(g, out, dcl, notVoid(sym.type),
      sm_stringc << "merge_" << sym.name
              << " (" << nonterm->mergeParam1 << ": " << notVoid(sym.type) << ") "
              << " (" << nonterm->mergeParam2 << ": " << notVoid(sym.type) << ") ");
    emitMLUserCode(out, nonterm->mergeCode);
    out << "\n";
  }

  if (nonterm && nonterm->keepCode) {
    emitMLFuncDecl(g, out, dcl, "bool",
      sm_stringc << "keep_" << sym.name
              << " (" << nonterm->keepParam << ": " << sym.type << ") ");
    emitMLUserCode(out, nonterm->keepCode);
    out << "\n";
  }

  if (term && term->classifyCode) {
    emitMLFuncDecl(g, out, dcl, "int",
      sm_stringc << "classify_" << sym.name
              << " (" << term->classifyParam << ": " << sym.type << ") ");
    emitMLUserCode(out, term->classifyCode);
    out << "\n";
  }
}

void emitMLSwitchCode(Grammar const &g, EmitCode &out,
                      char const *signature, char const *switchVar,
                      ObjList<Symbol> const &syms, int whichFunc,
                      char const *templateCode, char const *actUpon)
{
  out << replace(signature, "$acn", g.actionClassName) << " =\n"
         "begin\n"
         "  match " << switchVar << " with\n"
         ;

  FOREACH_OBJLIST(Symbol, syms, symIter) {
    Symbol const &sym = *(symIter.data());

    if (whichFunc==0 && sym.dupCode ||
        whichFunc==1 && sym.delCode ||
        whichFunc==2 && sym.asNonterminalC().mergeCode ||
        whichFunc==3 && sym.asNonterminalC().keepCode ||
        whichFunc==4 && sym.asTerminalC().classifyCode) {
      out << "  | " << sym.getTermOrNontermIndex() << " -> (\n";
      out << replace(replace(templateCode,
               "$symName", sym.name),
               "$symType", notVoid(sym.type));
      out << "    )\n";
    }
  }

  out << "  | _ -> (\n";
  switch (whichFunc) {
    default:
      xfailure("bad func code");

    // in ML it's not such a good idea to yield cNULL_SVAL, since the
    // runtime engine might get more confused than a C program
    // with a NULL pointer.. so always do the gc-defaults thing

    case 0:    // unspecified dup
      out << "      sval\n";
      break;

    case 1:    // unspecified del
      // ignore del
      out << "      ()\n";
      break;

    case 2:    // unspecified merge: warn, but then use left (arbitrarily)
      out << "      (Printf.printf \"WARNING: no action to merge nonterm %s\\n\"\n"
          << "                     nontermNamesArray.(" << switchVar << "));\n"
          << "      (flush stdout);\n"
          << "      left\n"
          ;
      break;

    case 3:    // unspecified keep: keep it
      out << "      true\n";
      break;

    case 4:    // unspecified classifier: identity map
      out << "      oldTokenType\n";
      break;
  }

  out << "    )\n"
         "end\n"
         "\n";
}


// ----------------- second half: table emission ------------------
// create literal tables
template <class EltType>
void emitMLTable(EmitCode &out, EltType const *table, int size, int rowLength,
                 char const *tableName)
{
  if (!table || !size) {
    out << "  " << tableName << " = [| |];      (* 0 elements *)\n"
        << "\n"
        ;
    return;
  }

  bool printHex = false;
  #if 0   // not needed?
                  0==strcmp(typeName, "ErrorBitsEntry") ||
                  (ENABLE_CRS_COMPRESSION && 0==strcmp(typeName, "ActionEntry")) ||
                  (ENABLE_CRS_COMPRESSION && 0==strcmp(typeName, "GotoEntry")) ;
  bool needCast = 0==strcmp(typeName, "StateId");
  #endif // 0

  if (size * sizeof(*table) > 50) {    // suppress small ones
    //out << "  // storage size: " << size * sizeof(*table) << " bytes\n";
    if (size % rowLength == 0) {
      out << "  (* rows: " << (size/rowLength) << "  cols: " << rowLength << " *)\n";
    }
  }

  int rowNumWidth = sm_stringf("%d", size / rowLength /*round down*/).length();

  out << "  " << tableName << " = [|           (* " << size << " elements *)";
  int row = 0;
  for (int i=0; i<size; i++) {
    if (i % rowLength == 0) {    // one row per state
      out << sm_stringf("\n    (*%*d*) ", rowNumWidth, row++);
    }

    #if 0
    if (needCast) {
      out << "(" << typeName << ")";           // ML: not used
    }    
    #endif // 0

    if (printHex) {
      out << sm_stringf("0x%02X", table[i]);    // ML: not used
    }
    else if (sizeof(table[i]) == 1) {
      // little bit of a hack to make sure 'unsigned char' gets
      // printed as an int; the casts are necessary because this
      // code gets compiled even when EltType is ProdInfo
      out << (int)(*((unsigned char*)(table+i)));
    }
    else {
      // print the other int-sized things, or ProdInfo using
      // the overloaded '<<' below
      out << table[i];
    }

    if (i != size-1) {
      out << "; ";
    }
  }
  out << "\n"
      << "  |];\n"
      << "\n"
      ;
}

#if 0   // not used
// used to emit the elements of the prodInfo table
sm_stringBuilder& operator<< (sm_stringBuilder &sb, ParseTables::ProdInfo const &info)
{
  sb << "{" << (int)info.rhsLen << "," << (int)info.lhsIndex << "}";
  return sb;
}


// like 'emitTable', but also set a local called 'tableName'
template <class EltType>
void emitMLTable2(EmitCode &out, EltType const *table, int size, int rowLength,
                  char const *typeName, char const *tableName)
{
  sm_string tempName = sm_stringc << tableName << "_static";
  emitMLTable(out, table, size, rowLength, typeName, tempName);
  out << "  " << tableName << " = const_cast<" << typeName << "*>("
      << tempName << ");\n\n";
}


template <class EltType>
void emitMLOffsetTable(EmitCode &out, EltType **table, EltType *base, int size,
                       char const *typeName, char const *tableName, char const *baseName)
{
  if (!table) {
    out << "  " << tableName << " = NULL;\n\n";
    return;
  }

  // make the pointers persist by storing a table of offsets
  Array<int> offsets(size);
  bool allUnassigned = true;
  for (int i=0; i < size; i++) {
    if (table[i]) {
      offsets[i] = table[i] - base;
      allUnassigned = false;
    }
    else {
      offsets[i] = UNASSIGNED;    // codes for a NULL entry
    }
  }

  if (allUnassigned) {
    // for example, an LALR(1) grammar has no ambiguous entries in its tables
    size = 0;
  }

  if (size > 0) {
    out << "  " << tableName << " = new " << typeName << " [" << size << "];\n";

    emitTable(out, (int*)offsets, size, 16, "int", sm_stringc << tableName << "_offsets");

    // at run time, interpret the offsets table
    out << "  for (int i=0; i < " << size << "; i++) {\n"
        << "    int ofs = " << tableName << "_offsets[i];\n"
        << "    if (ofs >= 0) {\n"
        << "      " << tableName << "[i] = " << baseName << " + ofs;\n"
        << "    }\n"
        << "    else {\n"
        << "      " << tableName << "[i] = NULL;\n"
        << "    }\n"
        << "  }\n\n";
  }
  else {
    out << "  // offset table is empty\n"
        << "  " << tableName << " = NULL;\n\n";
  }
}


// for debugging
template <class EltType>
void printMLTable(EltType const *table, int size, int rowLength,
                  char const *typeName, char const *tableName)
{
  // disabled for now since I don't need it anymore, and it adds
  // a link dependency on emitcode.cc ...
  #if 0
  {
    EmitCode out("printTable.tmp");
    emitTable(out, table, size, rowLength, typeName, tableName);
  }

  system("cat printTable.tmp; rm printTable.tmp");
  #endif // 0
}
#endif // 0


// emit code for a function which, when compiled and executed, will
// construct this same table (except the constructed table won't own
// the table data, since it will point to static program data)
void ParseTables::emitMLConstructionCode
  (EmitCode &out, char const *className, char const *funcName)
{
  // must have already called 'finishTables'
  xassert(!temp);

  out << "(* a literal tParseTables;\n"
      << " * the code is written by ParseTables::emitConstructionCode()\n"
      << " * in " << __FILE__ << " *)\n"
      << "let " << className << "ParseTables:tParseTables = {\n";
      ;

  #define SET_VAR(var) \
    out << "  " #var " = " << var << ";\n";

  SET_VAR(numTerms);
  SET_VAR(numNonterms);
  SET_VAR(numProds);
  out << "\n";

  SET_VAR(numStates);
  out << "\n";

  SET_VAR(actionCols);
  emitMLTable(out, actionTable, actionTableSize(),
              actionCols, "actionTable");

  SET_VAR(gotoCols);
  emitMLTable(out, gotoTable, gotoTableSize(),
              gotoCols, "gotoTable");

  // break the prodInfo into two arrays
  {
    Array<int> rhsLen(numProds);
    Array<int> lhsIndex(numProds);

    for (int i=0; i < numProds; i++) {
      rhsLen[i] = prodInfo[i].rhsLen;
      lhsIndex[i] = prodInfo[i].lhsIndex;
    }

    emitMLTable(out, rhsLen.operator int const *(), numProds,
                16 /*columns; arbitrary*/, "prodInfo_rhsLen");
    emitMLTable(out, lhsIndex.operator int const *(), numProds,
                16 /*columns; arbitrary*/, "prodInfo_lhsIndex");
  }

  emitMLTable(out, stateSymbol, numStates,
              16, "stateSymbol");
              
  SET_VAR(ambigTableSize);
  emitMLTable(out, ambigTable, ambigTableSize,
              16, "ambigTable");
              
  emitMLTable(out, nontermOrder, nontermOrderSize(),
              16, "nontermOrder");

  SET_VAR(startState);                                              
  
  // no semicolon for last one
  out << "  finalProductionIndex = " << finalProductionIndex << "\n";
  
  out << "}\n"
      << "\n"
      ;
}


// EOF
@h=tangler('elk/elk_glr.cpp')
@select(h)
// glr.cc            see license.txt for copyright and terms of use
// code for glr.h

/* Implementation Notes
 *
 * A design point: [GLR] uses more 'global's than I do.  My criteria
 * here is that something should be global (stored in class GLR) if
 * it has meaning between processing of tokens.  If something is only
 * used during the processing of a single token, then I make it a
 * parameter where necessary.
 *
 * Update: I've decided to make 'currentToken' and 'parserWorklist'
 * global because they are needed deep inside of 'glrShiftNonterminal',
 * though they are not needed by the intervening levels, and their
 * presence in the argument lists would therefore only clutter them.
 *
 * (OLD) It should be clear that many factors contribute to this
 * implementation being slow, and I'm going to refrain from any
 * optimization for a bit.
 *
 * UPDATE (3/29/02): I'm now trying to optimize it.  The starting
 * implementation is 300x slower than bison.  Ideal goal is 3x, but
 * more realistic is 10x.
 *
 * UPDATE (8/24/02): It's very fast now; within 3% of Bison for
 * deterministic grammars, and 5x when I disable the mini-LR core.
 *
 * Description of the various lists in play here:
 *
 *   topmostParsers
 *   --------------
 *   The active parsers are at the frontier of the parse tree
 *   space.  It *never* contains more than one stack node with
 *   a given parse state; I call this the unique-state property
 *   (USP).  If we're about to add a stack node with the same
 *   state as an existing node, we merge them (if it's a shift,
 *   we add another leftAdjState; if it's a reduction, we add a
 *   rule node *and* another leftAdjState).
 *
 *   Before a token is processed, topmostParsers contains those
 *   parsers that successfully shifted the previous token.  This
 *   list is then walked to make the initial reduction worklist.
 *
 *   Before the shifts are processed, the topmostParsers list is
 *   cleared.  As each shift is processed, the resulting parser is
 *   added to topmostParsers (modulo USP).
 *
 *   [GLR] calls this "active-parsers"
 *
 * 
 * Discussion of path re-examination, called do-limited-reductions by
 * [GLR]:
 *
 * After thinking about this for some time, I have reached the conclusion
 * that the only way to handle the problem is to separate the collection
 * of paths from the iteration over them.
 *
 * Here are several alternative schemes, and the reasons they don't
 * work:
 *
 *   1. [GLR]'s approach of limiting re-examination to those involving
 *      the new link
 *
 *      This fails because it does not prevent re-examined paths
 *      from appearing in the normal iteration also.
 *
 *   2. Modify [GLR] so the new link can't be used after the re-examination
 *      is complete
 *
 *      Then if *another* new link is added, paths involving both new
 *      links wouldn't be processed.
 *
 *   3. Further schemes involving controlling which re-examination stage can
 *      use which links
 *
 *      Difficult to reason about, unclear a correct scheme exists, short
 *      of the full-blown path-listing approach I'm going to take.
 *
 *   4. My first "fix" which assumes there is never more than one path to
 *      a given parser
 *
 *      This is WRONG.  There can be more than one path, even as all such
 *      paths are labeled the same (namely, with the RHS symbols).  Consider
 *      grammar "E -> x | E + E" parsing "x+x+x": both toplevel parses use
 *      the "E -> E + E" rule, and both arrive at the root parser
 *
 * So, the solution I will implement is to collect all paths into a list
 * before processing any of them.  During path re-examination, I also will
 * collect paths into a list, this time only those that involve the new
 * link.
 *
 * This scheme is clearly correct, since path collection cannot be disrupted
 * by the process of adding links, and when links are added, exactly the new
 * paths are collected and processed.  It's easy to see that every path is
 * considered exactly once.
 *
 *
 * MAJOR UPDATE (12/06/02):  I've replaced the state worklist (SWL) core
 * used in all previous GLR implementations with a reduction worklist (RWL)
 * core.  This core is just as fast, but can be implemented to always
 * avoid the yield-then-merge problem for acyclic grammars.
 *
 *
 * Below, parse-tree building activity is marked "TREEBUILD".
 */


#include "elk_glr.h"
#include "sm_strtokp.h"
#include "sm_syserr.h"
#include "sm_trace.h"
#include "sm_strutil.h"
#include "elk_lexerint.h"
#include "sm_test.h"
#include "elk_cyctimer.h"
#include "sm_sobjlist.h"
#include "sm_owner.h"

#include <stdio.h>       // FILE
#include <stdlib.h>      // getenv

// ACTION(..) is code to execute for action trace diagnostics, i.e. "-tr action"
#ifndef ACTION_TRACE
  #define ACTION_TRACE 0
#endif
#if ACTION_TRACE
  #define ACTION(stmt) stmt
  #define TRSACTION(stuff) if (tracingSys("action")) { cout << stuff << endl; }
#else
  #define ACTION(stmt)
  #define TRSACTION(stuff)
#endif

// TRSPARSE(stuff) traces <stuff> during debugging with -tr parse
#if !defined(NDEBUG)
  #define IF_NDEBUG(stuff)
  #define TRSPARSE(stuff) if (trParse) { trsParse << stuff << endl; }
  #define TRSPARSE_DECL(stuff) stuff
#else
  #define IF_NDEBUG(stuff) stuff
  #define TRSPARSE(stuff)
  #define TRSPARSE_DECL(stuff)
#endif

// whether to use the ordinary LR core in addition to the GLR core
#ifndef USE_MINI_LR
  #define USE_MINI_LR 1
#endif

// these disable features of mini-LR for performance testing
#ifndef USE_ACTIONS
  #define USE_ACTIONS 1
#endif
#ifndef USE_RECLASSIFY
  #define USE_RECLASSIFY 1
#endif
#ifndef USE_KEEP
  #define USE_KEEP 1
#endif

// enables tracking of some statistics useful for debugging and profiling
#ifndef DO_ACCOUNTING
  #define DO_ACCOUNTING 1
#endif
#if DO_ACCOUNTING
  #define ACCOUNTING(stuff) stuff
#else
  #define ACCOUNTING(stuff)
#endif

// unroll the inner loop; approx. 3% performance improvement
// update: right now, it actually *costs* about 8%..
#ifndef USE_UNROLLED_REDUCE
  #define USE_UNROLLED_REDUCE 0
#endif

// some things we track..
int parserMerges = 0;
int computeDepthIters = 0;
int totalExtracts = 0;
int multipleDelayedExtracts = 0;

// can turn this on to experiment.. but right now it
// actually makes things slower.. (!)
//#define USE_PARSER_INDEX


// Note on inlining generally: Inlining functions is a very important
// way to improve performance, in inner loops.  However it's easy to
// guess wrong about where and what to inline.  So generally I mark
// things as inline whenver the profiler (gprof) reports:
//   - it's showing up in gprof as a function call (i.e. not already
//     being inlined)
//   - the function that calls it takes significant time
//   - the call itself takes significant time
// All this is obvious, but is worth saying, since otherwise the
// tendency is to inline everything, which is a mistake because it
// makes the system as a whole slower (by wasting space in the I-cache)
// without leaving a clear indicator of who is to blame (it's very
// hard to profile for over-aggressive inlining).


// the transition to array-based implementations requires I specify
// initial sizes
enum {
  // this one does *not* grow as needed (at least not in the mini-LR core)
  MAX_RHSLEN = 30,

  // ----------
  // the settings below here are for initial sizes of growable arrays,
  // and it should be ok in terms of correctness to set them all to 1,
  // which may be a useful thing during debugging to verify

  // this one grows as needed
  TYPICAL_MAX_REDUCTION_PATHS = 5,

  // this is the length to make arrays which hold rhsLen many items
  // typically, but are growable
  INITIAL_RHSLEN_SIZE = 10,
};


// ------------- front ends to user code ---------------
// given a symbol id (terminal or nonterminal), and its associated
// semantic value, yield a description sm_string
sm_string symbolDescription(SymbolId sym, UserActions *user, 
                         SemanticValue sval)
{
  if (symIsTerm(sym)) {
    return user->terminalDescription(symAsTerm(sym), sval);
  }
  else {
    return user->nonterminalDescription(symAsNonterm(sym), sval);
  }
}

SemanticValue GLR::duplicateSemanticValue(SymbolId sym, SemanticValue sval)
{
  xassert(sym != 0);
  
  // 6/23/04: Why did I do this?  Some kind of optimization?  It should
  // at least be documented... and probably removed altogether.
  if (!sval) return sval;

  SemanticValue ret;
  if (symIsTerm(sym)) {
    ret = userAct->duplicateTerminalValue(symAsTerm(sym), sval);
  }
  else {
    ret = userAct->duplicateNontermValue(symAsNonterm(sym), sval);
  }

  TRSACTION("  " << symbolDescription(sym, userAct, ret) <<
            " is DUP of " <<
            symbolDescription(sym, userAct, sval));

  return ret;
}

void deallocateSemanticValue(SymbolId sym, UserActions *user,
                             SemanticValue sval)
{
  xassert(sym != 0);
  TRSACTION("  DEL " << symbolDescription(sym, user, sval));

  if (!sval) return;

  if (symIsTerm(sym)) {
    return user->deallocateTerminalValue(symAsTerm(sym), sval);
  }
  else {
    return user->deallocateNontermValue(symAsNonterm(sym), sval);
  }
}

void GLR::deallocateSemanticValue(SymbolId sym, SemanticValue sval)
{
  ::deallocateSemanticValue(sym, userAct, sval);
}


// ------------------ SiblingLink ------------------
inline SiblingLink::SiblingLink(StackNode *s, SemanticValue sv
                                SOURCELOCARG( SourceLoc L ) )
  : sib(s), sval(sv)
    SOURCELOCARG( loc(L) )
{
  YIELD_COUNT( yieldCount = 0; )
}

SiblingLink::~SiblingLink()
{}


// ----------------------- StackNode -----------------------
int StackNode::numStackNodesAllocd=0;
int StackNode::maxStackNodesAllocd=0;


StackNode::StackNode()
  : state(STATE_INVALID),
    leftSiblings(),
    firstSib(NULL, NULL_SVAL  SOURCELOCARG( SL_UNKNOWN ) ),
    referenceCount(0),
    determinDepth(0),
    glr(NULL)
{
  // the interesting stuff happens in init()
}

StackNode::~StackNode()
{
  // the interesting stuff happens in deinit()
}


inline void StackNode::init(StateId st, GLR *g)
{
  state = st;
  xassertdb(leftSiblings.isEmpty());
  xassertdb(hasZeroSiblings());
  referenceCount = 0;
  determinDepth = 1;    // 0 siblings now, so this node is unambiguous
  glr = g;

  #if DO_ACCOUNTING
    INC_HIGH_WATER(numStackNodesAllocd, maxStackNodesAllocd);
    //TRACE("nodes", "(!!!) init stack node: num=" << numStackNodesAllocd
    //            << ", max=" << maxStackNodesAllocd);
  #endif
}

inline void StackNode::decrementAllocCounter()
{
  #if DO_ACCOUNTING
    numStackNodesAllocd--;
    //TRACE("nodes", "(...) deinit stack node: num=" << numStackNodesAllocd
    //            << ", max=" << maxStackNodesAllocd);
  #endif
}

inline void StackNode::deinit()
{
  decrementAllocCounter();

  if (!unwinding()) {
    xassert(numStackNodesAllocd >= 0);
    xassert(referenceCount == 0);
  }

  deallocSemanticValues();

  // this is pulled out of 'deallocSemanticValues' since dSV gets
  // called from the mini-LR parser, which sets this to NULL itself
  // (and circumvents the refct decrement)
  firstSib.sib = NULL;
}

inline SymbolId StackNode::getSymbolC() const
{
  xassertdb((unsigned)state < (unsigned)(glr->tables->getNumStates()));
  return glr->tables->getStateSymbol(state);
}



void StackNode::deallocSemanticValues()
{
  // explicitly deallocate siblings, so I can deallocate their
  // semantic values if necessary (this requires knowing the
  // associated symbol, which the SiblingLinks don't know)
  if (firstSib.sib != NULL) {
    deallocateSemanticValue(getSymbolC(), glr->userAct, firstSib.sval);
  }

  while (leftSiblings.isNotEmpty()) {
    Owner<SiblingLink> sib(leftSiblings.removeAt(0));
    deallocateSemanticValue(getSymbolC(), glr->userAct, sib->sval);
  }
}


// add the very first sibling
inline void StackNode
  ::addFirstSiblingLink_noRefCt(StackNode *leftSib, SemanticValue sval
                                SOURCELOCARG( SourceLoc loc ) )
{
  xassertdb(hasZeroSiblings());

  // my depth will be my new sibling's depth, plus 1
  determinDepth = leftSib->determinDepth + 1;

  // we don't have any siblings yet; use embedded
  // don't update reference count of 'leftSib', instead caller must do so
  //firstSib.sib = leftSib;
  xassertdb(firstSib.sib == NULL);      // otherwise we'd miss a decRefCt
  firstSib.sib.setWithoutUpdateRefct(leftSib);

  firstSib.sval = sval;

  // initialize some other fields
  SOURCELOC( firstSib.loc = loc; )
  YIELD_COUNT( firstSib.yieldCount = 0; )
}


// add a new sibling by creating a new link
inline SiblingLink *StackNode::
  addSiblingLink(StackNode *leftSib, SemanticValue sval
                 SOURCELOCARG( SourceLoc loc ) )
{
  if (hasZeroSiblings()) {
    addFirstSiblingLink_noRefCt(leftSib, sval  SOURCELOCARG( loc ) );

    // manually increment leftSib's refct
    leftSib->incRefCt();

    // sibling link pointers are used to control the reduction
    // process in certain corner cases; an interior pointer
    // should work fine
    return &firstSib;
  }
  else {
    // as best I can tell, x86 static branch prediction is simply
    // "conditional forward branches are assumed not taken", hence
    // the uncommon case belongs in the 'else' branch
    return addAdditionalSiblingLink(leftSib, sval  SOURCELOCARG( loc ) );
  }
}


// pulled out of 'addSiblingLink' so I can inline addSiblingLink
// without excessive object code bloat; the branch represented by
// the code in this function is much less common
SiblingLink *StackNode::
  addAdditionalSiblingLink(StackNode *leftSib, SemanticValue sval
                           SOURCELOCARG( SourceLoc loc ) )
{
  // there's currently at least one sibling, and now we're adding another;
  // right now, no other stack node should point at this one (if it does,
  // most likely will catch that when we use the stale info)
  determinDepth = 0;

  SiblingLink *link = new SiblingLink(leftSib, sval  SOURCELOCARG( loc ) );
  leftSiblings.prepend(link);   // dsw: don't append; it becomes quadratic!
  return link;
}


// inlined for the GLR part; mini-LR doesn't use this directly;
// gcc will inline the first level, even though it's recursive,
// and the effect is significant (~10%) for GLR-only parser
inline void StackNode::decRefCt()
{
  xassert(referenceCount > 0);
  
  //printf("decrementing node %d to %d\n", state, referenceCount-1);

  if (--referenceCount == 0) {
    glr->stackNodePool->dealloc(this);
  }
}


SiblingLink const *StackNode::getUniqueLinkC() const
{
  xassert(hasOneSibling());
  return &firstSib;
}


SiblingLink *StackNode::getLinkTo(StackNode *another)
{
  // check first..
  if (firstSib.sib == another) {
    return &firstSib;
  }

  // check rest
  MUTATE_EACH_OBJLIST(SiblingLink, leftSiblings, sibIter) {
    SiblingLink *candidate = sibIter.data();
    if (candidate->sib == another) {
      return candidate;
    }
  }
  return NULL;
}


STATICDEF void StackNode::printAllocStats()
{
  cout << "stack nodes: " << numStackNodesAllocd
       << ", max stack nodes: " << maxStackNodesAllocd
       << endl;
}


int StackNode::computeDeterminDepth() const
{
  if (hasZeroSiblings()) {
    return 1;
  }
  else if (hasOneSibling()) {
    // it must be equal to sibling's, plus one
    return firstSib.sib->determinDepth + 1;
  }
  else {
    xassert(hasMultipleSiblings());
    return 0;
  }
}


// I sprinkle calls to this here and there; in NDEBUG mode
// they'll all disappear
inline void StackNode::checkLocalInvariants() const
{
  xassertdb(computeDeterminDepth() == determinDepth);
}


// ------------- stack node list ops ----------------
void decParserList(ArrayStack<StackNode*> &list)
{
  for (int i=0; i < list.length(); i++) {
    list[i]->decRefCt();
  }
}

void incParserList(ArrayStack<StackNode*> &list)
{
  for (int i=0; i < list.length(); i++) {
    list[i]->incRefCt();
  }
}

// candidate for adding to ArrayStack.. but I'm hesitant for some reason
bool parserListContains(ArrayStack<StackNode*> &list, StackNode *node)
{
  for (int i=0; i < list.length(); i++) {
    if (list[i] == node) {
      return true;
    }
  }
  return false;
}


// ------------------------- GLR ---------------------------
GLR::GLR(UserActions *user, ParseTables *t)
  : userAct(user),
    tables(t),
    lexerPtr(NULL),
    topmostParsers(),
    parserIndex(NULL),
    toPass(MAX_RHSLEN),
    prevTopmost(),
    stackNodePool(NULL),
    pathQueue(t),
    noisyFailedParse(true),
    trParse(tracingSys("parse")),
    trsParse(trace("parse") << "parse tracing enabled\n"),
    detShift(0),
    detReduce(0),
    nondetShift(0),
    nondetReduce(0),
    yieldThenMergeCt(0)
  // some fields (re-)initialized by 'clearAllStackNodes'
{
  // originally I had this inside glrParse() itself, but that
  // made it 25% slower!  gcc register allocator again!
  if (tracingSys("glrConfig")) {
    printConfig();
  }

  // the ordinary GLR core doesn't have this limitation because
  // it uses a growable array
  #if USE_MINI_LR
    // make sure none of the productions have right-hand sides
    // that are too long; I think it's worth doing an iteration
    // here since going over the limit would be really hard to
    // debug, and this ctor is of course outside the main
    // parsing loop
    for (int i=0; i < tables->getNumProds(); i++) {
      if (tables->getProdInfo(i).rhsLen > MAX_RHSLEN) {
        printf("Production %d contains %d right-hand side symbols,\n"
               "but the GLR core has been compiled with a limit of %d.\n"
               "Please adjust MAX_RHSLEN and recompile the GLR core.\n",
               i, tables->getProdInfo(i).rhsLen, MAX_RHSLEN);
        xfailure("cannot continue");
      }
    }
  #endif // USE_MINI_LR

  // check that the parse tables' compression (if any) is the same
  // as this core expects
  configCheck("EEF compression", ENABLE_EEF_COMPRESSION, tables->eef_enabled());
  configCheck("GCS compression", ENABLE_GCS_COMPRESSION, tables->gcs_enabled());
  configCheck("GCS column compression", ENABLE_GCS_COLUMN_COMPRESSION, tables->gcsc_enabled());
  configCheck("CRS compression", ENABLE_CRS_COMPRESSION, tables->crs_enabled());
}

void GLR::configCheck(char const *option, bool core, bool table)
{
  if (core != table) {
    xfailure(sm_stringc
      << "The GLR parser core was compiled with " << option
      << (core? " enabled" : " disabled")
      << ", but the parse tables generated by Elkhound have it "
      << (table? "enabled" : "disabled"));
  }
}

GLR::~GLR()
{
  if (parserIndex) {
    delete[] parserIndex;
  }

  // NOTE: must not delete 'tables' until after the 'decParserList'
  // calls above, because they refer to the tables!
}


void GLR::clearAllStackNodes()
{
  // the stack nodes themselves are now reference counted, so they
  // should already be cleared if we're between parses (modulo
  // creation of cycles, which I currently just ignore and allow to
  // leak..)
}


// print compile-time configuration; this is useful for making
// sure a given binary has been compiled the way you think
void GLR::printConfig() const
{
  printf("GLR configuration follows.  Settings marked with an\n"
         "asterisk (*) are the higher-performance settings.\n");

  printf("  source location information: \t\t\t%s\n",
         SOURCELOC(1+)0? "enabled" : "disabled *");

  printf("  stack node columns: \t\t\t\t%s\n",
         NODE_COLUMN(1+)0? "enabled" : "disabled *");

  printf("  semantic value yield count: \t\t\t%s\n",
         YIELD_COUNT(1+)0? "enabled" : "disabled *");

  printf("  ACTION_TRACE (for debugging): \t\t%s\n",
         ACTION(1+)0? "enabled" : "disabled *");

  printf("  NDEBUG: \t\t\t\t\t%s\n",
         IF_NDEBUG(1+)0? "set      *" : "not set");

  printf("  xassert-style assertions: \t\t\t%s\n",
         #ifdef NDEBUG_NO_ASSERTIONS
           "disabled *"
         #else
           "enabled"
         #endif
         );

  printf("  user actions: \t\t\t\t%s\n",
         USE_ACTIONS? "respected" : "ignored  *");

  printf("  token reclassification: \t\t\t%s\n",
         USE_RECLASSIFY? "enabled" : "disabled *");

  printf("  reduction cancellation: \t\t\t%s\n",
         USE_KEEP? "enabled" : "disabled *");

  printf("  mini-LR parser core: \t\t\t\t%s\n",
         USE_MINI_LR? "enabled  *" : "disabled");

  printf("  allocated-node and parse action accounting: \t%s\n",
         ACCOUNTING(1+)0? "enabled" : "disabled *");

  printf("  unrolled reduce loop: \t\t\t%s\n",
         USE_UNROLLED_REDUCE? "enabled  *" : "disabled");

  printf("  parser index: \t\t\t\t%s\n",
         #ifdef USE_PARSER_INDEX
           "enabled"
         #else
           "disabled *"
         #endif
         );

  // checking __OPTIMIZE__ is misleading if preprocessing is entirely
  // divorced from compilation proper, but I still think this printout
  // is useful; also, gcc does not provide a way to tell what level of
  // optimization was applied (as far as I know)
  printf("  C++ compiler's optimizer: \t\t\t%s\n",
         #ifdef __OPTIMIZE__
           "enabled  *"
         #else
           "disabled"
         #endif
         );

  // at the moment, disabling compression makes it fastest
  printf("  Error Entry Factoring (EEF): \t\t\t%s\n",
         ENABLE_EEF_COMPRESSION? "enabled" : "disabled *");
  printf("  Graph Coloring Scheme (GCS): \t\t\t%s\n",
         ENABLE_GCS_COMPRESSION? "enabled" : "disabled *");
  printf("  GCS for columns (GCSC): \t\t\t%s\n",
         ENABLE_GCS_COLUMN_COMPRESSION? "enabled" : "disabled *");
  printf("  Code Reduction Scheme (CRS): \t\t\t%s\n",
         ENABLE_CRS_COMPRESSION? "enabled" : "disabled *");
}


// used to extract the svals from the nodes just under the
// start symbol reduction
SemanticValue GLR::grabTopSval(StackNode *node)
{
  SiblingLink *sib = node->getUniqueLink();
  SemanticValue ret = sib->sval;
  sib->sval = duplicateSemanticValue(node->getSymbolC(), sib->sval);

  TRSACTION("dup'd " << ret << " for top sval, yielded " << sib->sval);

  return ret;
}


// This macro has been pulled out so I can have even finer control
// over the allocation process from the mini-LR core.
//   dest: variable into which the pointer to the new node will be put
//   state: DFA state for this node
//   glr: pointer to the associated GLR object
//   pool: node pool from which to allocate
#define MAKE_STACK_NODE(dest, state, glr, pool)              \
  dest = (pool).alloc();                                     \
  dest->init(state, glr);                                    \
  NODE_COLUMN( dest->column = (glr)->globalNodeColumn; )

// more-friendly inline version, for use outside mini-LR
inline StackNode *GLR::makeStackNode(StateId state)
{
  StackNode *sn;
  MAKE_STACK_NODE(sn, state, this, *stackNodePool);
  return sn;
}


// add a new parser to the 'topmostParsers' list, maintaing
// related invariants
inline void GLR::addTopmostParser(StackNode *parser)
{
  parser->checkLocalInvariants();

  topmostParsers.push(parser);
  parser->incRefCt();

  // I implemented this index, and then discovered it made no difference
  // (actually, slight degradation) in performance; so for now it will
  // be an optional design choice, off by default
  #ifdef USE_PARSER_INDEX
    // fill in the state id index; if the assertion here ever fails, it
    // means there are more than 255 active parsers; either the grammer
    // is highly ambiguous by mistake, or else ParserIndexEntry needs to
    // be re-typedef'd to something bigger than 'char'
    int index = topmostParsers.length()-1;   // index just used
    xassert(index < INDEX_NO_PARSER);

    xassert(parserIndex[parser->state] == INDEX_NO_PARSER);
    parserIndex[parser->state] = index;
  #endif // USE_PARSER_INDEX
}


void GLR::buildParserIndex()
{
  if (parserIndex) {
    delete[] parserIndex;
  }
  parserIndex = new ParserIndexEntry[tables->getNumStates()];
  {
    for (int i=0; i < tables->getNumStates(); i++) {
      parserIndex[i] = INDEX_NO_PARSER;
    }
  }
}


bool GLR::glrParse(LexerInterface &lexer, SemanticValue &treeTop)
{
  #if !ACTION_TRACE
    // tell the user why "-tr action" doesn't do anything, if 
    // they specified that
    trace("action") << "warning: ACTION_TRACE is currently disabled by a\n";
    trace("action") << "compile-time switch, so you won't see parser actions.\n";
  #endif
                 
  #ifdef NDEBUG
    trace("parse") << "warning: Because NDEBUG was specified when elkhound was\n";
    trace("parse") << "         compiled, the 'parse' tracing flag does nothing.\n";
  #endif

  // get ready..
  traceProgress(2) << "parsing...\n";
  clearAllStackNodes();

  // this should be reset to NULL on all exit paths..
  lexerPtr = &lexer;

  // build the parser index (I do this regardless of whether I'm going
  // to use it, because up here it makes no performance difference,
  // and I'd like as little code as possible being #ifdef'd)
  buildParserIndex();

  // call the inner parser core, which is a static member function
  bool ret = innerGlrParse(*this, lexer, treeTop);
  stackNodePool = NULL;     // prevent dangling references
  if (!ret) {
    lexerPtr = NULL;
    return ret;
  }

  // sm: I like to always see these statistics, but dsw doesn't,
  // so I'll just set ELKHOUND_DEBUG in my .bashrc
  if (getenv("ELKHOUND_DEBUG")) {
    #if DO_ACCOUNTING
      StackNode::printAllocStats();
      cout << "detShift=" << detShift
           << ", detReduce=" << detReduce
           << ", nondetShift=" << nondetShift
           << ", nondetReduce=" << nondetReduce
           << endl;
      //PVAL(parserMerges);
      PVAL(computeDepthIters);
      
      PVAL(yieldThenMergeCt);
      PVAL(totalExtracts);
      PVAL(multipleDelayedExtracts);
    #endif
  }

  lexerPtr = NULL;
  return ret;
}


// old note: this function's complexity and/or size is *right* at the
// limit of what gcc-2.95.3 is capable of optimizing well; I've already
// pulled quite a bit of functionality into separate functions to try
// to reduce the register pressure, but it's still near the limit;
// if you do something to cross a pressure threshold, performance drops
// 25% so watch out!
//
// This function is the core of the parser, and its performance is
// critical to the end-to-end performance of the whole system.  It is
// a static member so the accesses to 'glr' (aka 'this') will be
// visible.
STATICDEF bool GLR
  ::innerGlrParse(GLR &glr, LexerInterface &lexer, SemanticValue &treeTop)
{
  CycleTimer timer;
  #ifndef NDEBUG
    bool doDumpGSS = tracingSys("dumpGSS");
  #endif

  // pull a bunch of things out of 'glr' so they'll be accessible from
  // the stack frame instead of having to indirect into the 'glr' object
  UserActions *userAct = glr.userAct;
  ParseTables *tables = glr.tables;
  #if USE_MINI_LR
    ArrayStack<StackNode*> &topmostParsers = glr.topmostParsers;
  #endif

  // lexer token function
  LexerInterface::NextTokenFunc nextToken = lexer.getTokenFunc();

  #if USE_RECLASSIFY
  // reclassifier
  UserActions::ReclassifyFunc reclassifyToken =
    userAct->getReclassifier();
  #endif

  // the stack node pool is a local variable of this function for
  // fastest access by the mini-LR core; other parts of the algorihthm
  // can access it using a pointer stored in the GLR class (caller
  // nullifies this pointer afterward to prevent dangling references)
  ObjectPool<StackNode> stackNodePool(30);
  glr.stackNodePool = &stackNodePool;

  // create an initial ParseTop with grammar-initial-state,
  // set active-parsers to contain just this
  NODE_COLUMN( glr.globalNodeColumn = 0; )
  {
    StackNode *first = glr.makeStackNode(tables->startState);
    glr.addTopmostParser(first);
  }

  #if USE_MINI_LR
    // reduction action function
    UserActions::ReductionActionFunc reductionAction =
      userAct->getReductionAction();

    // this is *not* a reference to the 'glr' member because it
    // doesn't need to be shared with the rest of the algorithm (it's
    // only used in the Mini-LR core), and by having it directly on
    // the stack another indirection is saved
    //
    // new approach: let's try embedding this directly into the stack
    // (this saves 10% in end-to-end performance!)
    //GrowArray<SemanticValue> toPass(TYPICAL_MAX_RHSLEN);
    SemanticValue toPass[MAX_RHSLEN];
  #endif
                   
  // count # of times we use mini LR
  ACCOUNTING( int localDetShift=0; int localDetReduce=0; )

  // for each input symbol
  #ifndef NDEBUG
    int tokenNumber = 0;

    // some debugging streams so the TRSPARSE etc. macros work
    bool trParse       = glr.trParse;
    ostream &trsParse  = glr.trsParse;
  #endif
  for (;;) {
    // debugging
    TRSPARSE(
           "------- "
        << "processing token " << lexer.tokenDesc()
        << ", " << glr.topmostParsers.length() << " active parsers"
        << " -------"
    )
    TRSPARSE("Stack:" << glr.stackSummary())

    #ifndef NDEBUG
      if (doDumpGSS) {
        glr.dumpGSS(tokenNumber);
      }
    #endif

    // get token type, possibly using token reclassification
    #if USE_RECLASSIFY
      lexer.type = reclassifyToken(userAct, lexer.type, lexer.sval);
    #else     // this is what bccgr does
      //if (lexer.type == 1 /*L2_NAME*/) {
      //  lexer.type = 3 /*L2_VARIABLE_NAME*/;
      //} 
    #endif

    // alternate debugging; print after reclassification
    TRSACTION("lookahead token: " << lexer.tokenDesc() <<
              " aka " << userAct->terminalDescription(lexer.type, lexer.sval));

  #if USE_MINI_LR
    // try to cache a few values in locals (this didn't help any..)
    //ActionEntry const * const actionTable = this->tables->actionTable;
    //int const numTerms = this->tables->numTerms;

  tryDeterministic:
    // --------------------- mini-LR parser -------------------------
    // optimization: if there's only one active parser, and the
    // action is unambiguous, and it doesn't involve traversing
    // parts of the stack which are nondeterministic, then do the
    // parse action the way an ordinary LR parser would
    //
    // please note:  The code in this section is cobbled together
    // from various other GLR functions.  Everything here appears in
    // at least one other place, so modifications will usually have
    // to be done in both places.
    //
    // This code is the core of the parsing algorithm, so it's a bit
    // hairy for its performance optimizations.
    if (topmostParsers.length() == 1) {
      StackNode *parser = topmostParsers[0];
      xassertdb(parser->referenceCount==1);     // 'topmostParsers[0]' is referrer
      
      #if ENABLE_EEF_COMPRESSION
        if (tables->actionEntryIsError(parser->state, lexer.type)) {
          return false;    // parse error
        }
      #endif

      ActionEntry action =
        tables->getActionEntry_noError(parser->state, lexer.type);

      // I decode reductions before shifts because:
      //   - they are 4x more common in my C grammar
      //   - decoding a reduction is one less integer comparison
      // however I can only measure ~1% performance difference
      if (tables->isReduceAction(action)) {
        ACCOUNTING( localDetReduce++; )
        int prodIndex = tables->decodeReduce(action, parser->state);
        ParseTables::ProdInfo const &prodInfo = tables->getProdInfo(prodIndex);
        int rhsLen = prodInfo.rhsLen;
        if (rhsLen <= parser->determinDepth) {
          // can reduce unambiguously

          // I need to hide this declaration when debugging is off and
          // optimizer and -Werror are on, because it provokes a warning
          TRSPARSE_DECL( int startStateId = parser->state; )
          
          // if we're tracing actions, I'm going to build a sm_string 
          // that describes all of the RHS symbols
          ACTION( 
            sm_string rhsDescription("");
            if (rhsLen == 0) {
              // print something anyway
              rhsDescription = " empty";
            }
          )

          // record location of left edge; defaults to no location
          // (used for epsilon rules)
          // update: use location of lookahead token instead, for epsilons
          SOURCELOC( SourceLoc leftEdge = lexer.loc; )

          //toPass.ensureIndexDoubler(rhsLen-1);
          xassertdb(rhsLen <= MAX_RHSLEN);

          // we will manually sm_string the stack nodes together onto
          // the free list in 'stackNodePool', and 'prev' will point
          // to the head of the current list; at the end, we'll
          // install the final value of 'prev' back into
          // 'stackNodePool' as the new head of the list
          StackNode *prev = stackNodePool.private_getHead();

          #if USE_UNROLLED_REDUCE
            // What follows is unrollings of the loop below,
            // labeled "loop for arbitrary rhsLen".  Read that loop
            // before the unrollings here, since I omit the comments
            // here.  In general, this program should be correct
            // whether USE_UNROLLED_REDUCE is set or not.
            //
            // To produce the unrolled versions, simply copy all of the
            // noncomment lines from the general loop, and replace the
            // occurrence of 'i' with the value of one less than the 'case'
            // label number.
            switch ((unsigned)rhsLen) {    // gcc produces slightly better code if I cast to unsigned first
              case 1: {
                SiblingLink &sib = parser->firstSib;
                toPass[0] = sib.sval;
                ACTION( rhsDescription =
                  sm_stringc << " "
                          << symbolDescription(parser->getSymbolC(), userAct, sib.sval)
                          << rhsDescription; )
                SOURCELOC(
                  if (sib.validLoc()) {
                    leftEdge = sib.loc;
                  }
                )
                parser->nextInFreeList = prev;
                prev = parser;
                parser = sib.sib;
                xassertdb(parser->referenceCount==1);
                xassertdb(prev->referenceCount==1);
                prev->decrementAllocCounter();
                prev->firstSib.sib.setWithoutUpdateRefct(NULL);
                xassertdb(parser->referenceCount==1);
                // drop through into next case
              }

              case 0:
                // nothing to do
                goto afterGeneralLoop;
            }
          #endif // USE_UNROLLED_REDUCE

          // ------ loop for arbitrary rhsLen ------
          // pop off 'rhsLen' stack nodes, collecting as many semantic
          // values into 'toPass'
          // NOTE: this loop is the innermost inner loop of the entire
          // parser engine -- even *one* branch inside the loop body
          // costs about 30% end-to-end performance loss!
          for (int i = rhsLen-1; i >= 0; i--) {
            // grab 'parser's only sibling link
            //SiblingLink *sib = parser->getUniqueLink();
            SiblingLink &sib = parser->firstSib;

            // Store its semantic value it into array that will be
            // passed to user's routine.  Note that there is no need to
            // dup() this value, since it will never be passed to
            // another action routine (avoiding that overhead is
            // another advantage to the LR mode).
            toPass[i] = sib.sval;

            // when tracing actions, continue building rhs desc
            ACTION( rhsDescription = 
              sm_stringc << " "
                      << symbolDescription(parser->getSymbolC(), userAct, sib.sval)
                      << rhsDescription; )

            // not necessary:
            //   sib.sval = NULL;                  // link no longer owns the value
            // this assignment isn't necessary because the usual treatment
            // of NULL is to ignore it, and I manually ignore *any* value
            // in the inline-expanded code below

            // if it has a valid source location, grab it
            SOURCELOC(
              if (sib.validLoc()) {
                leftEdge = sib.loc;
              }
            )

            // pop 'parser' and move to the next one
            parser->nextInFreeList = prev;
            prev = parser;
            parser = sib.sib;

            // don't actually increment, since I now no longer actually decrement
            // cancelled(1) effect: parser->incRefCt();    // so 'parser' survives deallocation of 'sib'
            // cancelled(1) observable: xassertdb(parser->referenceCount==1);       // 'sib' and the fake one

            // so now it's just the one
            xassertdb(parser->referenceCount==1);     // just 'sib'

            xassertdb(prev->referenceCount==1);
            // expand "prev->decRefCt();"             // deinit 'prev', dealloc 'sib'
            {
              // I don't actually decrement the reference count on 'prev'
              // because it will be reset to 0 anyway when it is inited
              // the next time it is used
              //prev->referenceCount = 0;

              // adjust the global count of stack nodes
              prev->decrementAllocCounter();

              // I previously had a test for "prev->firstSib.sval != NULL",
              // but that can't happen because I set it to NULL above!
              // (as the alias sib.sval)
              // update: now I don't even set it to NULL because the code here
              // has been changed to ignore *any* value
              //if (prev->firstSib.sval != NULL) {
              //  cout << "I GOT THE ANALYSIS WRONG!\n";
              //}

              // cancelled(1) effect: parser->decRefCt();
              prev->firstSib.sib.setWithoutUpdateRefct(NULL);

              // possible optimization: I could eliminiate
              // "prev->firstSib.sib=NULL" if I consistently modified all
              // creation of stack nodes to treat sib as a dead value:
              // right after creation I would make sure the new
              // sibling value *overwrites* sib, and no attempt is
              // made to decrement a refct on the dead value

              // this is obviated by the manual construction of the
              // free list links (nestInFreeList) above
              //stackNodePool.deallocNoDeinit(prev);
            }

            xassertdb(parser->referenceCount==1);     // fake refct only
          } // end of general rhsLen loop

        #if USE_UNROLLED_REDUCE    // suppress the warning when not using it..
        afterGeneralLoop:
        #endif
          // having now manually strung the deallocated stack nodes together
          // on the free list, I need to make the node pool's head point at them
          stackNodePool.private_setHead(prev);

          // call the user's action function (TREEBUILD)
          SemanticValue sval =
          #if USE_ACTIONS
            reductionAction(userAct, prodIndex, toPass /*.getArray()*/
                            SOURCELOCARG( leftEdge ) );
          #else
            NULL;
          #endif

          // now, push a new state; essentially, shift prodInfo.lhsIndex.
          // do "glrShiftNonterminal(parser, prodInfo.lhsIndex, sval, leftEdge);",
          // except avoid interacting with the worklists

          // this is like a shift -- we need to know where to go; the
          // 'goto' table has this information
          StateId newState = tables->decodeGoto(
            tables->getGotoEntry(parser->state, prodInfo.lhsIndex),
            prodInfo.lhsIndex);

          // debugging
          TRSPARSE("state " << startStateId <<
                   ", (unambig) reduce by " << prodIndex <<
                   " (len=" << rhsLen <<
                   "), back to " << parser->state <<
                   " then out to " << newState);

          // 'parser' has refct 1, reflecting the local variable only
          xassertdb(parser->referenceCount==1);

          // push new state
          StackNode *newNode;
          MAKE_STACK_NODE(newNode, newState, &glr, stackNodePool)

          newNode->addFirstSiblingLink_noRefCt(
            parser, sval  SOURCELOCARG( leftEdge ) );
          // cancelled(3) effect: parser->incRefCt();

          // cancelled(3) effect: xassertdb(parser->referenceCount==2);
          // expand:
          //   "parser->decRefCt();"                 // local variable "parser" about to go out of scope
          {
            // cancelled(3) effect: parser->referenceCount = 1;
          }
          xassertdb(parser->referenceCount==1);

          // replace whatever is in 'topmostParsers[0]' with 'newNode'
          topmostParsers[0] = newNode;
          newNode->incRefCt();
          xassertdb(newNode->referenceCount == 1);   // topmostParsers[0] is referrer

          // emit some trace output
          TRSACTION("  " << 
                    symbolDescription(newNode->getSymbolC(), userAct, sval) <<
                    " ->" << rhsDescription);

          #if USE_KEEP
            // see if the user wants to keep this reduction
            if (!userAct->keepNontermValue(prodInfo.lhsIndex, sval)) {
              ACTION( sm_string lhsDesc =
                        userAct->nonterminalDescription(prodInfo.lhsIndex, sval); )
              TRSACTION("    CANCELLED " << lhsDesc);
              glr.printParseErrorMessage(newNode->state);
              ACCOUNTING(
                glr.detShift += localDetShift;
                glr.detReduce += localDetReduce;
              )
              
              // TODO: I'm pretty sure I'm not properly cleaning
              // up all of my state here..
              return false;
            }
          #endif // USE_KEEP

          // after all this, we haven't shifted any tokens, so the token
          // context remains; let's go back and try to keep acting
          // determinstically (if at some point we can't be deterministic,
          // then we drop into full GLR, which always ends by shifting)
          goto tryDeterministic;
        }
      }

      else if (tables->isShiftAction(action)) {
        ACCOUNTING( localDetShift++; )

        // can shift unambiguously
        StateId newState = tables->decodeShift(action, lexer.type);

        TRSPARSE("state " << parser->state <<
                 ", (unambig) shift token " << lexer.tokenDesc() <<
                 ", to state " << newState);

        NODE_COLUMN( glr.globalNodeColumn++; )

        StackNode *rightSibling;
        MAKE_STACK_NODE(rightSibling, newState, &glr, stackNodePool);

        rightSibling->addFirstSiblingLink_noRefCt(
          parser, lexer.sval  SOURCELOCARG( lexer.loc ) );
        // cancelled(2) effect: parser->incRefCt();

        // replace 'parser' with 'rightSibling' in the topmostParsers list
        topmostParsers[0] = rightSibling;
        // cancelled(2) effect: xassertdb(parser->referenceCount==2);         // rightSibling & topmostParsers[0]
        // expand "parser->decRefCt();"
        {
          // cancelled(2) effect: parser->referenceCount = 1;
        }
        xassertdb(parser->referenceCount==1);         // rightSibling

        xassertdb(rightSibling->referenceCount==0);   // just created
        // expand "rightSibling->incRefCt();"
        {
          rightSibling->referenceCount = 1;
        }
        xassertdb(rightSibling->referenceCount==1);   // topmostParsers[0] refers to it

        // get next token
        goto getNextToken;
      }

      else {
        // error or ambig; not deterministic
      }
    }
    // ------------------ end of mini-LR parser ------------------
  #endif // USE_MINI_LR

    // if we get here, we're dropping into the nondeterministic GLR
    // algorithm in its full glory
    if (!glr.nondeterministicParseToken()) {
      return false;
    }

  #if USE_MINI_LR    // silence a warning when it's not enabled
  getNextToken:
  #endif
    // was that the last token?
    if (lexer.type == 0) {
      break;
    }

    // get the next token
    nextToken(&lexer);
    #ifndef NDEBUG
      tokenNumber++;
    #endif
  }

  // push stats into main object
  ACCOUNTING(
    glr.detShift += localDetShift;
    glr.detReduce += localDetReduce;
  )

  // end of parse; note that this function must be called *before*
  // the stackNodePool is deallocated
  return glr.cleanupAfterParse(timer, treeTop);
}


// diagnostic/debugging function: yield sequence of
// states represented by 'parser'; in the case of
// ambiguity, just show one...
sm_string stackTraceString(StackNode *parser)
{
  // hmm.. what to do about cyclic stacks?
  return sm_string("need to think about this some more..");
}


// return false if caller should return false; pulled out of
// glrParse to reduce register pressure (but didn't help as
// far as I can tell!)
bool GLR::nondeterministicParseToken()
{
  //cout << "not deterministic\n";

  // ([GLR] called the code from here to the end of
  // the loop 'parseword')

  // work through the worklist
  StateId lastToDie = STATE_INVALID;

  // do all reduction explicitly first, then all shifts by
  // re-iterating over topmost parsers
  int i;
  for (i=0; i < topmostParsers.length(); i++) {
    StackNode *parser = topmostParsers[i];

    ActionEntry action =
      tables->getActionEntry(parser->state, lexerPtr->type);
    int actions = rwlEnqueueReductions(parser, action, NULL /*sibLink*/);

    if (actions == 0) {
      TRSPARSE("parser in state " << parser->state << " died");
      lastToDie = parser->state;
    }
  }

  // now that the reductions for all the existing topmost states
  // have been enqueued, process that worklist
  rwlProcessWorklist();

  // finally, do all the shifts that the topmost states can do
  rwlShiftTerminals();


  // if all active parsers have died, there was an error
  if (topmostParsers.isEmpty()) {
    printParseErrorMessage(lastToDie);
    return false;
  }
  else {
    return true;
  }
}


// pulled out of glrParse() to reduce register pressure
void GLR::printParseErrorMessage(StateId lastToDie)
{
  if (!noisyFailedParse) {
    return;
  }

  // print which tokens could have allowed progress; this isn't
  // perfect because I'm only printing this for one state, but in the
  // nondeterministic algorithm there might have been more than one
  // state that could have made progress..
  if (lastToDie != STATE_INVALID) {
    cout << "In state " << lastToDie << ", I expected one of these tokens:\n";
    cout << "  ";
    for (int i=0; i < tables->getNumTerms(); i++) {
      ActionEntry act = tables->getActionEntry(lastToDie, i);
      if (!tables->isErrorAction(act)) {
        //cout << "  [" << i << "] " << lexerPtr->tokenKindDesc(i) << "\n";
        cout << lexerPtr->tokenKindDesc(i) << ", ";
      }
    }
    cout << "\n";
  }
  else {                                                                          
    // this happens because I lose the dead-parser info while processing
    // the reduction worklist; to implement this I'd need to remember each
    // state that died while processing the worklist; for now I'll just let
    // it be, and only have the right info sometimes
    cout << "(expected-token info not available due to nondeterministic mode)\n";
  }

  cout << toString(lexerPtr->loc)
       << ": Parse error (state " << lastToDie << ") at "
       << lexerPtr->tokenDesc()
       << endl;

  // removing this for now since keeping it would mean putting
  // sample inputs and left contexts for all states into the
  // parse tables
  #if 0
  if (lastToDie == STATE_INVALID) {
    // I'm not entirely confident it has to be nonnull..
    cout << "what the?  lastToDie is STATE_INVALID??\n";
  }
  else {
    // print out the context of that parser
    cout << "last parser (state " << lastToDie << ") to die had:\n"
         << "  sample input: "
         << sampleInput(getItemSet(lastToDie)) << "\n"
         << "  left context: "
         << leftContextString(getItemSet(lastToDie)) << "\n";
  }
  #endif // 0
}


SemanticValue GLR::doReductionAction(
  int productionId, SemanticValue const *svals
  SOURCELOCARG( SourceLoc loc ) )
{
  // get the function pointer and invoke it; possible optimization
  // is to cache the function pointer in the GLR object
  return (userAct->getReductionAction())(userAct, productionId, svals  SOURCELOCARG(loc));
}


// pulled from glrParse() to reduce register pressure
bool GLR::cleanupAfterParse(CycleTimer &timer, SemanticValue &treeTop)
{
  traceProgress() << "done parsing (" << timer.elapsed() << ")\n";
  trsParse << "Parse succeeded!\n";


  // finish the parse by reducing to start symbol
  if (topmostParsers.length() != 1) {
    cout << "parsing finished with more than one active parser!\n";
    return false;
  }
  StackNode *last = topmostParsers.top();

  // pull out the semantic values; this assumes the start symbol
  // always looks like "Start -> Something EOF"; it also assumes
  // the top of the tree is unambiguous
  SemanticValue arr[2];
  StackNode *nextToLast = last->getUniqueLink()->sib;
  arr[0] = grabTopSval(nextToLast);   // Something's sval
  arr[1] = grabTopSval(last);         // eof's sval

  // reduce
  TRSACTION("handing toplevel sval " << arr[0] <<
            " and " << arr[1] <<
            " to top start's reducer");
  treeTop = doReductionAction(
              //getItemSet(last->state)->getFirstReduction()->prodIndex,
              tables->finalProductionIndex,
              arr
              SOURCELOCARG( last->getUniqueLinkC()->loc ) );

  // why do this song-and-dance here, instead of letting the normal
  // parser engine do the final reduction?  because the GLR algorithm
  // always finishes its iterations with a shift, and it's not trivial
  // to add a special exception for the case of the reduce which
  // finishes the parse

  // these also must be done before the pool goes away..
  decParserList(topmostParsers);

  return true;
}


// this used to be code in glrParse(), but its presense disturbs gcc's
// register allocator to the tune of a 33% performance hit!  so I've
// pulled it in hopes the allocator will be happier now
void GLR::pullFromTopmostParsers(StackNode *parser)
{
  int last = topmostParsers.length()-1;
  for (int i=0; i <= last; i++) {
    if (topmostParsers[i] == parser) {
      // remove it; if it's not last in the list, swap it with
      // the last one to maintain contiguity
      if (i < last) {
        topmostParsers[i] = topmostParsers[last];
        // (no need to actually copy 'i' into 'last')
      }
      topmostParsers.pop();     // removes a reference to 'parser'
      parser->decRefCt();       // so decrement reference count
      break;
    }
  }
}


// return true if the given parser can either shift or reduce.  NOTE:
// this isn't really sufficient for its intended purpose, since I
// don't check to see whether *further* actions after a reduce are
// possible; moreover, checking that could be very expensive, since
// there may be many paths along which to consider reducing, and many
// paths from that reduced node forward..
bool GLR::canMakeProgress(StackNode *parser)
{
  ActionEntry entry =
    tables->getActionEntry(parser->state, lexerPtr->type);

  return tables->isShiftAction(entry) ||
         tables->isReduceAction(entry) ||
         !tables->isErrorAction(entry);
}


// if an active parser is at 'state', return it; otherwise
// return NULL
StackNode *GLR::findTopmostParser(StateId state)
{
  #ifdef USE_PARSER_INDEX
    int index = parserIndex[state];
    if (index != INDEX_NO_PARSER) {
      return topmostParsers[index];
    }
    else {
      return NULL;
    }
  #else
    for (int i=0; i < topmostParsers.length(); i++) {
      StackNode *node = topmostParsers[i];
      if (node->state == state) {
        return node;
      }
    }
    return NULL;
  #endif
}


// print the graph-structured stack to a file, named according
// to the current token number, in a format suitable for a
// graph visualization tool of some sort
void GLR::dumpGSS(int tokenNumber) const
{
  FILE *dest = fopen(sm_stringc << "gss." << tokenNumber << ".g", "w");

  // list of nodes we've already printed, to avoid printing any
  // node more than once
  SObjList<StackNode> printed;

  // list of nodes to print; might intersect 'printed', in which case
  // such nodes should be discarded; initially contains all the active
  // parsers (tops of stacks)
  SObjList<StackNode> queue;
  for (int i=0; i < topmostParsers.length(); i++) {
    queue.append(topmostParsers[i]);
  }

  // keep printing nodes while there are still some to print
  while (queue.isNotEmpty()) {
    StackNode *node = queue.removeFirst();
    if (printed.contains(node)) {
      continue;
    }
    printed.append(node);

    // only edges actually get printed (since the node names
    // encode all the important information); so iterate over
    // the sibling links now; while iterating, add the discovered
    // nodes to the queue so we'll print them too
    if (node->firstSib.sib != NULL) {
      dumpGSSEdge(dest, node, node->firstSib.sib);
      queue.append(node->firstSib.sib);

      FOREACH_OBJLIST(SiblingLink, node->leftSiblings, iter) {
        dumpGSSEdge(dest, node, iter.data()->sib);
        queue.append(const_cast<StackNode*>( iter.data()->sib.getC() ));
      }
    }
  }

  fclose(dest);
}


void GLR::dumpGSSEdge(FILE *dest, StackNode const *src,
                                  StackNode const *target) const
{
  fprintf(dest, "e %d_%p_%d %d_%p_%d\n",
                0 NODE_COLUMN( + src->column ), src, src->state,
                0 NODE_COLUMN( + target->column ), target, target->state);
}


// alternative to above: stack info in a single sm_string
sm_string GLR::stackSummary() const
{
  sm_stringBuilder sb;

  // list of nodes we've already printed, to avoid printing any
  // node more than once
  SObjList<StackNode const> printed;

  for (int i=0; i < topmostParsers.length(); i++) {
    sb << " (" << i << ": ";
    innerStackSummary(sb, printed, topmostParsers[i]);
    sb << ")";
  }

  return sb;
}

void GLR::nodeSummary(sm_stringBuilder &sb, StackNode const *node) const
{
  sb << node->state << "[" << node->referenceCount << "]";
}

void GLR::innerStackSummary(sm_stringBuilder &sb, SObjList<StackNode const> &printed,
                            StackNode const *node) const
{
  if (printed.contains(node)) {
    sb << "(rep:";
    nodeSummary(sb, node);
    sb << ")";
    return;
  }

  nodeSummary(sb, node);
  printed.append(node);

  if (!node->firstSib.sib) {
    return;   // no siblings
  }

  sb << "-";

  if (node->leftSiblings.isEmpty()) {
    // one sibling
    innerStackSummary(sb, printed, node->firstSib.sib);
  }
  else {
    // multiple siblings
    sb << "(";
    innerStackSummary(sb, printed, node->firstSib.sib);

    FOREACH_OBJLIST(SiblingLink, node->leftSiblings, iter) {
      sb << "|";
      innerStackSummary(sb, printed, iter.data()->sib);
    }
    sb << ")";
  }
}


#if 0
SemanticValue GLR::getParseResult()
{
  // the final topmost parser is the one that shifted the
  // end-of-stream marker, so we want its left sibling, since that
  // will be the reduction(s) to the start symbol
  SemanticValue sv =
    topmostParsers.first()->                    // parser that shifted end-of-stream
      leftSiblings.first()->sib->              // parser that shifted start symbol
      leftSiblings.first()->                   // sibling link with start symbol
      sval;                                    // start symbol tree node

  return sv;
}    
#endif // 0


// -------------- reduction worklist (RWL) algorithm --------------
// This algorithm is an attempt to avoid the problem where a semantic
// value is yielded to a reduction action, but then merged with
// another semantic value, such that the original one yielded is now
// stale.  It's described in more detail in the tech report.

ReductionPathQueue::Path::Path()
  : startStateId(STATE_INVALID),
    prodIndex(-1),
    startColumn(-1),
    leftEdgeNode(NULL),
    sibLinks(INITIAL_RHSLEN_SIZE),
    symbols(INITIAL_RHSLEN_SIZE)
{
  next = NULL;
}

ReductionPathQueue::Path::~Path()
{}


void ReductionPathQueue::Path::init(StateId ssi, int pi, int rhsLen)
{
  startStateId = ssi;
  prodIndex = pi;

  sibLinks.ensureIndexDoubler(rhsLen);
  symbols.ensureIndexDoubler(rhsLen);
}


ReductionPathQueue::ReductionPathQueue(ParseTables *t)
  : top(NULL),
    pathPool(30),    // arbitrary initial pool size
    tables(t)
{}

ReductionPathQueue::~ReductionPathQueue()
{
  // 'pathPool' will automatically array-deallocate all of the
  // paths, which will themselves then delete their internal
  // 'sibLinks' and 'symbols' arrays
}


ReductionPathQueue::Path *ReductionPathQueue::newPath(
  StateId startStateId, int prodIndex, int rhsLen)
{
  Path *p = pathPool.alloc();
  p->init(startStateId, prodIndex, rhsLen);
  return p;
}


void ReductionPathQueue::insertPathCopy(Path const *src, StackNode *leftEdge)
{
  ParseTables::ProdInfo const &prodInfo = tables->getProdInfo(src->prodIndex);

  // make a new node
  Path *p = pathPool.alloc();
  p->init(src->startStateId, src->prodIndex, prodInfo.rhsLen);

  // fill in left edge info
  p->leftEdgeNode = leftEdge;
  p->startColumn = leftEdge->column;

  // copy the path info
  for (int i = prodInfo.rhsLen-1; i>=0; i--) {
    p->sibLinks[i] = src->sibLinks[i];
    p->symbols[i] = src->symbols[i];
  }

  // find the proper place to insert it
  if (!top || goesBefore(p, top)) {
    // prepend
    p->next = top;
    top = p;
  }
  else {
    // search
    Path *prev = top;
    while (prev->next && !goesBefore(p, prev->next)) {
      prev = prev->next;
    }

    // insert
    p->next = prev->next;
    prev->next = p;
  }
}

bool ReductionPathQueue::goesBefore(Path const *p1, Path const *p2) const
{
  if (p1->startColumn > p2->startColumn) {
    // 'p1' spans fewer tokens, so it goes first
    return true;
  }
  else if (p2->startColumn > p1->startColumn) {
    // same logic
    return false;
  }
  else {
    // equal start columns, so compare ids of nonterminals
    // to which we're reducing in each case
    NtIndex p1NtIndex = tables->getProdInfo(p1->prodIndex).lhsIndex;
    NtIndex p2NtIndex = tables->getProdInfo(p2->prodIndex).lhsIndex;

    // consult total order on nonterminals
    int ord1 = tables->getNontermOrdinal(p1NtIndex);
    int ord2 = tables->getNontermOrdinal(p2NtIndex);

    return ord1 < ord2;
  }
}


inline ReductionPathQueue::Path *ReductionPathQueue::dequeue()
{
  Path *ret = top;
  top = top->next;
  return ret;
}


void ReductionPathQueue::deletePath(Path *p)
{
  pathPool.dealloc(p);
}


// process the reduction worklist
void GLR::rwlProcessWorklist()
{
  // location of this token
  SOURCELOC( SourceLoc tokenLoc = lexerPtr->loc; )

  while (pathQueue.isNotEmpty()) {
    // process the enabled reductions in priority order
    ReductionPathQueue::Path *path = pathQueue.dequeue();

    // info about the production
    ParseTables::ProdInfo const &prodInfo = tables->getProdInfo(path->prodIndex);
    int rhsLen = prodInfo.rhsLen;

    TRSPARSE("state " << path->startStateId <<
             ", reducing by production " << path->prodIndex <<
             " (rhsLen=" << rhsLen <<
             "), back to state " << path->leftEdgeNode->state);

    ACCOUNTING( nondetReduce++; )

    // record location of left edge; initially is location of
    // the lookahead token
    SOURCELOC( SourceLoc leftEdge = tokenLoc; )

    // build description of rhs for tracing
    ACTION(
      sm_string rhsDescription("");
      if (rhsLen == 0) {
        // print something anyway
        rhsDescription = " empty";
      }
    )

    // before calling the user, duplicate any needed values; this loop
    // goes from right to left backwards so that 'leftEdge' is
    // computed properly
    toPass.ensureIndexDoubler(rhsLen-1);
    for (int i=rhsLen-1; i >= 0; i--) {
      SiblingLink *sib = path->sibLinks[i];

      // we're about to yield sib's 'sval' to the reduction action
      toPass[i] = sib->sval;

      // continue building rhs desc
      ACTION( rhsDescription =
        sm_stringc << symbolDescription(path->symbols[i], userAct, sib->sval)
                << " "
                << rhsDescription;
      )

      // left edge?  or, have all previous tokens failed to yield
      // information?
      SOURCELOC(
        if (sib->loc != SL_UNKNOWN) {     
          leftEdge = sib->loc;
        }
      )

      // we inform the user, and the user responds with a value
      // to be kept in this sibling link *instead* of the passed
      // value; if this link yields a value in the future, it will
      // be this replacement
      sib->sval = duplicateSemanticValue(path->symbols[i], sib->sval);

      YIELD_COUNT( sib->yieldCount++; )
    }

    // we've popped the required number of symbols; call the
    // user's code to synthesize a semantic value by combining them
    // (TREEBUILD)
    SemanticValue sval =
      doReductionAction(path->prodIndex, toPass.getArray()
                        SOURCELOCARG( leftEdge ) );

    // emit tracing diagnostics for this reduction
    ACTION( sm_string lhsDesc =
              userAct->nonterminalDescription(prodInfo.lhsIndex, sval); )
    TRSACTION("  " << lhsDesc << " ->" << rhsDescription);

    // see if the user wants to keep this reduction
    if (USE_KEEP &&
        !userAct->keepNontermValue(prodInfo.lhsIndex, sval)) {
      TRSACTION("    CANCELLED " << lhsDesc);
    }
    else {
      // shift the nonterminal with its reduced semantic value
      SiblingLink *newLink =
        rwlShiftNonterminal(path->leftEdgeNode, prodInfo.lhsIndex,
                            sval  SOURCELOCARG( leftEdge ) );

      if (newLink) {
        // for each 'finished' parser ...
        for (int i=0; i < topmostParsers.length(); i++) {
          StackNode *parser = topmostParsers[i];

          // ... do any reduce actions that are now enabled by the new link
          ActionEntry action =
            tables->getActionEntry(parser->state, lexerPtr->type);
          rwlEnqueueReductions(parser, action, newLink);
        }
      }
    }

    pathQueue.deletePath(path);
  }
}


// shift reduction onto 'leftSibling' parser, 'lhsIndex' says which
// nonterminal is being shifted; 'sval' is the semantic value of this
// subtree, and 'loc' is the location of the left edge; return value
// is the newly added link, if one was added between existing nodes
// ([GLR] calls this function 'reducer')
//
// exactly one of three possible things happens:
//   - we make a new stack node
//   - we add a new link between existing stack nodes
//   - we merge two semantic values onto an existing link
SiblingLink *GLR::rwlShiftNonterminal(StackNode *leftSibling, int lhsIndex,
                                      SemanticValue /*owner*/ sval
                                      SOURCELOCARG( SourceLoc loc ) )
{
  // this is like a shift -- we need to know where to go; the
  // 'goto' table has this information
  StateId rightSiblingState = tables->decodeGoto(
    tables->getGotoEntry(leftSibling->state, lhsIndex), lhsIndex);

  // debugging
  TRSPARSE("state " << leftSibling->state <<
           ", shift nonterm " << lhsIndex <<
           ", to state " << rightSiblingState);

  // is there already an active parser with this state?
  StackNode *rightSibling = findTopmostParser(rightSiblingState);
  if (rightSibling) {
    // does it already have a sibling link to 'leftSibling'?
    SiblingLink *sibLink = rightSibling->getLinkTo(leftSibling);
    if (sibLink) {
      // we already have a sibling link, so we don't need to add one

      // +--------------------------------------------------+
      // | it is here that we are bringing the tops of two  |
      // | alternative parses together (TREEBUILD)          |
      // +--------------------------------------------------+

      // sometimes we are trying to merge dead trees--if the
      // 'rightSibling' cannot make progress at all, it would be much
      // better to just drop this alternative than demand the user
      // merge trees when there is not necessarily any ambiguity
      if (!canMakeProgress(rightSibling)) {
        // both trees are dead; deallocate one (the other alternative
        // will be dropped later, when 'rightSibling' is considered
        // for action in the usual way)
        TRSPARSE("avoided a merge by noticing the state was dead");
        deallocateSemanticValue(rightSibling->getSymbolC(), sval);
        return NULL;
      }

      // remember previous value, for yield count warning
      YIELD_COUNT(SemanticValue old2 = sibLink->sval);

      // remember descriptions of the values before they are merged
      ACTION(
        sm_string leftDesc = userAct->nonterminalDescription(lhsIndex, sibLink->sval);
        sm_string rightDesc = userAct->nonterminalDescription(lhsIndex, sval);
      )

      // call the user's code to merge, and replace what we have
      // now with the merged version
      sibLink->sval =
        userAct->mergeAlternativeParses(lhsIndex, sibLink->sval, sval  SOURCELOCARG( loc ) );

      // emit tracing diagnostics for the merge
      TRSACTION("  " <<
                userAct->nonterminalDescription(lhsIndex, sibLink->sval) <<
                " is MERGE of " << leftDesc << " and " << rightDesc);

      YIELD_COUNT(
        if (sibLink->yieldCount > 0) {
          // yield-then-merge (YTM) happened
          yieldThenMergeCt++;
          SOURCELOC( trace("ytm") << "at " << toString(loc) << endl; )

          // if merging yielded a new semantic value, then we most likely
          // have a problem; if it yielded the *same* value, then most
          // likely the user has implemented the 'ambiguity' link soln,
          // so we're ok
          if (old2 != sibLink->sval) {
            cout << "warning: incomplete parse forest: " << (void*)old2
                 << " has already been yielded, but it now has been "
                 << "merged with " << (void*)sval << " to make "
                 << (void*)(sibLink->sval) << " (lhsIndex="
                 << lhsIndex << ")" << endl;
          }
        }
      )

      // ok, done
      return NULL;

      // and since we didn't add a link, there is no potential for new
      // paths
    }

    // we get here if there is no suitable sibling link already
    // existing; so add the link (and keep the ptr for loop below)
    sibLink = rightSibling->addSiblingLink(leftSibling, sval  SOURCELOCARG( loc ) );

    // adding a new sibling link may have introduced additional
    // opportunties to do reductions from parsers we thought
    // we were finished with.
    //
    // what's more, it's not just the parser ('rightSibling') we
    // added the link to -- if rightSibling's itemSet contains 'A ->
    // alpha . B beta' and B ->* empty (so A's itemSet also has 'B
    // -> .'), then we reduced it (if lookahead ok), so
    // 'rightSibling' now has another left sibling with 'A -> alpha
    // B . beta'.  We need to let this sibling re-try its reductions
    // also.
    //
    // so, the strategy is to let all 'finished' parsers re-try
    // reductions, and process those that actually use the just-
    // added link

    // TODO: I think this code path is unusual; confirm by measurement
    // update: it's taken maybe 1 in 10 times through this function..
    parserMerges++;

    // we don't have to recompute if nothing else points at
    // 'rightSibling'; the refct is always at least 1 because we found
    // it on the "active parsers" worklist
    if (rightSibling->referenceCount > 1) {
      // since we added a new link *all* determinDepths might
      // be compromised; iterating more than once should be very
      // rare (and this code path should already be unusual)
      int changes=1, iters=0;
      while (changes) {
        changes = 0;
        for (int i=0; i < topmostParsers.length(); i++) {
          StackNode *parser = topmostParsers[i];
          int newDepth = parser->computeDeterminDepth();
          if (newDepth != parser->determinDepth) {
            changes++;
            parser->determinDepth = newDepth;
          }
        }
        iters++;
        xassert(iters < 1000);    // protect against infinite loop
        computeDepthIters++;
      }
    }

    // inform the caller that a new sibling link was added
    return sibLink;
  }

  else {
    // no, there is not already an active parser with this
    // state.  we must create one; it will become the right
    // sibling of 'leftSibling'
    rightSibling = makeStackNode(rightSiblingState);

    // add the sibling link (and keep ptr for tree stuff)
    rightSibling->addSiblingLink(leftSibling, sval  SOURCELOCARG( loc ) );

    // since this is a new parser top, it needs to become a
    // member of the frontier
    addTopmostParser(rightSibling);

    // here, rather than adding something to the parser worklist,
    // we'll directly expand its reduction paths and add them
    // to the reduction worklist
    ActionEntry action =
      tables->getActionEntry(rightSibling->state, lexerPtr->type);
    rwlEnqueueReductions(rightSibling, action, NULL /*sibLink*/);

    // no need for the elaborate re-checking above, since we
    // just created rightSibling, so no new opportunities
    // for reduction could have arisen
    return NULL;
  }
}


// find and enqueue all the reductions that 'parser' can do; 'action'
// is the parser's action code; we only consider reductions that use
// 'mustUseLink', if that is not NULL
//
// This function will enqueue reduction paths, ordered first by the
// number of terminals spanned and second by the nonterminal
// derivability relation on the nonterminal to which the path reduces
// (if A ->+ B then we will reduce to B before reducing to A, if
// terminal spans are equal).
//
// this function returns the # of actions the parser can take, as
// part of a rather weak error reporting scheme..
int GLR::rwlEnqueueReductions(StackNode *parser, ActionEntry action,
                              SiblingLink *mustUseLink)
{
  parser->checkLocalInvariants();

  if (tables->isShiftAction(action)) {
    // do nothing, we're only interested in reductions
    return 1;
  }
  else if (tables->isReduceAction(action)) {
    // reduce
    int prodIndex = tables->decodeReduce(action, parser->state);

    // get information about the production we'll use
    ParseTables::ProdInfo const &info = tables->getProdInfo(prodIndex);
    int rhsLen = info.rhsLen;
    xassert(rhsLen >= 0);    // paranoia before using this to control recursion

    // initialize a prototype Path which will monitor our progress
    // though the enumeration of all paths
    ReductionPathQueue::Path *proto =
      pathQueue.newPath(parser->state, prodIndex, rhsLen);

    // kick off the recursion
    rwlRecursiveEnqueue(proto, rhsLen, parser, mustUseLink);

    // deallocate the prototype
    pathQueue.deletePath(proto);

    return 1;
  }
  else if (tables->isErrorAction(action)) {
    // the parser dies, we don't do anything
    return 0;
  }
  else {
    // ambiguous; check for reductions
    ActionEntry *entry = tables->decodeAmbigAction(action, parser->state);
    for (int i=0; i<entry[0]; i++) {
      rwlEnqueueReductions(parser, entry[i+1], mustUseLink);
    }

    return entry[0];
  }
}


// arguments have same meanings as in 'rwlRecursiveEnqueue'
inline void GLR::rwlCollectPathLink(
  ReductionPathQueue::Path *proto, int popsRemaining,
  StackNode *currentNode, SiblingLink *mustUseLink, SiblingLink *linkToAdd)
{
  proto->sibLinks[popsRemaining] = linkToAdd;
  proto->symbols[popsRemaining] = currentNode->getSymbolC();

  if (linkToAdd == mustUseLink) {
    rwlRecursiveEnqueue(proto, popsRemaining, linkToAdd->sib,
                        NULL /*mustUseLink*/);
  }
  else {
    rwlRecursiveEnqueue(proto, popsRemaining, linkToAdd->sib,
                        mustUseLink);
  }
}

// recursive depth-first enumeration of paths
void GLR::rwlRecursiveEnqueue(
  ReductionPathQueue::Path *proto,  // prototype path, with path so far
  int popsRemaining,                // # of links yet to traverse to find a full path
  StackNode *currentNode,           // node we're at in the path
  SiblingLink *mustUseLink)         // link the path must use (if non-NULL)
{
  if (popsRemaining == 0) {
    // we found path of required length

    // if we have failed to use the required link, ignore this path
    if (mustUseLink != NULL) {
      return;
    }

    // the prototype path is the one we want; copy it, fill in
    // the 'startColumn', and insert it into the queue
    pathQueue.insertPathCopy(proto, currentNode);
  }

  else {
    // explore 'currentNode's siblings
    rwlCollectPathLink(proto, popsRemaining-1, currentNode, mustUseLink,
                       &(currentNode->firstSib));

    // test before dropping into the loop, since profiler reported
    // some time spent calling VoidListMutator::reset ..
    if (currentNode->leftSiblings.isNotEmpty()) {
      FOREACH_OBJLIST_NC(SiblingLink, currentNode->leftSiblings, sibling) {
        rwlCollectPathLink(proto, popsRemaining-1, currentNode, mustUseLink,
                           sibling.data());
      }
    }
  }
}


// final phase in processing of a token: all topmost parsers
// shift the current token, if they can
void GLR::rwlShiftTerminals()
{
  NODE_COLUMN( globalNodeColumn++; )

  // move all the parsers from 'topmostParsers' into 'prevTopmost'
  xassert(prevTopmost.isEmpty());
  prevTopmost.swapWith(topmostParsers);
  xassert(topmostParsers.isEmpty());

  // to solve the multi-yield problem for tokens, I'll remember
  // the previously-created sibling link (if any), and dup the
  // sval in that link as needed
  SiblingLink *prev = NULL;

  // foreach node in prevTopmost
  while (prevTopmost.isNotEmpty()) {                
    // take the node from 'prevTopmost'; the refcount includes both
    // 'leftSibling' and 'prevTopmost', and then we decrement the
    // count to reflect that only 'leftSibling' has it
    RCPtr<StackNode> leftSibling(prevTopmost.pop());
    xassertdb(leftSibling->referenceCount >= 2);
    leftSibling->decRefCt();

    // where can this shift, if anyplace?
    ActionEntry action =
      tables->getActionEntry(leftSibling->state, lexerPtr->type);
      
    // we'll set this if we find a valid shift dest
    StateId newState = STATE_INVALID;

    // consult action table, looking only for shifts
    if (tables->isShiftAction(action)) {
      // unambiguous shift
      newState = tables->decodeShift(action, lexerPtr->type);
    }
    else if (tables->isReduceAction(action) ||
             tables->isErrorAction(action)) {
      // reduce or error
      continue;
    }
    else {
      // nondeterministic; get actions
      ActionEntry *entry = tables->decodeAmbigAction(action, leftSibling->state);

      // do each one
      for (int i=0; i<entry[0]; i++) {
        action = entry[i+1];
        if (tables->isShiftAction(action)) {
          // a shift was among the conflicted actions
          newState = tables->decodeShift(action, lexerPtr->type);
          break;
        }
      }

      // did we find a shift?
      if (newState == STATE_INVALID) {
        continue;    // no
      }
    }

    // found a shift to perform
    ACCOUNTING( nondetShift++; )

    // debugging
    TRSPARSE("state " << leftSibling->state <<
             ", shift token " << lexerPtr->tokenDesc() <<
             ", to state " << newState);

    // if there's already a parser with this state
    StackNode *rightSibling = findTopmostParser(newState);
    if (rightSibling != NULL) {
      // no need to create the node
    }

    else {
      // must make a new stack node
      rightSibling = makeStackNode(newState);

      // and add it to the active parsers
      addTopmostParser(rightSibling);
    }

    SemanticValue sval = lexerPtr->sval;
    if (prev) {
      // the 'sval' we just grabbed has already been claimed by
      // 'prev->sval'; get a fresh one by duplicating the latter
      sval = userAct->duplicateTerminalValue(lexerPtr->type, prev->sval);
      
      TRSACTION("  " << userAct->terminalDescription(lexerPtr->type, sval) <<
                " is (@lexer) DUP of " <<
                userAct->terminalDescription(lexerPtr->type, prev->sval));
    }

    // either way, add the sibling link now
    //TRSACTION("grabbed token sval " << lexerPtr->sval);
    prev = rightSibling->addSiblingLink(leftSibling, sval
                                        SOURCELOCARG( lexerPtr->loc ) );

    // adding this sibling link cannot violate the determinDepth
    // invariant of some other node, because all of the nodes created
    // or added-to during shifting do not have anything pointing at
    // them, so in particular nothing points to 'rightSibling'; a simple
    // check of this is to check the reference count and verify it is 1,
    // the 1 being for the 'topmostParsers' list it is on
    xassert(rightSibling->referenceCount == 1);
  }
}


// ------------------ stuff for outputting raw graphs ------------------
#if 0   // disabled for now
// name for graphs (can't have any spaces in the name)
sm_string stackNodeName(StackNode const *sn)
{
  Symbol const *s = sn->getSymbolC();
  char const *symName = (s? s->name.pcharc() : "(null)");
  return sm_stringb(sn->stackNodeId
              << ":col="  << sn->tokenColumn
              << ",st=" << sn->state->id
              << ",sym=" << symName);
}

// name for rules; 'rn' is the 'ruleNo'-th rule in 'sn'
// (again, no spaces allowed)
sm_string reductionName(StackNode const *sn, int ruleNo, Reduction const *red)
{
  return sm_stringb(sn->stackNodeId << "/" << ruleNo << ":"
              << replace(red->production->toString(), " ", "_"));
}                                                            


// this prints the graph in my java graph applet format, where
// nodes lines look like
//   n <name> <optional-desc>
// and edges look like
//   e <from> <to>
// unfortunately, the graph applet needs a bit of work before it
// is worthwhile to use this routinely (though it's great for
// quickly verifying a single (small) parse)
//
// however, it's worth noting that the text output is not entirely
// unreadable...
void GLR::writeParseGraph(char const *fname) const
{
  FILE *out = fopen(sm_stringb("graphs/" << fname), "w");
  if (!out) {
    xsyserror("fopen", sm_stringb("opening file `graphs/" << fname << "'"));
  }

  // header info
  fprintf(out, "# parse graph file: %s\n", fname);
  fprintf(out, "# automatically generated\n"
               "\n");

  #if 0    // can't do anymore because allStackNodes is gone ...
  // for each stack node
  FOREACH_OBJLIST(StackNode, allStackNodes, stackNodeIter) {
    StackNode const *stackNode = stackNodeIter.data();
    sm_string myName = stackNodeName(stackNode);

    // visual delimiter
    fputs(sm_stringb("\n# ------ node: " << myName << " ------\n"), out);

    // write info for the node itself
    fputs(sm_stringb("n " << myName << "\n\n"), out);

    // for all sibling links
    int ruleNo=0;
    FOREACH_OBJLIST(SiblingLink, stackNode->leftSiblings, sibIter) {
      SiblingLink const *link = sibIter.data();

      // write the sibling link
      fputs(sm_stringb("e " << myName << " "
                         << stackNodeName(link->sib) << "\n"), out);

      // ideally, we'd attach the reduction nodes directly to the
      // sibling edge.  however, since I haven't developed the
      // graph applet far enough for that, I'll instead attach it
      // to the stack node directly..

      if (link->treeNode->isNonterm()) {
        // for each reduction node
        FOREACH_OBJLIST(Reduction, link->treeNode->asNonterm().reductions,
                        redIter) {
          Reduction const *red = redIter.data();
          ruleNo++;

          sm_string ruleName = reductionName(stackNode, ruleNo, red);

          // write info for the rule node
          fputs(sm_stringb("n " << ruleName << "\n"), out);

          // put the link from the stack node to the rule node
          fputs(sm_stringb("e " << myName << " " << ruleName << "\n"), out);

          // write all child links
          // ACK!  until my graph format is better, this is almost impossible
          #if 0
          SFOREACH_OBJLIST(StackNode, rule->children, child) {
            fputs(sm_stringb("e " << ruleName << " "
                               << stackNodeName(child.data()) << "\n"), out);
          }
          #endif // 0

          // blank line for visual separation
          fputs("\n", out);
        } // for each reduction
      } // if is nonterminal
    } // for each sibling
  } // for each stack node
  #endif // 0

  // done
  if (fclose(out) != 0) {
    xsyserror("fclose");
  }
}
#endif // 0


// --------------------- testing ------------------------
// read an entire file into a single sm_string
// currenty is *not* pipe-friendly because it must seek
// (candidate for adding to 'str' module)
sm_string readFileIntoString(char const *fname)
{
  // open file
  FILE *fp = fopen(fname, "r");
  if (!fp) {
    xsyserror("fopen", sm_stringb("opening `" << fname << "' for reading"));
  }

  // determine file's length
  if (fseek(fp, 0, SEEK_END) < 0) {
    xsyserror("fseek");
  }
  int len = (int)ftell(fp);      // conceivably problematic cast..
  if (len < 0) {
    xsyserror("ftell");
  }
  if (fseek(fp, 0, SEEK_SET) < 0) {
    xsyserror("fseek");
  }

  // allocate a sufficiently large buffer
  sm_string ret(len);
  
  // read the file into that buffer
  if (fread(ret.pchar(), 1, len, fp) < (size_t)len) {
    xsyserror("fread");
  }

  // close file
  if (fclose(fp) < 0) {
    xsyserror("fclose");
  }

  // return the new sm_string
  return ret;
}


// EOF
@h=tangler('elk/elk_gramanl.cpp')
@select(h)
// gramanl.cc            see license.txt for copyright and terms of use
// code for gramanl.h

#include "elk_gramanl.h"

#include "sm_bit2d.h"
#include "sm_bitarray.h"
#include "sm_strtokp.h"
#include "sm_syserr.h"
#include "sm_trace.h"
#include "sm_nonport.h"
#include "sm_crc.h"
#include "elk_flatutil.h"
#include "elk_grampar.h"
#include "elk_emitcode.h"
#include "sm_strutil.h"
#include "sm_ckheap.h"
#include "elk_genml.h"

#include <fstream.h>     // ofstream
#include <stdlib.h>      // getenv
#include <stdio.h>       // printf

// for ParseTables::emitConstructionCode:
//   linkdepend: emittables.cc


// for now, we'll just have these be global variables; if I later
// decide I actually want more than one at a time, I can move these
// into GrammarAnalysis and push the interfaces to accomodate

// NOTE: only LALR(1) has been recently tested; in particular I
// know that LR(1) is broken (3/26/02)

// LR(0) does all reductions, regardless of what the next token is
static bool const LR0 = false;

// SLR(1) looks at a production's LHS's Follow
static bool const SLR1 = false;

// LR(1) computes context-sensitive follow for each item,
// depending on how that item arises in the item-set DFA
static bool const LR1 = false;

// LALR(1) is like LR(1), except two states are merged if
// they only differ in their items' lookaheads (so it has
// the same # of states as SLR(1), while having some of the
// context-sensitivity of LR(1))
static bool const LALR1 = true;


#if !defined(NDEBUG)     // track unauthorized malloc's
  #define TRACK_MALLOC
#endif

#ifdef TRACK_MALLOC
  // take initial snapsot
  #define INITIAL_MALLOC_STATS() \
    unsigned mallocCt = numMallocCalls();

  // nothing should have been allocated recently; if it has, then
  // print a warning
  #define CHECK_MALLOC_STATS(desc)                                              \
    {                                                                           \
      unsigned newCt = numMallocCalls();                                        \
      if (mallocCt != newCt) {                                                  \
        cout << (newCt - mallocCt) << " malloc calls during " << desc << endl;  \
        mallocCt = newCt;                                                       \
        breaker();                                                              \
      }                                                                         \
    }

  // some unavoidable allocation just happened, so just update counter
  #define UPDATE_MALLOC_STATS() \
    mallocCt = numMallocCalls();
#else
  #define INITIAL_MALLOC_STATS()
  #define CHECK_MALLOC_STATS(desc)
  #define UPDATE_MALLOC_STATS()
#endif


// ----------------- DottedProduction ------------------
#if 0    // used?
DottedProduction::DottedProduction(DottedProduction const &obj)
{
  prod = obj.prod;
  dot = obj.dot;
  afterDot = obj.afterDot;
  firstSet = obj.firstSet;
  canDeriveEmpty = obj.canDeriveEmpty;
}                
#endif // 0


DottedProduction::DottedProduction()
{
  init();
}

void DottedProduction::init()
{
  prod = NULL;
  dot = -1;
  afterDot = NULL;
  canDeriveEmpty = false;
  backPointer = NULL;
}


DottedProduction::~DottedProduction()
{}


// arbitrary integer unique to every symbol and preserved
// across read/write
int symbolIndex(Symbol const *s)
{
  if (s->isTerminal()) {
    // make terminals negative since otherwise they'd
    // collide with nonterminals
    return -( s->asTerminalC().termIndex );
  }
  else {
    return s->asNonterminalC().ntIndex;
  }
}


#if 0
bool DottedProduction::isEqual(DottedProduction const &obj) const
{
  return dot == obj.dot &&
         prod == obj.prod;
}
#endif // 0


void DottedProduction::setProdAndDot(Production const *p, int d)
{
  prod = p;
  dot = d;

  // computing this each time turned out to be significant
  // according to the profiler, so we store it instead
  bool dotAtEnd = (dot == prod->rhsLength());
  afterDot = dotAtEnd? NULL : prod->right.nthC(dot)->sym;
}

Symbol const *DottedProduction::symbolBeforeDotC() const
{
  xassert(!isDotAtStart());
  return prod->right.nthC(dot-1)->sym;
}

#if 0
Symbol const *DottedProduction::symbolAfterDotC() const
{
  xassert(!isDotAtEnd());
  return prod->right.nthC(dot)->sym;
}
#endif // 0


void DottedProduction::print(ostream &os) const
{
  os << prod->left->name << " ->";

  int position = 0;
  for (ObjListIter<Production::RHSElt> iter(prod->right);
       !iter.isDone(); iter.adv(), position++) {
    if (position == dot) {
      os << " .";
    }
    os << " " << iter.data()->sym->toString();
  }
  if (position == dot) {
    os << " .";
  }
}


// ---------------------- LRItem -------------------
LRItem::LRItem(int numTerms, DottedProduction const *dp)
  : dprod(dp),
    lookahead(numTerms)
{}

LRItem::LRItem(LRItem const &obj)
  : dprod(obj.dprod),
    lookahead(obj.lookahead)
{}

LRItem::~LRItem()
{}

LRItem::LRItem(Flatten &flat)
  : dprod(NULL),
    lookahead(flat)
{}

void LRItem::xfer(Flatten &flat)
{
  lookahead.xfer(flat);
}

void LRItem::xferSerfs(Flatten &flat, GrammarAnalysis &g)
{
  if (flat.writing()) {
    flat.writeInt(prodIndex());
    flat.writeInt(getDot());
  }
  else {
    // originally had these directly in the argument list,
    // but order of eval is undefined!
    int idx = flat.readInt();
    int d = flat.readInt();
    dprod = g.getDProdIndex(idx, d);
  }
}


// compare two items in an arbitrary (but deterministic) way so that
// sorting will always put a list of items into the same order, for
// comparison purposes; this doesn't consider the lookahead
STATICDEF int LRItem::diff(LRItem const *a, LRItem const *b, void*)
{
  // check the prodIndex first
  int ret = a->prodIndex() - b->prodIndex();
  if (ret) { return ret; }

  // 'dot'
  ret = a->getDot() - b->getDot();
  return ret;
}


bool firstIncludes(Symbol const *sym, Terminal const *t)
{
  if (sym->isTerminal()) {
    return sym == t;
  }
  else {
    // this generalizes 'isExtendingShift'.. and while this did help
    // eliminate one S/R in a grammar I was working on, there were
    // others that could not be eliminated at all (they were not
    // statically decidable), so this generalization might not be
    // useful afterall
    return sym->asNonterminalC().first.contains(t->termIndex);
  }
}

bool LRItem::isExtendingShift(Nonterminal const *A, Terminal const *t) const
{
  return !dprod->isDotAtEnd() &&                      // shift
         dprod->getProd()->left == A &&               // extending A
         firstIncludes(dprod->symbolAfterDotC(), t);  // with t
}


void LRItem::print(ostream &os, GrammarAnalysis const &g) const
{
  dprod->print(os);
  lookahead.print(os, g);      // prints the separating comma, if necessary
}


// ----------------- ItemSet -------------------
ItemSet::ItemSet(StateId anId, int numTerms, int numNonterms)
  : kernelItems(),
    nonkernelItems(),
    termTransition(NULL),      // inited below
    nontermTransition(NULL),   // inited below
    terms(numTerms),
    nonterms(numNonterms),
    dotsAtEnd(NULL),
    numDotsAtEnd(0),
    stateSymbol(NULL),
    id(anId),
    BFSparent(NULL)
{
  allocateTransitionFunction();
}

void ItemSet::allocateTransitionFunction()
{
  termTransition = new ItemSet* [terms];
  nontermTransition = new ItemSet* [nonterms];

  INTLOOP(t, 0, terms) {
    termTransition[t] = (ItemSet*)NULL;      // means no transition on t
  }
  INTLOOP(n, 0, nonterms) {
    nontermTransition[n] = (ItemSet*)NULL;
  }
}


ItemSet::~ItemSet()
{
  delete[] termTransition;
  delete[] nontermTransition;

  if (dotsAtEnd) {
    delete[] dotsAtEnd;
  }
}


ItemSet::ItemSet(Flatten &flat)
  : termTransition(NULL),
    nontermTransition(NULL),
    dotsAtEnd(NULL),
    numDotsAtEnd(0),
    stateSymbol(NULL),
    BFSparent(NULL)
{}


Production *getNthProduction(Grammar *g, int n)
{
  if (0 <= n && n < g->productions.count()) {
    return g->productions.nth(n);
  }
  else {
    // my access path functions' contract is to
    // return NULL on any error (as opposed to, say,
    // an exception or assertion failure); this serves two
    // purposes:
    //   - the writing code can use it to determine the
    //     maximum value of 'n'
    //   - the reading code can use it to validate 'n',
    //     since that comes from the input file
    return NULL;
  }
}

#if 0    // not needed, doesn't work
DottedProduction *getNthDottedProduction(Production *p, int n)
{
  if (0 <= n && n < (p->rhsLength() + 1)) {
    return p->getDProd(n);
  }
  else {
    return NULL;
  }                                 
}
#endif // 0


void ItemSet::xfer(Flatten &flat)
{
  xferObjList(flat, kernelItems);
  xferObjList(flat, nonkernelItems);

  flat.xferInt(terms);
  flat.xferInt(nonterms);

  // numDotsAtEnd and kernelItemsCRC are computed from
  // other data
  // NEW: but computing them requires the items, which I'm omitting

  flat.xferInt(numDotsAtEnd);
  flat.xferLong((long&)kernelItemsCRC);

  flat.xferInt((int&)id);
}


int ticksComputeNonkernel = 0;

void ItemSet::xferSerfs(Flatten &flat, GrammarAnalysis &g)
{
  // xfer the 'prod' fields of the items
  {
    MUTATE_EACH_OBJLIST(LRItem, kernelItems, k) {
      k.data()->xferSerfs(flat, g);
    }
    MUTATE_EACH_OBJLIST(LRItem, nonkernelItems, n) {
      n.data()->xferSerfs(flat, g);
    }
  }


  #if 0
    // 'kernelItems' and 'nonkernelItems': each one accessed as
    //   g.productions.nth(???)->getDProd(???)
    xferSObjList_twoLevelAccess(
      flat,
      kernelItems,               // serf list
      static_cast<Grammar*>(&g), // root of access path
      getNthProduction,          // first access path link
      getNthDottedProduction);   // second access path link

    #if 1
      xferSObjList_twoLevelAccess(
        flat,
        nonkernelItems,            // serf list
        static_cast<Grammar*>(&g), // root of access path
        getNthProduction,          // first access path link
        getNthDottedProduction);   // second access path link
    #else
      // instead of the above, let's try computing the nonkernel items
      if (flat.reading()) {
        int start = getMilliseconds();
        g.itemSetClosure(*this);
        ticksComputeNonkernel += (getMilliseconds() - start);
      }
    #endif
  #endif // 0

  // these need to be sorted for 'changedItems'; but since
  // we're sorting by *address*, that's not necessarily
  // preserved across read/write
  // NEW: it should be stable now
  //kernelItems.insertionSort(LRItem::diff);


  // transition functions
  if (flat.reading()) {
    allocateTransitionFunction();
  }
  INTLOOP(t, 0, terms) {
    //xferNullableSerfPtrToList(flat, termTransition[t], g.itemSets);
    xferNullableSerfPtr(flat, termTransition[t]);
  }
  INTLOOP(n, 0, nonterms) {
    //xferNullableSerfPtrToList(flat, nontermTransition[n], g.itemSets);
    xferNullableSerfPtr(flat, nontermTransition[n]);
  }


  // dotsAtEnd, numDotsAtEnd, kernelItemsCRC
  //if (flat.reading()) {
  //  changedItems();
  //}
                         
  if (flat.reading()) {
    dotsAtEnd = new LRItem const * [numDotsAtEnd];
  }
  INTLOOP(p, 0, numDotsAtEnd) {
    #if 0
    xferSerfPtr_twoLevelAccess(
      flat,
      const_cast<LRItem*&>(dotsAtEnd[p]),   // serf
      static_cast<Grammar*>(&g), // root of access path
      getNthProduction,          // first access path link
      getNthDottedProduction);   // second access path link
    #endif // 0
    xferSerfPtr(flat, dotsAtEnd[p]);
  }

  xferNullableSerfPtr(flat, stateSymbol);

  xferNullableSerfPtrToList(flat, BFSparent, g.itemSets);
}


Symbol const *ItemSet::computeStateSymbolC() const
{
  // need only check kernel items since all nonkernel items
  // have their dots at the left side
  FOREACH_OBJLIST(LRItem, kernelItems, item) {
    if (! item.data()->isDotAtStart() ) {
      return item.data()->symbolBeforeDotC();
    }
  }
  return NULL;
}


int ItemSet::bcheckTerm(int index) const
{
  xassert(0 <= index && index < terms);
  return index;
}

int ItemSet::bcheckNonterm(int index) const
{
  xassert(0 <= index && index < nonterms);
  return index;
}

ItemSet *&ItemSet::refTransition(Symbol const *sym)
{
  if (sym->isTerminal()) {
    Terminal const &t = sym->asTerminalC();
    return termTransition[bcheckTerm(t.termIndex)];
  }
  else {
    Nonterminal const &nt = sym->asNonterminalC();
    return nontermTransition[bcheckNonterm(nt.ntIndex)];
  }
}


ItemSet const *ItemSet::transitionC(Symbol const *sym) const
{
  return const_cast<ItemSet*>(this)->refTransition(sym);
}


void ItemSet::setTransition(Symbol const *sym, ItemSet *dest)
{
  refTransition(sym) = dest;
}


void ItemSet::removeShift(Terminal const *sym)
{
  refTransition(sym) = NULL;
}


void ItemSet::addKernelItem(LRItem *item)
{
  // add it
  kernelItems.appendUnique(item);
}


void ItemSet::sortKernelItems()
{
  // sort the items to facilitate equality checks
  kernelItems.mergeSort(LRItem::diff);

  // note: the caller must call changedItems
}


bool ItemSet::operator==(ItemSet const &obj) const
{
  // since common case is disequality, check the
  // CRCs first, and only do full check if they
  // match
  if (kernelItemsCRC == obj.kernelItemsCRC) {                 
    // since nonkernel items are entirely determined by kernel
    // items, and kernel items are sorted, it's sufficient to
    // check for kernel list equality
    // OLD: when pointer equality was sufficient
    //   return kernelItems.equalAsPointerLists(obj.kernelItems);
    // NEW: use deep equality check
    return kernelItems.equalAsLists(obj.kernelItems, LRItem::diff);
  }
  else {
    // can't possibly be equal if CRCs differ
    return false;
  }
}


void ItemSet::addNonkernelItem(LRItem *item)
{
  nonkernelItems.appendUnique(item);
  
  // note: the caller is supposed to call changedItems
}


void ItemSet::removeReduce(Production const *prod, Terminal const *sym)
{                       
  MUTATE_EACH_OBJLIST(LRItem, kernelItems, k) {
    if (k.data()->isDotAtEnd() &&
        k.data()->getProd() == prod) {
      k.data()->laRemove(sym->termIndex);
    }
  }

  MUTATE_EACH_OBJLIST(LRItem, nonkernelItems, n) {
    if (n.data()->isDotAtEnd() &&
        n.data()->getProd() == prod) {
      n.data()->laRemove(sym->termIndex);
    }
  }

  #if 0
  ObjListMutator<LRItem> k(kernelItems);
  while (!k.isDone()) {
    if (k.data()->isDotAtEnd() &&
        k.data()->getProd() == prod) {
      k.deleteIt();
    }
    else {
      k.adv();
    }
  }

  changedItems();
  #endif // 0
}


void ItemSet::getAllItems(SObjList<LRItem> &dest, bool nonkernel) const
{
  SObjListMutator<LRItem> mut(dest);

  FOREACH_OBJLIST(LRItem, kernelItems, k) {
    mut.append(const_cast<LRItem*>(k.data()));
  }
  if (nonkernel) {
    FOREACH_OBJLIST(LRItem, nonkernelItems, n) {
      mut.append(const_cast<LRItem*>(n.data()));
    }
  }
}


STATICDEF int ItemSet::diffById(ItemSet const *left, ItemSet const *right, void*)
{
  return left->id - right->id;
}


void ItemSet::throwAwayItems()
{
  // can't delete the whole lists because I need the
  // reductions; among other things, 'dotsAtEnd' refers to them
  deleteNonReductions(kernelItems);
  deleteNonReductions(nonkernelItems);
}

void ItemSet::deleteNonReductions(ObjList<LRItem> &list)
{
  ObjListMutator<LRItem> mut(list);
  while (!mut.isDone()) {
    if (mut.data()->isDotAtEnd()) {
      // keep it
      mut.adv();
    }
    else {
      // trash it
      mut.deleteIt();     // also advances
    }
  }
}


// return the reductions that are ready in this state, given
// that the next symbol is 'lookahead'
void ItemSet::getPossibleReductions(ProductionList &reductions,
                                    Terminal const *lookahead,
                                    bool parsing) const
{
  // for each item with dot at end
  loopi(numDotsAtEnd) {
    LRItem const *item = dotsAtEnd[i];

    if (LR0) {
      // don't check the lookahead
    }
    else if (SLR1) {
      // the follow of its LHS must include 'lookahead'
      if (!item->getProd()->left->follow.contains(lookahead->termIndex)) {    // (constness)
        if (parsing && tracingSys("parse")) {
          trace("parse") << "state " << id
                         << ", not reducing by " 
                         << item->getProd()->toString(false /*printType*/)
                         << " because " << lookahead->toString()
                         << " is not in follow of "
                         << item->getProd()->left->name << endl;
        }
        continue;
      }
    }
    else if (LALR1 || LR1) {
      // the item's lookahead must include 'lookahead'
      if (!item->laContains(lookahead->termIndex)) {
        if (parsing && tracingSys("parse")) {
          trace("parse") << "state " << id
                         << ", not reducing by "
                         << item->getProd()->toString(false /*printType*/)
                         << " because " << lookahead->toString()
                         << " is not in lookahead" << endl;
        }
        continue;
      }
    }
    else {
      xfailure("no LR variant specified?");
    }

    // ok, this one's ready
    reductions.append(const_cast<Production*>(item->getProd()));       // (constness)
  }
}


bool ItemSet::mergeLookaheadsInto(ItemSet &dest) const
{        
  // will return true if any changes made
  bool changes = false;

  // iterate over both kernel lists simultaneously
  ObjListIter<LRItem> srcIter(kernelItems);
  ObjListMutator<LRItem> destIter(dest.kernelItems);
  while (!srcIter.isDone() && !destIter.isDone()) {
    LRItem const &srcItem = *(srcIter.data());
    LRItem &destItem = *(destIter.data());

    // the caller should already have established equality of the
    // non-lookahead components of the kernel items
    xassert(srcItem.equalNoLA(destItem));

    // merge lookaheads
    if (destItem.laMerge(srcItem)) {
      changes = true;
    }
    
    srcIter.adv();
    destIter.adv();
  }

  // kernel list lengths are supposed to be the same
  xassert(srcIter.isDone() && destIter.isDone());

  return changes;
}


bool ItemSet::hasExtendingShift(Nonterminal const *A, Terminal const *t) const
{
  FOREACH_OBJLIST(LRItem, kernelItems, iter1) {
    if (iter1.data()->isExtendingShift(A, t)) { return true; }
  }
  FOREACH_OBJLIST(LRItem, nonkernelItems, iter2) {
    if (iter2.data()->isExtendingShift(A, t)) { return true; }
  }
  return false;
}


Production const *ItemSet::getFirstReduction() const
{
  xassert(numDotsAtEnd >= 1);
  return dotsAtEnd[0]->getProd();
}


void ItemSet::changedItems()
{
  // -- recompute dotsAtEnd --
  // collect all items
  SObjList<LRItem> items;      // (constness) 'items' shouldn't be used to modify the elements
  getAllItems(items);

  // count number with dots at end
  int count = 0;
  {
    SFOREACH_OBJLIST(LRItem, items, itemIter) {
      LRItem const *item = itemIter.data();

      if (item->isDotAtEnd()) {
        count++;
      }
    }
  }

  // get array of right size
  if (dotsAtEnd  &&  count == numDotsAtEnd) {
    // no need to reallocate, already correct size
  }
  else {
    // throw old away
    if (dotsAtEnd) {
      delete[] dotsAtEnd;
    }

    // allocate new array
    numDotsAtEnd = count;
    dotsAtEnd = new LRItem const * [numDotsAtEnd];
  }

  // fill array
  int index = 0;
  SFOREACH_OBJLIST(LRItem, items, itemIter) {
    LRItem const *item = itemIter.data();

    if (item->isDotAtEnd()) {
      dotsAtEnd[index] = item;
      index++;
    }
  }

  // verify both loops executed same number of times
  xassert(index == count);

  // compute CRC; in this function, I just allocate here since this
  // function is already allocation-happy
  GrowArray<DottedProduction const*> array(0 /*allocate later*/);
  computeKernelCRC(array);

  // compute this so we can throw away items later if we want to
  stateSymbol = computeStateSymbolC();
}


void ItemSet::computeKernelCRC(GrowArray<DottedProduction const*> &array)
{
  int numKernelItems = kernelItems.count();
  
  // expand as necessary, but don't get smaller
  array.ensureAtLeast(numKernelItems);

  // we will crc the prod/dot fields, using the pointer representation
  // of 'dprod'; assumes the items have already been sorted!
  int index = 0;
  FOREACH_OBJLIST(LRItem, kernelItems, kitem) {
    array[index] = kitem.data()->dprod;
    index++;
  }

  // CRC the buffer
  kernelItemsCRC = crc32((unsigned char const*)(array.getArray()),
                         sizeof(array[0]) * numKernelItems);
}


void ItemSet::print(ostream &os, GrammarAnalysis const &g, 
                    bool nonkernel) const
{
  os << "ItemSet " << id << ":\n";

  // collect all items
  SObjList<LRItem> items;     // (constness) don't use 'item' to modify elements
  getAllItems(items, nonkernel);

  // for each item  
  SFOREACH_OBJLIST(LRItem, items, itemIter) {
    LRItem const *item = itemIter.data();

    // print its text
    os << "  ";
    item->print(os, g);
    os << "      ";

    // print any transitions on its after-dot symbol
    if (!item->isDotAtEnd()) {
      ItemSet const *is = transitionC(item->symbolAfterDotC());
      if (is == NULL) {
        // this happens if I print the item set before running closure,
        // and also after prec/assoc disambiguation
        os << "(no transition)";
      }
      else {
        os << "--> " << is->id;
      }
    }
    os << endl;
  }

  // print transition function directly, since I'm now throwing
  // away items sometimes
  for (int t=0; t<terms; t++) {
    if (termTransition[t]) {
      os << "  on terminal " << g.getTerminal(t)->name 
         << " go to " << termTransition[t]->id << endl;
    }
  }

  for (int n=0; n<nonterms; n++) {
    if (nontermTransition[n]) {
      os << "  on nonterminal " << g.getNonterminal(n)->name 
         << " go to " << nontermTransition[n]->id << endl;
    }
  }
  
  for (int p=0; p<numDotsAtEnd; p++) {
    os << "  can reduce by " << dotsAtEnd[p]->getProd()->toString() << endl;
  }
}


void ItemSet::writeGraph(ostream &os, GrammarAnalysis const &g) const
{
  // node: n <name> <desc>
  os << "\nn ItemSet" << id << " ItemSet" << id << "/";
    // rest of desc will follow

  // collect all items
  SObjList<LRItem> items;         // (constness) don't use 'items' to modify elements
  getAllItems(items);

  // for each item, print the item text
  SFOREACH_OBJLIST(LRItem, items, itemIter) {
    LRItem const *item = itemIter.data();

    // print its text
    os << "   ";
    item->print(os, g);

    // THIS IS A PROBLEM!  the item's output will include
    // slashes too, if it has >1 lookahead token ... !
    os << "/";      // line separator in my node format
  }
  os << endl;

  // print transitions on terminals
  INTLOOP(t, 0, terms) {
    if (termTransition[t] != NULL) {
      os << "e ItemSet" << id
         << " ItemSet" << termTransition[t]->id << endl;
    }
  }

  // print transitions on nonterminals
  INTLOOP(nt, 0, nonterms) {
    if (nontermTransition[nt] != NULL) {
      os << "e ItemSet" << id
         << " ItemSet" << nontermTransition[nt]->id << endl;
    }
  }
}


// ------------------------ GrammarAnalysis --------------------
GrammarAnalysis::GrammarAnalysis()
  : derivable(NULL),
    indexedNonterms(NULL),
    indexedTerms(NULL),
    numNonterms(0),
    numTerms(0),
    productionsByLHS(NULL),
    dottedProds(NULL),
    indexedProds(NULL),
    numProds(0),
    initialized(false),
    nextItemSetId(0),    // [ASU] starts at 0 too
    itemSets(),
    startState(NULL),
    cyclic(false),
    symOfInterest(NULL),
    errors(0),
    tables(NULL)
{}


GrammarAnalysis::~GrammarAnalysis()
{
  if (indexedNonterms != NULL) {
    delete indexedNonterms;
  }

  if (indexedTerms != NULL) {
    delete indexedTerms;
  }

  if (productionsByLHS != NULL) {
    // empties all lists automatically because of "[]"
    delete[] productionsByLHS;
  }

  if (indexedProds != NULL) {
    delete[] indexedProds;
  }

  deleteDottedProductions();

  if (derivable != NULL) {
    delete derivable;
  }

  if (tables) {
    delete tables;
  }
}


Terminal const *GrammarAnalysis::getTerminal(int index) const
{
  xassert((unsigned)index < (unsigned)numTerms);
  return indexedTerms[index];
}

Nonterminal const *GrammarAnalysis::getNonterminal(int index) const
{
  xassert((unsigned)index < (unsigned)numNonterms);
  return indexedNonterms[index];
}

Production const *GrammarAnalysis::getProduction(int index) const
{
  xassert((unsigned)index < (unsigned)numProds);
  return indexedProds[index];
}

ItemSet const *GrammarAnalysis::getItemSet(int index) const
{
  // no pretense of efficiency; this is only used interactively
  FOREACH_OBJLIST(ItemSet, itemSets, iter) {
    if (iter.data()->id == index) {
      return iter.data();
    }
  }
  return NULL;
}


void GrammarAnalysis::xfer(Flatten &flat)
{
  Grammar::xfer(flat);

  xferOwnerPtr(flat, derivable);

  // delay indexed[Non]Terms, productionsByLHS,
  // and initialized

  flat.xferInt(nextItemSetId);

  xferObjList(flat, itemSets);
  xferSerfPtrToList(flat, startState, itemSets);

  flat.xferBool(cyclic);

  // don't bother xferring 'symOfInterest', since it's
  // only used for debugging
    
  // 7/27/03: tables are no longer xferrable
  //xferOwnerPtr(flat, tables);

  // now do the easily-computable stuff
  // NOTE: these functions are also called by initializeAuxData,
  // so they need to serve both callers correctly
  computeIndexedNonterms();
  computeIndexedTerms();
  computeProductionsByLHS();
  createDottedProductions();

  // do serfs after because if I want to compute the
  // nonkernel items instead of storing them, I need
  // the indices
  MUTATE_EACH_OBJLIST(ItemSet, itemSets, iter) {
    iter.data()->xferSerfs(flat, *this);
  }

  flat.xferBool(initialized);
}


void GrammarAnalysis::
  printProductions(ostream &os, bool printCode) const
{
  if (cyclic) {
    os << "(cyclic!) ";
  }
  Grammar::printProductions(os, printCode);
}


void GrammarAnalysis::
  printProductionsAndItems(ostream &os, bool printCode) const
{
  printProductions(os, printCode);

  FOREACH_OBJLIST(ItemSet, itemSets, iter) {
    iter.data()->print(os, *this);
  }
}


void printSymbols(ostream &os, ObjList<Symbol> const &list)
{
  for (ObjListIter<Symbol> iter(list);
       !iter.isDone(); iter.adv()) {
    os << "  " << *(iter.data()) << endl;
  }
}


bool GrammarAnalysis::addDerivable(Nonterminal const *left, Nonterminal const *right)
{
  return addDerivable(left->ntIndex, right->ntIndex);
}

bool GrammarAnalysis::addDerivable(int left, int right)
{
  // Almost as an aside, I'd like to track cyclicity in grammars.
  // It's always true that N ->* N, because 0 steps are allowed.
  // A grammar is cyclic if N ->+ N, i.e. it derives itself in
  // 1 or more steps.
  //
  // We can detect that fairly easily by tracking calls to
  // this fn with left==right.  Since N ->* N in 0 steps is
  // recorded during init (and *not* by calling this fn), the
  // only calls to this with left==right will be when the
  // derivability code detects a nonzero-length path.

  if (left==right) {
    Nonterminal *NT = indexedNonterms[left];    // ==right
    if (!NT->cyclic) {
      trace("derivable")
        << "discovered that " << NT->name << " ->+ "
        << NT->name << " (i.e. is cyclic)\n";
      NT->cyclic = true;
      cyclic = true;     // for grammar as a whole

      // Even though we didn't know this already, it doesn't
      // constitute a change in the ->* relation (which is what the
      // derivability code cares about), so we do *not* report a
      // change for the cyclicty detection.
    }
  }

  // we only made a change, and hence should return true,
  // if there was a 0 here before
  return 0 == derivable->testAndSet(point(left, right));
}


bool GrammarAnalysis::canDerive(Nonterminal const *left, Nonterminal const *right) const
{
  return canDerive(left->ntIndex, right->ntIndex);
}

bool GrammarAnalysis::canDerive(int left, int right) const
{
  return 1 == derivable->get(point(left, right));
}


void GrammarAnalysis::initDerivableRelation()
{
  // two-dimensional matrix to represent token derivabilities
  derivable = new Bit2d(point(numNonterms, numNonterms));

  // initialize it
  derivable->setall(0);
  loopi(numNonterms) {
    derivable->set(point(i,i));
      // every nonterminal can derive itself in 0 or more steps
      // (specifically, in 0 steps, at least)
      //
      // NOTE: we do *not* call addDerivable because that would
      // mess up the cyclicity detection logic
  }
}


bool GrammarAnalysis::canDeriveEmpty(Nonterminal const *nonterm) const
{
  return canDerive(nonterm, &emptyString);
}


bool GrammarAnalysis::sequenceCanDeriveEmpty(RHSEltList const &list) const
{
  RHSEltListIter iter(list);
  return iterSeqCanDeriveEmpty(iter);
}

bool GrammarAnalysis::iterSeqCanDeriveEmpty(RHSEltListIter iter) const
{
  // look through the sequence beginning with 'iter'; if any members cannot
  // derive emptyString, fail
  for (; !iter.isDone(); iter.adv()) {
    if (iter.data()->sym->isTerminal()) {
      return false;    // terminals can't derive emptyString
    }

    if (!canDeriveEmpty(&( iter.data()->sym->asNonterminalC() ))) {
      return false;    // nonterminal that can't derive emptyString
    }
  }

  return true;
}


bool GrammarAnalysis::firstIncludes(Nonterminal const *NT, Terminal const *term) const
{
  return NT->first.contains(term->termIndex);
}

#if 0
bool GrammarAnalysis::addFirst(Nonterminal *NT, Terminal *term)
{
  return NT->first.prependUnique(term);

  // regarding non-constness of 'term':
  // highly nonideal.. the problem is that by using annotations in
  // the structures themselves, I have a hard time saying that I
  // intend to modify the annotations but not the "key" data...
  // this cast is really a symptom of that too.. (and, perhaps, also
  // that I don't have a List class that promises to never permit
  // modification of the pointed-to data.. but it's not clear I'd
  // be better of using it here even if I had it)
}
#endif // 0


bool GrammarAnalysis::followIncludes(Nonterminal const *NT, Terminal const *term) const
{
  return NT->follow.contains(term->termIndex);
}
 
#if 0
// returns true if Follow(NT) is changed by adding 'term' to it
bool GrammarAnalysis::addFollow(Nonterminal *NT, Terminal *term)
{
  return NT->follow.prependUnique(term);
}    
#endif // 0


// ----------------- Grammar algorithms --------------------------
// create and initialize 'indexedNonterms'
void GrammarAnalysis::computeIndexedNonterms()
{
  // map: ntIndex -> Nonterminal*
  numNonterms = Grammar::numNonterminals();
  indexedNonterms = new Nonterminal* [numNonterms];

  // fill it
  indexedNonterms[emptyStringIndex] = &emptyString;
  int index = emptyStringIndex;
  emptyString.ntIndex = index++;

  for (ObjListMutator<Nonterminal> sym(nonterminals);
       !sym.isDone(); index++, sym.adv()) {
    indexedNonterms[index] = sym.data();    // map: index to symbol
    sym.data()->ntIndex = index;            // map: symbol to index
  }
}


// create and initialize 'indexedTerms'
void GrammarAnalysis::computeIndexedTerms()
{
  // map: termIndex -> Terminal*
  // the ids have already been assigned; but I'm going to continue
  // to insist on a contiguous space starting at 0
  numTerms = Grammar::numTerminals();
  indexedTerms = new Terminal* [numTerms];
  loopi(numTerminals()) {
    indexedTerms[i] = NULL;      // used to track id duplication
  }
  for (ObjListMutator<Terminal> sym(terminals);
       !sym.isDone(); sym.adv()) {
    int index = sym.data()->termIndex;   // map: symbol to index
    if (indexedTerms[index] != NULL) {
      xfailure(sm_stringc << "terminal index collision at index " << index);
    }
    indexedTerms[index] = sym.data();    // map: index to symbol
  }
}


// set the first/follow of all nonterminals to the correct size
void GrammarAnalysis::resetFirstFollow()
{
  MUTATE_EACH_NONTERMINAL(nonterminals, sym) {
    sym.data()->first.reset(numTerminals());
    sym.data()->follow.reset(numTerminals());
  }
}


// create and initialize 'productionsByLHS' and 'indexedProds'
void GrammarAnalysis::computeProductionsByLHS()
{
  // map: nonterminal -> productions with that nonterm on LHS
  productionsByLHS = new SObjList<Production> [numNonterms];
  
  // map: prodIndex -> production
  numProds = productions.count();
  indexedProds = new Production* [numProds];
  memset(indexedProds, 0, sizeof(*indexedProds) * numProds);

  // fill in both maps
  {
    MUTATE_EACH_PRODUCTION(productions, prod) {        // (constness)
      int LHSindex = prod.data()->left->ntIndex;
      xassert(LHSindex < numNonterms);

      productionsByLHS[LHSindex].append(prod.data());
      indexedProds[prod.data()->prodIndex] = prod.data();
    }
  }                                                      

  // verify we filled the 'prodIndex' map
  for (int id=0; id<numProds; id++) {
    xassert(indexedProds[id] != NULL);
  }
}


void GrammarAnalysis::createDottedProductions()
{
  // map: prodIndex x dotPosn -> DottedProduction
  //DottedProduction const **
  dottedProds = new DottedProduction* [numProds];
  memset(dottedProds, 0, sizeof(*dottedProds) * numProds);

  FOREACH_PRODUCTION(productions, iter) {
    Production const *prod = iter.data();
    int rhsLen = prod->rhsLength();
    xassert(rhsLen >= 0);
    int id = prod->prodIndex;

    // one dottedproduction for every dot position, which is one
    // more than the # of RHS elements
    DottedProduction *array = new DottedProduction[rhsLen + 1];
    dottedProds[id] = array;

    // fill in each one
    for (int posn=0; posn <= rhsLen; posn++) {
      array[posn].setProdAndDot(prod, posn);
    }
  }

  // verify we filled the whole table, i.e. that the production
  // indices form a dense map
  for (int id=0; id<numProds; id++) {
    xassert(dottedProds[id] != NULL);
  }
}


void GrammarAnalysis::deleteDottedProductions()
{
  if (dottedProds != NULL) {
    for (int id=0; id<numProds; id++) {
      delete[] dottedProds[id];
    }
    delete[] dottedProds;
    dottedProds = NULL;
  }
}


DottedProduction const *GrammarAnalysis::
  getDProd(Production const *prod, int posn) const
{
  xassert(posn <= prod->rhsLength());
  return &( dottedProds[prod->prodIndex][posn] );
}

DottedProduction const *GrammarAnalysis::
  getDProdIndex(int prodIndex, int posn) const
{
  // go through the other fn to bounds-check 'posn'
  return getDProd(getProduction(prodIndex), posn);
}


#ifndef NDEBUG
DottedProduction const *GrammarAnalysis::
  nextDProd(DottedProduction const *dp) const
{
  xassert(!dp->isDotAtEnd());
  return dp + 1;
}
#endif // !NDEBUG


// NOTE: the sequence of initialization actions in this function
// and the functions it calls must interact properly with the
// sequence in GrammarAnalysis::xfer
void GrammarAnalysis::initializeAuxData()
{
  // at the moment, calling this twice leaks memory
  xassert(!initialized);

  computeIndexedNonterms();
  computeIndexedTerms();
  resetFirstFollow();

  computeProductionsByLHS();
  computeReachable();

  // finish the productions before we compute the
  // dotted productions
  MUTATE_EACH_PRODUCTION(productions, prod) {
    prod.data()->finished(numTerminals());
  }

  createDottedProductions();

  // initialize the derivable relation
  initDerivableRelation();

  // mark the grammar as initialized
  initialized = true;
}


void GrammarAnalysis::computeWhatCanDeriveWhat()
{
  xassert(initialized);


  // iterate: propagate 'true' bits across the derivability matrix
  // (i.e. compute transitive closure on the canDerive relation)
  for (;;) {
    int changes = 0;       // for this iter, # of times we set a matrix bit

    // --------- first part: add new canDerive relations --------
    // loop over all productions
    for (ObjListIter<Production> prodIter(productions);
         !prodIter.isDone(); prodIter.adv()) {
      // convenient alias
      Production const *prod = prodIter.data();

      // since I don't include 'empty' explicitly in my rules, I won't
      // conclude that anything can derive empty, which is a problem;
      // so I special-case it here
      if (prod->right.isEmpty()) {
        addDerivable(prod->left, &emptyString);
        continue;       // no point in looping over RHS symbols since there are none
      }

      // iterate over RHS symbols, seeing if the LHS can derive that
      // RHS symbol (by itself)
      for (RHSEltListIter rightSym(prod->right);
           !rightSym.isDone(); rightSym.adv()) {

        if (rightSym.data()->sym->isTerminal()) {
          // if prod->left derives a sm_string containing a terminal,
          // then it can't derive any nontermial alone (using this
          // production, at least) -- empty is considered a nonterminal
          break;
        }

        // otherwise, it's a nonterminal
        Nonterminal const &rightNT = rightSym.data()->sym->asNonterminalC();

        // check if we already know that LHS derives rightNT
        if (canDerive(prod->left, &rightNT)) {
          // we already know that prod->left derives rightSym,
          // so let's not check it again
        }

        else {
          // we are wondering if prod->left can derive rightSym.. for
          // this to be true, every symbol that comes after rightSym
          // must be able to derive emptySymbol (we've already verified
          // by now that every symbol to the *left* can derive empty)
          RHSEltListIter afterRightSym(rightSym);
          bool restDeriveEmpty = true;
          for (afterRightSym.adv();    // *after* right symbol
               !afterRightSym.isDone(); afterRightSym.adv()) {

            if (afterRightSym.data()->sym->isTerminal()  ||
                  // if it's a terminal, it can't derive emptyString
                !canDeriveEmpty(&( afterRightSym.data()->sym->asNonterminalC() ))) {
                  // this symbol can't derive empty sm_string (or, we don't
                  // yet know that it can), so we conclude that prod->left
                  // can't derive rightSym
              restDeriveEmpty = false;
              break;
            }
          }

          if (restDeriveEmpty) {
            // we have discovered that prod->left can derive rightSym
            bool chgd = addDerivable(prod->left, &rightNT);
            xassert(chgd);    // above, we verified we didn't already know this

            changes++;

            trace("derivable") 
              << "discovered (by production): " << prod->left->name
              << " ->* " << rightNT.name << "\n";
          }
        }

        // ok, we've considered prod->left deriving rightSym.  now, we
        // want to consider whether prod->left can derive any of the
        // symbols that follow rightSym in this production.  for this
        // to be true, rightSym itself must derive the emptyString
        if (!canDeriveEmpty(&rightNT)) {
          // it doesn't -- no point in further consideration of
          // this production
          break;
        }
      } // end of loop over RHS symbols
    } // end of loop over productions


    // -------- second part: compute closure over existing relations ------
    // I'll do this by computing R + R^2 -- that is, I'll find all
    // paths of length 2 and add an edge between their endpoints.
    // I do this, rather than computing the entire closure now, since
    // on the next iter I will add more relations and have to re-do
    // a full closure; iterative progress seems a better way.

    // I don't consider edges (u,u) because it messes up my cyclicty
    // detection logic.  (But (u,v) and (v,u) is ok, and in fact is
    // what I want, for detecting cycles.)

    // for each node u (except empty)
    int numNonterms = numNonterminals();
    for (int u=1; u<numNonterms; u++) {
      // for each edge (u,v) where u != v
      for (int v=0; v<numNonterms; v++) {
        if (u==v || !canDerive(u,v)) continue;

        // for each edge (v,w) where v != w
        for (int w=0; w<numNonterms; w++) {
          if (v==w || !canDerive(v,w)) continue;

          // add an edge (u,w), if there isn't one already
          if (addDerivable(u,w)) {
            changes++;
            trace("derivable") 
              << "discovered (by closure step): "
              << indexedNonterms[u]->name << " ->* "
              << indexedNonterms[w]->name << "\n";
          }
        }
      }
    }


    // ------ finally: iterate until no changes -------
    if (changes == 0) {
      // didn't make any changes during the last iter, so
      // everything has settled
      break;
    }
  } // end of loop until settles


  // I used to do all closure here and no closure in the loop.
  // But that fails in cases where closure (when it reveals
  // more things that derive emptyString) yields new opportunities
  // for derives-relation discovery.  Therefore I now alternate
  // between them, and at the end, no closure is necessary.
}


// set Nonterminal::superset to correspond to Nonterminal::subsets
void GrammarAnalysis::computeSupersets()
{
  FOREACH_OBJLIST_NC(Nonterminal, nonterminals, iter1) {
    Nonterminal *super = iter1.data();

    SFOREACH_OBJLIST_NC(Nonterminal, super->subsets, iter2) {
      Nonterminal *sub = iter2.data();

      // for now, only handle 'super' as a partial function      
      if (sub->superset != NULL) {
        xfailure(sm_stringc << sub->name << " has more than one superset");
      }
      sub->superset = super;
    }
  }
}


// Compute, for each nonterminal, the "First" set, defined as:
//
//   First(N) = { x | N ->* x alpha }, where alpha is any sequence
//                                     of terminals and nonterminals
//
// If N can derive emptyString, I'm going to say that empty is
// *not* in First, despite what Aho/Sethi/Ullman says.  I do this
// because I have that information readily as my derivable relation,
// and because it violates the type system I've devised.
//
// I also don't "compute" First for terminals, since they are trivial
// (First(x) = {x}).
void GrammarAnalysis::computeFirst()
{
  bool tr = tracingSys("first");
  int numTerms = numTerminals();

  // iterate, looking for new First members, until no changes
  int changes = 1;   // so the loop begins
  while (changes > 0) {
    changes = 0;

    // for each production
    for (ObjListMutator<Production> prodIter(productions);
         !prodIter.isDone(); prodIter.adv()) {
      // convenient aliases
      Production *prod = prodIter.data();
      Nonterminal *LHS = prod->left;
        // the list iter is mutating because I modify LHS's First set

      // compute First(RHS-sequence)
      TerminalSet firstOfRHS(numTerms);
      firstOfSequence(firstOfRHS, prod->right);

      // store this back into 'prod'
      prod->firstSet.merge(firstOfRHS);

      // add everything in First(RHS-sequence) to First(LHS)
      if (LHS->first.merge(firstOfRHS)) {
        changes++;
        if (tr) {
          ostream &trs = trace("first");
          trs << "added ";
          firstOfRHS.print(trs, *this);
          trs << " to " << LHS->name << " because of "
              << prod->toString() << endl;
        }
      }
    } // for (productions)
  } // while (changes)

  if (tr) {
    FOREACH_NONTERMINAL(nonterminals, iter) {
      Nonterminal const &nt = *(iter.data());

      ostream &trs = trace("first") << " " << nt.name << ": ";
      nt.first.print(trs, *this);
      trs << endl;
    }
  }
}


// 'sequence' isn't const because we need to hand pointers over to
// the 'destList', which isn't const; similarly for 'this'
// (what I'd like here is to say that 'sequence' and 'this' are const
// if 'destList' can't modify the things it contains)
void GrammarAnalysis::firstOfSequence(TerminalSet &destList,
                                      RHSEltList const &sequence)
{
  RHSEltListIter iter(sequence);
  firstOfIterSeq(destList, iter);
}

// similar to above, 'sym' needs to be a mutator
void GrammarAnalysis::firstOfIterSeq(TerminalSet &destList,
                                     RHSEltListIter sym)
{
  //int numTerms = numTerminals();

  // for each sequence member such that all
  // preceeding members can derive emptyString
  for (; !sym.isDone(); sym.adv()) {
    // LHS -> x alpha   means x is in First(LHS)
    if (sym.data()->sym->isTerminal()) {
      destList.add(sym.data()->sym->asTerminal().termIndex);
      break;    // stop considering RHS members since a terminal
                // effectively "hides" all further symbols from First
    }

    // sym must be a nonterminal
    Nonterminal const &nt = sym.data()->sym->asNonterminalC();

    // anything already in nt's First should be added to destList
    destList.merge(nt.first);

    // if nt can't derive emptyString, then it blocks further
    // consideration of right-hand side members
    if (!canDeriveEmpty(&nt)) {
      break;
    }
  } // for (RHS members)
}


void GrammarAnalysis::computeDProdFirsts()
{
  // for each production..
  FOREACH_PRODUCTION(productions, prodIter) {
    // for each dotted production where the dot is not at the end..
    int rhsLen = prodIter.data()->rhsLength();
    for (int posn=0; posn <= rhsLen; posn++) {
      DottedProduction *dprod = getDProd_nc(prodIter.data(), posn);

      // compute its first
      RHSEltListIter symIter(dprod->getProd()->right, posn);
      dprod->firstSet.reset(numTerms);
      firstOfIterSeq(dprod->firstSet, symIter);

      // can it derive empty?
      dprod->canDeriveEmpty = iterSeqCanDeriveEmpty(symIter);
    }
  }
}


void GrammarAnalysis::computeFollow()
{
  int numTerms = numTerminals();

  // loop until no changes
  int changes = 1;
  while (changes > 0) {
    changes = 0;

    // 'mutate' is needed because adding 'term' to the follow of 'nt'
    // needs a mutable 'term' and 'nt'

    // for each production
    MUTATE_EACH_PRODUCTION(productions, prodIter) {
      Production *prod = prodIter.data();

      // for each RHS nonterminal member
      MUTATE_EACH_OBJLIST(Production::RHSElt, prod->right, rightSym) {
        if (rightSym.data()->sym->isTerminal()) continue;

        // convenient alias
        Nonterminal &rightNT = rightSym.data()->sym->asNonterminal();

        // I'm not sure what it means to compute Follow(emptyString),
        // so let's just not do so
        if (&rightNT == &emptyString) {
          continue;
        }

        // an iterator pointing to the symbol just after
        // 'rightSym' will be useful below
        RHSEltListMutator afterRightSym(rightSym);
        afterRightSym.adv();    // NOTE: 'isDone()' may be true now

        // rule 1:
        // if there is a production A -> alpha B beta, then
        // everything in First(beta) is in Follow(B)
        {
          // compute First(beta)
          TerminalSet firstOfBeta(numTerms);
          firstOfIterSeq(firstOfBeta, afterRightSym);

          // put those into Follow(rightNT)
          if (rightNT.follow.merge(firstOfBeta)) {
            changes++;
            if (&rightNT == symOfInterest) {
              ostream &trs = trace("follow-sym");
              trs << "Follow(" << rightNT.name
                  << "): adding ";
              firstOfBeta.print(trs, *this);
              trs << " by first(RHS-tail) of " << *prod
                  << endl;
            }
          }
        }

        // rule 2:
        // if there is a production A -> alpha B, or a
        // production A -> alpha B beta where beta ->* empty ...
        if (iterSeqCanDeriveEmpty(afterRightSym)) {
          // ... then everything in Follow(A) is in Follow(B)
          if (rightNT.follow.merge(prod->left->follow)) {
            changes++;
            if (&rightNT == symOfInterest) {
              ostream &trs = trace("follow-sym");
              trs << "Follow(" << rightNT.name
                  << "): adding ";
              prod->left->follow.print(trs, *this);
              trs << " by follow(LHS) of " << *prod
                  << endl;
            }
          }
        }

      } // for each RHS nonterminal member
    } // for each production
  } // until no changes
}


// [ASU] alg 4.4, p.190
void GrammarAnalysis::computePredictiveParsingTable()
{
  int numTerms = numTerminals();
  int numNonterms = numNonterminals();

  // the table will be a 2d array of lists of productions
  ProductionList *table = new ProductionList[numTerms * numNonterms];     // (owner)
  #define TABLE(term,nt) table[(term) + (nt)*numNonterms]

  // for each production 'prod' (non-const iter because adding them
  // to ProductionList, which doesn't promise to not change them)
  MUTATE_EACH_PRODUCTION(productions, prodIter) {
    Production *prod = prodIter.data();

    // for each terminal 'term' in First(RHS)
    TerminalSet firsts(numTerms);
    firstOfSequence(firsts, prod->right);
    for (int termIndex=0; termIndex<numTerms; termIndex++) {
      if (!firsts.contains(termIndex)) continue;

      // add 'prod' to table[LHS,term]
      TABLE(prod->left->ntIndex, termIndex).prependUnique(prod);
    }

    // if RHS ->* emptyString, ...
    if (sequenceCanDeriveEmpty(prod->right)) {
      // ... then for each terminal 'term' in Follow(LHS), ...
      for (int termIndex=0; termIndex<numTerms; termIndex++) {
        if (!firsts.contains(termIndex)) continue;

        // ... add 'prod' to table[LHS,term]
        TABLE(prod->left->ntIndex, termIndex).prependUnique(prod);
      }
    }
  }


  // print the resulting table
  ostream &os = trace("pred-table") << endl;

  // for each nonterminal
  INTLOOP(nonterm, 0, numNonterms) {
    os << "Row " << indexedNonterms[nonterm]->name << ":\n";

    // for each terminal
    INTLOOP(term, 0, numTerms) {
      os << "  Column " << indexedTerms[term]->name << ":";

      // for each production in table[nonterm,term]
      SFOREACH_PRODUCTION(TABLE(nonterm,term), prod) {
        os << "   ";
        prod.data()->print(os);
      }

      os << endl;
    }
  }

  // cleanup
  #undef TABLE
  delete[] table;
}


// these hashtables are keyed using the DottedProduction,
// but yield LRItems as values

// for storing dotted productions in a hash table, this is
// the hash function itself
STATICDEF unsigned LRItem::hash(DottedProduction const *key)
{
  //DottedProduction const *dp = (DottedProduction const*)key;

  // on the assumption few productions have 20 RHS elts..
  //int val = dp->dot + (20 * dp->prod->prodIndex);

  // just use the address.. they're all shared..
  return HashTable::lcprngHashFn((void*)key);
}

// given the data, yield the key
STATICDEF DottedProduction const *LRItem::dataToKey(LRItem *it)
{
  return it->dprod;
}

// compare two dotted production keys for equality; since dotted
// productions are shared, pointer equality suffices
STATICDEF bool LRItem::dpEqual(DottedProduction const *key1, 
                               DottedProduction const *key2)
{
  return key1 == key2;
}


// based on [ASU] figure 4.33, p.223
// NOTE: sometimes this is called with nonempty nonkernel items...
void GrammarAnalysis::itemSetClosure(ItemSet &itemSet)
{
  bool const tr = tracingSys("closure");
  ostream &trs = trace("closure");     // trace stream
  if (tr) {
    trs << "computing closure of ";
    itemSet.print(trs, *this);
  }

  // hashtable, list of items still yet to close; items are
  // simultaneously in both the hash and the list, or not in either
  #if 0
  OwnerKHashArray<LRItem, DottedProduction> workhash(
    &LRItem::dataToKey,
    &LRItem::hash,
    &LRItem::dpEqual, 13);
  #endif // 0
  
  // every 'item' on the worklist has item->dprod->backPointer == item;
  // every 'dprod' not associated has dprod->backPointer == NULL
  ArrayStack<LRItem*> worklist;

  // scratch terminal set for singleItemClosure
  TerminalSet scratchSet(numTerminals());

  // and another for the items we've finished
  OwnerKHashTable<LRItem, DottedProduction> finished(
    &LRItem::dataToKey,
    &LRItem::hash,
    &LRItem::dpEqual, 13);
  finished.setEnableShrink(false);

  // put all the nonkernels we have into 'finished'
  while (itemSet.nonkernelItems.isNotEmpty()) {
    LRItem *dp = itemSet.nonkernelItems.removeFirst();
    finished.add(dp->dprod, dp);
  }

  // first, close the kernel items -> worklist
  FOREACH_OBJLIST(LRItem, itemSet.kernelItems, itemIter) {
    singleItemClosure(finished, worklist, itemIter.data(), scratchSet);
  }

  while (worklist.isNotEmpty()) {
    // pull the first production
    LRItem *item = worklist.pop();
    xassert(item->dprod->backPointer == item);     // was on worklist
    item->dprod->backPointer = NULL;               // now off of worklist

    // put it into list of 'done' items; this way, if this
    // exact item is generated during closure, it will be
    // seen and re-inserted (instead of duplicated)
    finished.add(item->dprod, item);

    // close it -> worklist
    singleItemClosure(finished, worklist, item, scratchSet);
  }

  // move everything from 'finished' to the nonkernel items list
  try {
    for (OwnerKHashTableIter<LRItem, DottedProduction> iter(finished);
         !iter.isDone(); iter.adv()) {
      // temporarily, the item is owned both by the hashtable
      // and the list
      itemSet.nonkernelItems.prepend(iter.data());
    }
    finished.disownAndForgetAll();
  }
  catch (...) {
    breaker();    // debug breakpoint

    // resolve the multiple ownership by leaking some
    finished.disownAndForgetAll();
    throw;
  }

  // we potentially added a bunch of things
  itemSet.changedItems();

  if (tr) {
    trs << "done with closure of state " << itemSet.id << endl;
    itemSet.print(trs, *this);
  }
}


void GrammarAnalysis
  ::singleItemClosure(OwnerKHashTable<LRItem, DottedProduction> &finished,
                      ArrayStack<LRItem*> &worklist,
                      //OwnerKHashArray<LRItem, DottedProduction> &workhash,
                      LRItem const *item, TerminalSet &newItemLA)
{
  INITIAL_MALLOC_STATS();

  bool const tr = tracingSys("closure");
  ostream &trs = trace("closure");     // trace stream

  if (tr) {
    trs << "  considering item ";
    item->print(trs, *this);
    trs << endl;
  }

  if (item->isDotAtEnd()) {
    if (tr) {
      trs << "    dot is at the end" << endl;
    }
    CHECK_MALLOC_STATS("return, dot at end");
    return;
  }

  // in comments that follow, 'item' is broken down as
  //   A -> alpha . B beta, LA

  // get the symbol B (the one right after the dot)
  Symbol const *B = item->symbolAfterDotC();
  if (B->isTerminal()) {
    if (tr) {
      trs << "    symbol after the dot is a terminal" << endl;
    }
    CHECK_MALLOC_STATS("return, dot sym is terminal");
    return;
  }
  int nontermIndex = B->asNonterminalC().ntIndex;

  // could pull this out of even this fn, to the caller, but I don't
  // see any difference in time when I make it static (which simulates
  // the effect, though static itself is a bad idea because it makes
  // the size constant through a whole run); but maybe when other things
  // are faster I will be able to notice the difference, so I might
  // revisit this
  //TerminalSet newItemLA(numTerminals());

  // for each production "B -> gamma"
  SMUTATE_EACH_PRODUCTION(productionsByLHS[nontermIndex], prodIter) {    // (constness)
    Production &prod = *(prodIter.data());
    if (tr) {
      trs << "    considering production " << prod << endl;
    }

    // key to good performance: do *no* dynamic allocation in this
    // loop (one of two inner loops in the grammar analysis), until a
    // new item is actually *needed* (which is the uncommon case); for
    // example, all debug output statements are guarded by 'if (tr)'
    // because otherwise they would allocate

    // invariant of the indexed productions list
    xassert(prod.left == B);

    // construct "B -> . gamma, First(beta LA)";
    // except, don't actually build it until later; in the meantime,
    // determine which DP and lookahead it would use if created
    DottedProduction const *newDP = getDProd(&prod, 0 /*dot at left*/);

    // get beta (what follows B in 'item')
    DottedProduction const *beta = nextDProd(item->dprod);

    // get First(beta) -> new item's lookahead
    newItemLA = beta->firstSet;

    // if beta ->* epsilon, add LA
    if (beta->canDeriveEmpty) {
      newItemLA.merge(item->lookahead);
    }

    if (tr) {
      trs << "      built item ";
      // this is what LRItem::print would do if I actually
      // constructed the object
      newDP->print(trs);
      trs << ", ";
      newItemLA.print(trs, *this);
      trs << endl;
    }

    // is 'newDP' already there?
    // check in working and finished tables
    bool inDoneList = true;
    LRItem *already = newDP->backPointer;   // workhash.lookup(newDP);
    if (already) {
      inDoneList = false;  
    }
    else {
      already = finished.get(newDP);
    }

    if (already) {
      // yes, it's already there
      if (tr) {
        trs << "      looks similar to ";
        already->print(trs, *this);
        trs << endl;
      }

      // but the new item may have additional lookahead
      // components, so merge them with the old
      if (already->lookahead.merge(newItemLA)) {
        // merging changed 'already'
        if (tr) {
          trs << "      (chg) merged it to make ";
          already->print(trs, *this);
          trs << endl;
        }

        if (inDoneList) {
          // pull from the 'done' list and put in worklist, since the
          // lookahead changed
          finished.remove(already->dprod);
          CHECK_MALLOC_STATS("before worklist push");
          worklist.push(already);
          xassert(already->dprod->backPointer == NULL);   // was not on
          already->dprod->backPointer = already;          // now is on worklist
          UPDATE_MALLOC_STATS();     // allow expansion
        }
        else {
          // 'already' is in the worklist, so that's fine
        }
      }
      else {
        if (tr) {
          trs << "      this dprod already existed" << endl;
        }
      }
    }
    else {
      CHECK_MALLOC_STATS("bunch of stuff before 'if'");

      // it's not already there, so add it to worklist (but first
      // actually create it!)
      LRItem *newItem = new LRItem(numTerms, newDP);
      newItem->lookahead.copy(newItemLA);
      if (tr) {
        trs << "      this dprod is new, queueing it to add" << endl;
      }

      worklist.push(newItem);
      xassert(newItem->dprod->backPointer == NULL);
      newItem->dprod->backPointer = newItem;

      UPDATE_MALLOC_STATS();     // "new LRItem" or expansion of worklist
    }

    CHECK_MALLOC_STATS("processing of production");
  } // for each production

  CHECK_MALLOC_STATS("end of singleItemClosure");
}


// -------------- START of construct LR item sets -------------------
ItemSet *GrammarAnalysis::makeItemSet()
{
  return new ItemSet((StateId)(nextItemSetId++), 
                     numTerminals(), numNonterminals());
}

void GrammarAnalysis::disposeItemSet(ItemSet *is)
{
  // we assume we're only doing this right after making it, as the
  // point of this exercise is to avoid fragmenting the id space
  nextItemSetId--;
  xassert(is->id == nextItemSetId);
  delete is;
}


// yield (by filling 'dest') a new itemset by moving the dot across
// the productions in 'source' that have 'symbol' to the right of the
// dot; do *not* compute the closure
//
// unusedTail:
//   since 'dest' comes with a bunch of kernel items, some of which we
//   most likely won't need, put the unused ones into 'unusedTail'
//
// array:
//   since I don't want to allocate anything in here, we need scratch
//   space for computing kernel CRCs
void GrammarAnalysis::moveDotNoClosure(ItemSet const *source, Symbol const *symbol,
                                       ItemSet *dest, ObjList<LRItem> &unusedTail,
                                       GrowArray<DottedProduction const*> &array)
{
  //ItemSet *ret = makeItemSet();

  // total # of items added
  int appendCt=0;

  // iterator for walking down dest's kernel list
  ObjListMutator<LRItem> destIter(dest->kernelItems);

  // iterator for walking both lists of items; switching from an
  // implementation which used 'getAllItems' for performance reasons
  ObjListIter<LRItem> srcIter(source->kernelItems);
  int passCt=0;    // 0=kernelItems, 1=nonkernelItems
  while (passCt < 2) {
    if (passCt++ == 1) {
      srcIter.reset(source->nonkernelItems);
    }

    // for each item
    for (; !srcIter.isDone(); srcIter.adv()) {
      LRItem const *item = srcIter.data();

      if (item->isDotAtEnd() ||
          item->symbolAfterDotC() != symbol) {
        continue;    // can't move dot
      }

      // need to access destIter; if there are no more items, make more
      if (destIter.isDone()) {
        // the new item becomes the current 'data()'
        destIter.insertBefore(new LRItem(numTerminals(), NULL /*dprod*/));
      }

      // move the dot; write dot-moved item into 'destIter'
      LRItem *dotMoved = destIter.data();
      dotMoved->dprod = nextDProd(item->dprod);
      dotMoved->lookahead = item->lookahead;

      // add the new item to the itemset I'm building
      //ret->addKernelItem(dotMoved);   // UPDATE: it's already in the list
      appendCt++;
      destIter.adv();
    }
  }

  // pull out any unused items into 'unusedItems'; it's important that
  // this action not have to look at each unused item, because I want
  // to be able to make a really big scratch item list and not pay for
  // items I don't end up using
  unusedTail.stealTailAt(appendCt, dest->kernelItems);

  // verify we actually got something
  xassert(appendCt > 0);

  // we added stuff; sorting is needed both for the CRC below, and also
  // for the lookahead merge step that follows a successful lookup
  dest->sortKernelItems();

  // recompute the one thing I need to do hashing
  dest->computeKernelCRC(array);
}


// if 'list' contains something equal to 'itemSet', return that
// equal object; otherwise, return NULL
// 'list' is non-const because might return an element of it
ItemSet *GrammarAnalysis::findItemSetInList(ObjList<ItemSet> &list,
                                            ItemSet const *itemSet)
{
  // inefficiency: using iteration to check set membership

  MUTATE_EACH_OBJLIST(ItemSet, list, iter) {
    if (itemSetsEqual(iter.data(), itemSet)) {
      return iter.data();
    }
  }
  return NULL;
}


STATICDEF bool GrammarAnalysis::itemSetsEqual(ItemSet const *is1, ItemSet const *is2)
{
  // checks for equality of the kernel items
  return *is1 == *is2;
}


// keys and data are the same
STATICDEF ItemSet const *ItemSet::dataToKey(ItemSet *data)
{
  return data;
}

STATICDEF unsigned ItemSet::hash(ItemSet const *key)
{
  unsigned crc = key->kernelItemsCRC;
  return HashTable::lcprngHashFn((void*)crc);
}

STATICDEF bool ItemSet::equalKey(ItemSet const *key1, ItemSet const *key2)
{
  return *key1 == *key2;
}


// [ASU] fig 4.34, p.224
// puts the finished parse tables into 'itemSetsDone'
void GrammarAnalysis::constructLRItemSets()
{
  bool tr = tracingSys("lrsets");

  enum { BIG_VALUE = 100 };

  // item sets yet to be processed; item sets are simultaneously in
  // both the hash and the list, or not in either
  OwnerKHashArray<ItemSet, ItemSet> itemSetsPending(
    &ItemSet::dataToKey,
    &ItemSet::hash,
    &ItemSet::equalKey);

  // item sets with all outgoing links processed
  OwnerKHashTable<ItemSet, ItemSet> itemSetsDone(
    &ItemSet::dataToKey,
    &ItemSet::hash,
    &ItemSet::equalKey);
  itemSetsDone.setEnableShrink(false);

  // to avoid allocating in the inner loop, we make a single item set
  // which we'll fill with kernel items every time we think we *might*
  // make a new state, and if it turns out we really do need a new
  // state, then the kernel items in this one will be copied elsewhere
  Owner<ItemSet> scratchState(
    new ItemSet((StateId)-1 /*id*/, numTerms, numNonterms));

  // fill the scratch state with lots of kernel items to start with;
  // since these items will be re-used over and over, filling it now
  // ensures good locality on those accesses (assuming malloc returns
  // objects close together)
  enum { INIT_LIST_LEN = BIG_VALUE };
  for (int i=0; i<INIT_LIST_LEN; i++) {
    // this is a dummy item; it allocates the bitmap for 'lookahead',
    // but those bits and the 'dprod' pointer will be overwritten
    // many times during the algorithm
    LRItem *item = new LRItem(numTerms, NULL /*dottedprod*/);
    scratchState->addKernelItem(item);
  }

  // similar to the scratch state, make a scratch array for the
  // kernel CRC computation
  GrowArray<DottedProduction const*> kernelCRCArray(BIG_VALUE);

  // start by constructing closure of first production
  // (basically assumes first production has start symbol
  // on LHS, and no other productions have the start symbol
  // on LHS)
  {
    ItemSet *is = makeItemSet();              // (owner)
    startState = is;
    LRItem *firstDP
      = new LRItem(numTerms, getDProd(productions.first(), 0 /*dot at left*/));
    
    // don't add this to the lookahead; we assume EOF is actually
    // mentioned in the production already, and we won't contemplate
    // executing this reduction within the normal parser core
    // (see GLR::cleanupAfterParse)
    //firstDP->laAdd(0 /*EOF token id*/);

    is->addKernelItem(firstDP);
    is->sortKernelItems();                    // redundant, but can't hurt
    itemSetClosure(*is);                      // calls changedItems internally

    // this makes the initial pending itemSet
    itemSetsPending.push(is, is);             // (ownership transfer)
  }

  // track how much allocation we're doing
  INITIAL_MALLOC_STATS();

  // for each pending item set
  while (itemSetsPending.isNotEmpty()) {
    ItemSet *itemSet = itemSetsPending.pop();          // dequeue (owner)

    CHECK_MALLOC_STATS("top of pending list loop");

    // put it in the done set; note that we must do this *before*
    // the processing below, to properly handle self-loops
    itemSetsDone.add(itemSet, itemSet);                // (ownership transfer; 'itemSet' becomes serf)

    // allows for expansion of 'itemSetsDone' hash
    UPDATE_MALLOC_STATS();

    if (tr) {
      trace("lrsets") << "state " << itemSet->id
                      << ", " << itemSet->kernelItems.count()
                      << " kernel items and "
                      << itemSet->nonkernelItems.count()
                      << " nonkernel items" << endl;
    }

    // see below; this is part of a fix for a *very* subtle heisenbug
    bool mustCloseMyself = false;

    // for each production in the item set where the
    // dot is not at the right end
    //
    // explicitly iterate over both lists because 'getAllItems'
    // does allocation
    ObjListIter<LRItem> itemIter(itemSet->kernelItems);
    int passCt=0;    // 0=kernelItems, 1=nonkernelItems
    while (passCt < 2) {
      if (passCt++ == 1) {
        itemIter.reset(itemSet->nonkernelItems);
      }

      for (; !itemIter.isDone(); itemIter.adv()) {
        LRItem const *item = itemIter.data();
        if (item->isDotAtEnd()) continue;

        CHECK_MALLOC_STATS("top of item list loop");

        if (tr) {
          ostream &trs = trace("lrsets");
          trs << "considering item ";
          item->print(trs, *this);
          trs << endl;
        }

        // get the symbol 'sym' after the dot (next to be shifted)
        Symbol const *sym = item->symbolAfterDotC();

        // in LALR(1), two items might have different lookaheads; more
        // likely, re-expansions needs to propagate lookahead that
        // wasn't present from an earlier expansion
        if (!LALR1) {
          // if we already have a transition for this symbol,
          // there's nothing more to be done
          if (itemSet->transitionC(sym) != NULL) {
            continue;
          }
        }

        // compute the itemSet (into 'scratchState') produced by moving
        // the dot across 'sym'; don't take closure yet since we
        // first want to check whether it is already present
        //
        // this call also yields the unused remainder of the kernel items,
        // so we can add them back in at the end
        ObjList<LRItem> unusedTail;
        moveDotNoClosure(itemSet, sym, scratchState,
                         unusedTail, kernelCRCArray);
        ItemSet *withDotMoved = scratchState;    // clarify role from here down

        CHECK_MALLOC_STATS("moveDotNoClosure");

        // see if we already have it, in either set
        ItemSet *already = itemSetsPending.lookup(withDotMoved);
        bool inDoneList = false;
        if (already == NULL) {
          already = itemSetsDone.get(withDotMoved);
          inDoneList = true;    // used if 'already' != NULL
        }

        // have it?
        if (already != NULL) {
          // we already have a state with at least equal kernel items, not
          // considering their lookahead sets; so we have to merge the
          // computed lookaheads with those in 'already'
          if (withDotMoved->mergeLookaheadsInto(*already)) {
            if (tr) {
              trace("lrsets")
                << "from state " << itemSet->id << ", found that the transition "
                << "on " << sym->name << " yielded a state similar to "
                << already->id << ", but with different lookahead" << endl;
            }

            CHECK_MALLOC_STATS("mergeLookaheadsInto");

            // this changed 'already'; recompute its closure
            if (already != itemSet) {
              itemSetClosure(*already);
            }
            else {
              // DANGER!  I'm already iterating over 'itemSet's item lists,
              // and if I execute the closure algorithm it will invalidate
              // my iterator.  so, postpone it
              mustCloseMyself = true;
            }

            // and reconsider all of the states reachable from it
            if (!inDoneList) {
              // itemSetsPending contains 'already', it will be processed later
            }
            else {
              // we thought we were done with this
              xassertdb(itemSetsDone.get(already));

              // but we're not: move it back to the 'pending' list
              itemSetsDone.remove(already);
              itemSetsPending.push(already, already);
            }

            // it's ok if closure makes more items, or if
            // the pending list expands
            UPDATE_MALLOC_STATS();
          }

          // we already have it, so throw away one we made
          // UPDATE: we didn't allocate, so don't deallocate
          //disposeItemSet(withDotMoved);     // deletes 'withDotMoved'

          // and use existing one for setting the transition function
          withDotMoved = already;
        }
        else {
          // we don't already have it; need to actually allocate & copy
          withDotMoved = makeItemSet();
          FOREACH_OBJLIST(LRItem, scratchState->kernelItems, iter) {
            withDotMoved->addKernelItem(new LRItem( *(iter.data()) ));
          }

          // finish it by computing its closure
          itemSetClosure(*withDotMoved);

          // then add it to 'pending'
          itemSetsPending.push(withDotMoved, withDotMoved);

          // takes into account:
          //   - creation of 'withDotMoved' state
          //   - creation of items to fill its kernel
          //   - creation of nonkernel items during closure
          //   - possible expansion of the 'itemSetsPending' hash
          UPDATE_MALLOC_STATS();
        }

        // setup the transition function
        itemSet->setTransition(sym, withDotMoved);

        // finally, restore 'scratchState's kernel item list
        scratchState->kernelItems.concat(unusedTail);

        // make sure the link restoration process works as expected
        xassertdb(scratchState->kernelItems.count() >= INIT_LIST_LEN);

        CHECK_MALLOC_STATS("end of item loop");

      } // for each item
    } // 0=kernel, 1=nonkernel

    CHECK_MALLOC_STATS("end of item set loop");

    // now that we're finished iterating over the items, I can do the
    // postponed closure
    if (mustCloseMyself) {
      itemSetClosure(*itemSet);
      UPDATE_MALLOC_STATS();
    }

  } // for each item set

  // we're done constructing item sets, so move all of them out
  // of the 'itemSetsDone' hash and into 'this->itemSets'
  try {
    for (OwnerKHashTableIter<ItemSet, ItemSet> iter(itemSetsDone);
         !iter.isDone(); iter.adv()) {
      itemSets.prepend(iter.data());
    }
    itemSetsDone.disownAndForgetAll();
  }
  catch (...) {
    breaker();
    itemSetsDone.disownAndForgetAll();
    throw;
  }

  // since we sometimes consider a state more than once, the
  // states end up out of order; put them back in order
  itemSets.mergeSort(ItemSet::diffById);


  traceProgress(1) << "done with LR sets: " << itemSets.count()
                   << " states\n";


  // do the BFS now, since we want to print the sample inputs
  // in the loop that follows
  traceProgress(1) << "BFS tree on transition graph...\n";
  computeBFSTree();

  if (tracingSys("itemset-graph")) {
    // write this info to a graph applet file
    ofstream out("lrsets.g");
    if (!out) {
      xsyserror("ofstream open");
    }
    out << "# lr sets in graph form\n";

    FOREACH_OBJLIST(ItemSet, itemSets, itemSet) {
      itemSet.data()->writeGraph(out, *this);
    }
  }
}


// print each item set
void GrammarAnalysis::printItemSets(ostream &os, bool nonkernel) const
{
  FOREACH_OBJLIST(ItemSet, itemSets, itemSet) {
    os << "State " << itemSet.data()->id
       << ", sample input: " << sampleInput(itemSet.data()) << "\n"
       << "  and left context: " << leftContextString(itemSet.data()) << "\n"
       ;
    itemSet.data()->print(os, *this, nonkernel);
    os << "\n\n";
  }
}


// --------------- END of construct LR item sets -------------------


Symbol const *GrammarAnalysis::
  inverseTransitionC(ItemSet const *source, ItemSet const *target) const
{
  // for each symbol..
  FOREACH_TERMINAL(terminals, t) {
    // see if it is the one
    if (source->transitionC(t.data()) == target) {
      return t.data();
    }
  }

  FOREACH_NONTERMINAL(nonterminals, nt) {
    if (source->transitionC(nt.data()) == target) {
      return nt.data();
    }
  }

  xfailure("GrammarAnalysis::inverseTransitionC: no transition from source to target");
  return NULL;     // silence warning
}


void GrammarAnalysis::computeReachable()
{
  // start by clearing the reachability flags
  MUTATE_EACH_NONTERMINAL(nonterminals, iter) {
    iter.data()->reachable = false;
  }
  
  // do a DFS on the grammar, marking things reachable as
  // they're encountered
  computeReachableDFS(startSymbol);
}


void GrammarAnalysis::computeReachableDFS(Nonterminal *nt)
{
  if (nt->reachable) {
    // already looked at this nonterminal
    return;
  }
  nt->reachable = true;

  // iterate over this nonterminal's rules
  SFOREACH_PRODUCTION(productionsByLHS[nt->ntIndex], iter) {
    // iterate over symbols in the rule RHS
    FOREACH_OBJLIST(Production::RHSElt, iter.data()->right, jter) {
      Production::RHSElt const *elt = jter.data();

      if (elt->sym->isNonterminal()) {
        // recursively analyze nonterminal elements
        computeReachableDFS(elt->sym->ifNonterminal());
      }
      else {
        // just mark terminals
        elt->sym->reachable = true;
      }
    }
  }
}


// --------------- LR support -------------------
// decide what to do, and record the result into the two
// boolean reference parameters
void GrammarAnalysis::handleShiftReduceConflict(
  bool &keepShift, bool &keepReduce, bool &dontWarn,
  ItemSet const *state, Production const *prod, Terminal const *sym)
{
  // say that we're considering this conflict
  trace("prec")
    << "in state " << state->id << ", S/R conflict on token "
    << sym->name << " with production " << *prod << endl;

  // look at scannerless directives
  { 
    // is this nonterm or any of its declared supersets maximal?
    Nonterminal const *super = prod->left;
    bool maximal = super->maximal;
    while (!maximal && super->superset) {
      super = super->superset;
      maximal = super->maximal;
    }
    
    if (maximal) {
      // see if this reduction can be removed due to a 'maximal' spec;
      // in particular, is the shift going to extend 'super'?
      if (state->hasExtendingShift(super, sym)) {
        trace("prec") << "resolved in favor of SHIFT due to maximal munch\n";
        keepReduce = false;
        return;
      }
    }
  }

  if (!( prod->precedence && sym->precedence )) {
    // one of the two doesn't have a precedence specification,
    // so we can do nothing
    trace("prec") << "will SPLIT because no disambiguation spec available" << endl;
    return;
  }

  if (prod->precedence > sym->precedence) {
    // production's precedence is higher, so we choose to reduce
    // instead of shift
    trace("prec") << "resolved in favor of REDUCE due to precedence\n";
    keepShift = false;
    return;
  }

  if (prod->precedence < sym->precedence) {
    // symbol's precedence is higher, so we shift
    trace("prec") << "resolved in favor of SHIFT due to precedence\n";
    keepReduce = false;
    return;
  }

  // precedences are equal, so we look at associativity (of token)
  switch (sym->associativity) {
    case AK_LEFT:
      trace("prec") << "resolved in favor of REDUCE due to associativity\n";
      keepShift = false;
      return;

    case AK_RIGHT:
      trace("prec") << "resolved in favor of SHIFT due to associativity\n";
      keepReduce = false;
      return;

    case AK_NONASSOC:
      trace("pred") << "removed BOTH alternatives due to nonassociativity\n";
      keepShift = false;
      keepReduce = false;
      return;

    case AK_NEVERASSOC:
      // the user claimed this token would never be involved in a conflict
      trace("pred") << "neverassoc specification ERROR\n";
      errors++;
      cout << "token " << sym->name << " was declared 'prec', "
           << "but it is involved in an associativity conflict with \""
           << *prod << "\" in state " << state->id << endl;
      return;

    case AK_SPLIT:
      // the user does not want disambiguation of this
      trace("pred") << "will SPLIT because user asked to\n";
      dontWarn = true;
      return;

    default:
      xfailure("bad assoc code");
  }
}


// given an LR transition graph, compute the BFS tree on top of it
// and set the parent links to record the tree
void GrammarAnalysis::computeBFSTree()
{
  // for the BFS, we need a queue of states yet to be processed, and a
  // pile of 'done' states
  SObjList<ItemSet> queue;
  SObjList<ItemSet> done;

  // initial entry in queue is root of BFS tree
  queue.append(startState);

  // it will be convenient to have all the symbols in a single list
  // for iteration purposes
  SymbolList allSymbols;          // (const list)
  {
    FOREACH_TERMINAL(terminals, t) {
      allSymbols.append(const_cast<Terminal*>(t.data()));
    }
    FOREACH_NONTERMINAL(nonterminals, nt) {
      allSymbols.append(const_cast<Nonterminal*>(nt.data()));
    }
  }

  // loop until the queue is exhausted
  while (queue.isNotEmpty()) {
    // dequeue first element
    ItemSet *source = queue.removeAt(0);

    // mark it as done so we won't consider any more transitions to it
    done.append(source);

    // for each symbol...
    SFOREACH_SYMBOL(allSymbols, sym) {
      // get the transition on this symbol
      ItemSet *target = source->transition(sym.data());

      // if the target is done or already enqueued, or there is no
      // transition on this symbol, we don't need to consider it
      // further
      if (target == NULL ||
          done.contains(target) ||
          queue.contains(target)) {
        continue;
      }

      // the source->target link just examined is the first time
      // we've encounted 'target', so that link becomes the BFS
      // parent link
      target->BFSparent = source;

      // finally, enqueue the target so we'll explore its targets too
      queue.append(target);
    }
  }
}


// --------------- parse table construction -------------------
#if 0 // obsolete
// compare two productions by precedence
static int productionPrecCompare(Production const *p1, Production const *p2, void*)
{
  if (p1->precedence && p2->precedence) {
    // I want the low precedence first
    return p1->precedence - p2->precedence;
  }
  else {
    // if one or the other doesn't have a precedence, then there's
    // no basis for distinction
    return 0;
  }
}
#endif

// given some potential parse actions, apply available disambiguation
// to remove some of them; print warnings about conflicts, in some
// situations
void GrammarAnalysis::resolveConflicts(
  ItemSet const *state,        // parse state in which the actions are possible
  Terminal const *sym,         // lookahead symbol for these actions
  ItemSet const *&shiftDest,   // (inout) if non-NULL, the state to which we can shift
  ProductionList &reductions,  // (inout) list of possible reductions
  bool allowAmbig,             // if false, always return at most 1 action
  bool &printedConflictHeader, // (inout) true once we've printed the state header
  int &sr, int &rr)            // (inout) counts of S/R and R/R conflicts, resp.
{
  // how many actions are there?
  int actions = (shiftDest? 1 : 0) + reductions.count();
  if (actions <= 1) {
    return;      // no conflict
  }

  // count how many warning suppressions we have
  int dontWarns = 0;

  // static disambiguation for S/R conflicts
  if (shiftDest) {
    // we have (at least) a shift/reduce conflict, which is the
    // situation in which prec/assoc specifications are used; consider
    // all the possible reductions, so we can resolve S/R conflicts
    // even when there are R/R conflicts present too
    SObjListMutator<Production> mut(reductions);
    while (!mut.isDone() && shiftDest != NULL) {
      Production const *prod = mut.data();

      bool keepShift=true, keepReduce=true, dontWarn=false;
      handleShiftReduceConflict(keepShift, keepReduce, dontWarn, state, prod, sym);

      if (!keepShift) {
        actions--;
        shiftDest = NULL;      // remove the shift
      }

      if (!keepReduce) {
        actions--;
        mut.remove();          // remove the reduction
      }
      else {
        mut.adv();
      }

      if (dontWarn) {
        dontWarns++;
      }
    }

    // there is still a potential for misbehavior.. e.g., if there are two
    // possible reductions (R1 and R2), and one shift (S), then the user
    // could have specified prec/assoc to disambiguate, e.g.
    //   R1 < S
    //   S < R2
    // so that R2 is the right choice; but if I consider (S,R2) first,
    // I'll simply drop S, leaving no way to disambiguate R1 and R2 ..
    // for now I'll just note the possibility...
  }

  // static disambiguation for R/R conflicts
  if (reductions.count() > 1) {

// NEW CODE FROM ELKHOUND version 1.156, 2005/02/25 20:10:47
 // find the highest precedence
  	     int highestPrec = 0;
  	     SFOREACH_PRODUCTION(reductions, iter) {
  	       int p = iter.data()->precedence;
  	 
  	       if (p && p>highestPrec) {
  	         highestPrec = p;
  	       }
  	     }
  	 
  	     // remove any productions that are lower than 'highestPrec'
  	     SObjListMutator<Production> mut(reductions);
  	     while (!mut.isDone()) {
  	       int p = mut.data()->precedence;
  	 
  	       if (p && p<highestPrec) {
  	         trace("prec")
  	           << "in state " << state->id << ", R/R conflict on token "
  	           << sym->name << ", removed production " << *(mut.data())
  	           << " because " << p << "<" << highestPrec << endl;
  	         mut.remove();
  	       }
  	       else {
  	         mut.adv();
  	       }
  	     }
  	 
#if 0    // totally wrong
    // sort the reductions so the lowest precedence reductions are
    // first, then higher precedences, and finally reductions that
    // lack any precedence (use insertion sort since I expect that
    // most of the time the list won't require any changes)
    reductions.insertionSort(productionPrecCompare);

    // work through the head of the list, discarding productions
    // that have higher-precedence productions beneath them
    int ct = reductions.count();
    while (ct >= 2) {
      Production *p1 = reductions.nth(0);
      Production *p2 = reductions.nth(1);
      if (!(p1->precedence && p2->precedence)) break;

      // remove first one
      reductions.removeFirst();
      ct--;
      actions--;

      // report
      trace("prec")
        << "in state " << state->id << ", R/R conflict on token "
        << sym->name << ", removed production " << *p1 << endl;
    }
#endif
  }
                                                      
  // additional R/R resolution using subset directives
  if (reductions.count() > 1) {
    actions -= subsetDirectiveResolution(state, sym, reductions);
  }

  // after the disambiguation, maybe now there's no conflicts?
  // or, if conflicts remain, did we get at least that many warning
  // suppressions?
  if ((actions-dontWarns) <= 1) {
    // don't print information about conflicts
  }
  else {
    // print conflict info
    if (!printedConflictHeader) {
      trace("conflict")
        << "--------- state " << state->id << " ----------\n"
        << "left context: " << leftContextString(state)
        << endl
        << "sample input: " << sampleInput(state)
        << endl
        ;
      printedConflictHeader = true;
    }

    trace("conflict")
      << "conflict for symbol " << sym->name
      << endl;

    if (shiftDest) {
      trace("conflict") << "  shift, and move to state " << shiftDest->id << endl;
      sr++;                 // shift/reduce conflict
      rr += actions - 2;    // any reduces beyond first are r/r errors
    }
    else {
      rr += actions - 1;    // all reduces beyond first are r/r errors
    }

    SFOREACH_PRODUCTION(reductions, prod) {
      trace("conflict") << "  reduce by rule " << *(prod.data()) << endl;
    }
  }

  if (!allowAmbig && actions > 1) {
    // force only one action, using Bison's disambiguation:
    //   - prefer shift to reduce
    //   - prefer the reduction which occurs first in the grammar file
    if (shiftDest) {
      reductions.removeAll();
    }
    else {
      while (reductions.count() >= 2) {
        // compare first and second
        Production const *first = reductions.nth(0);
        Production const *second = reductions.nth(1);

        // production indices happen to be assigned in file order
        if (first->prodIndex < second->prodIndex) {
          reductions.removeItem(second);
        }
        else {
          reductions.removeItem(first);
        }
      }
    }
  }
}


void reportUnexpected(int value, int expectedValue, char const *desc)
{
  if ((expectedValue == -1 && value>0) ||
      (expectedValue != -1 && expectedValue != value)) {
    cout << value << " " << desc;
    if (expectedValue != -1) {
      cout << " (expected " << expectedValue << ")";
    }
    cout << endl;
  }
}


// the idea is we might be trying to do scannerless parsing, and
// someone might say that Identifier has as subsets all the keywords,
// so competing reductions should favor the subsets (the keywords)
int GrammarAnalysis::subsetDirectiveResolution(
  ItemSet const *state,        // parse state in which the actions are possible
  Terminal const *sym,         // lookahead symbol for these actions
  ProductionList &reductions)  // list to try to cut down
{
  int removed = 0;

  // make a map of which nonterminals appear on the LHS of one
  // of the reductions, and has a superset
  BitArray map(numNonterms);
  bool anyWithSuper = false;
  {
    SFOREACH_PRODUCTION(reductions, iter) {
      Production const *p = iter.data();
      if (p->left->superset) {
        map.set(p->left->ntIndex);
        anyWithSuper = true;
      }
    }
  }

  if (!anyWithSuper) {
    return removed;     // nothing we can do
  }

  // walk over the reductions, removing those that have reductions
  // to subsets also in the list
  SObjListMutator<Production> mut(reductions);
  while (!mut.isDone()) {
    Production const *prod = mut.data();

    SFOREACH_OBJLIST(Nonterminal, prod->left->subsets, iter) {
      Nonterminal const *sub = iter.data();
      if (map.test(sub->ntIndex)) {
        trace("prec")
          << "in state " << state->id
          << ", R/R conflict on token " << sym->name
          << ", removed production yielding " << prod->left->name
          << " b/c another yields subset " << sub->name
          << endl;
        mut.remove();
        removed++;
        goto continue_outer_loop;
      }
    }

    // didn't remove, must manually advance
    mut.adv();

    continue_outer_loop:;
  }
  
  return removed;
}


bool isAmbiguousNonterminal(Symbol const *sym)
{
  if (sym->isNonterminal()) {
    Nonterminal const &nt = sym->asNonterminalC();
    if (nt.mergeCode) {
      return true;   // presence of merge() signals potential ambiguity
    }
  }
  return false;
}

  
// The purpose of this function is to number the states (which have up
// to this point been numbered arbitrarily) in such a way that all
// states that have a given symbol on incoming arcs will be numbered
// consecutively.  This is part of the table compression schemes
// described in the Dencker et. al. paper (see parsetables.h).
void GrammarAnalysis::renumberStates()
{
  // sort them into the right order
  itemSets.mergeSort(&GrammarAnalysis::renumberStatesDiff, this);

  // number them in that order
  int n = 0;
  FOREACH_OBJLIST_NC(ItemSet, itemSets, iter) {
    ItemSet *s = iter.data();
    if (n == 0) {
      // the first element should always be the start state
      xassert(s->id == 0);
    }
    else {
      s->id = (StateId)n;
    }

    n++;
  }
}

STATICDEF int GrammarAnalysis::renumberStatesDiff
  (ItemSet const *left, ItemSet const *right, void *vgramanl)
{
  GrammarAnalysis *gramanl = (GrammarAnalysis*)vgramanl;

  int ret;

  // if for some reason I'm ever asked to compare a state to
  // itself..
  if (left == right) { 
    return 0;
  }

  // order them first by their incoming arc symbol; this effects
  // the renumbering that the Code Reduction Scheme demands
  {
    Symbol const *ls = left->getStateSymbolC();
    Symbol const *rs = right->getStateSymbolC();

    // any state with no incoming arcs (start state) is first
    ret = (int)(bool)ls - (int)(bool)rs;
    if (ret) return ret;

    // terminals come before nonterminals
    ret = (int)(ls->isNonterminal()) - (int)(rs->isNonterminal());
    if (ret) return ret;

    // order by id within terms/nonterms
    ret = ls->getTermOrNontermIndex() - rs->getTermOrNontermIndex();
    if (ret) return ret;
  }

  // from this point on, the CRS would be happy with an arbitrary
  // order, but I want the state numbering to be canonical so that
  // I have an easier time debugging and comparing parse traces

  // they have the same incoming arc symbol; now, sort by outgoing
  // arc symbols

  // first up: terminals
  {
    for (int t=0; t < gramanl->numTerminals(); t++) {
      ItemSet const *ldest = left->getTermTransition(t);
      ItemSet const *rdest = right->getTermTransition(t);

      ret = (int)!ldest - (int)!rdest;
      if (ret) return ret;

      if (ldest && rdest) {
        ret = ldest->id - rdest->id;
        if (ret) return ret;
      }
    }
  }

  // next: nonterminals
  {
    for (int nt=0; nt < gramanl->numNonterminals(); nt++) {
      ItemSet const *ldest = left->getNontermTransition(nt);
      ItemSet const *rdest = right->getNontermTransition(nt);

      ret = (int)!ldest - (int)!rdest;
      if (ret) return ret;

      if (ldest && rdest) {
        ret = ldest->id - rdest->id;
        if (ret) return ret;
      }
    }
  }
                                                            
  // I suspect this will never be reached, since usually the
  // transition function will be sufficient
  // update: it happens often enough.. even in the arith grammar
  //cout << "using reductions to distinguish states\n";

  // finally, order by possible reductions
  FOREACH_OBJLIST(Terminal, gramanl->terminals, termIter) {
    ProductionList lpl, rpl;
    left->getPossibleReductions(lpl, termIter.data(), false /*parsing*/);
    right->getPossibleReductions(rpl, termIter.data(), false /*parsing*/);

    // sort the productions before we can compare them...
    lpl.insertionSort(&GrammarAnalysis::arbitraryProductionOrder);
    rpl.insertionSort(&GrammarAnalysis::arbitraryProductionOrder);

    ret = lpl.compareAsLists(rpl, &GrammarAnalysis::arbitraryProductionOrder);
    if (ret) return ret;
  }

  // I used to throw an xfailure here, but that causes a problem
  // because the 'itemSets' list is not well-formed, because we
  // are in the middle of sorting it
  cout << "two different states have identical transitions and "
          "identical reductions!\n";
  cout << "left=" << left->id
       << ", sym is " << left->getStateSymbolC()->toString() << "\n";
  left->print(cout, *gramanl);
  cout << "right=" << right->id
       << ", sym is " << right->getStateSymbolC()->toString() << "\n";
  right->print(cout, *gramanl);

  return 0;
}

STATICDEF int GrammarAnalysis::arbitraryProductionOrder
  (Production const *left, Production const *right, void*)
{
  // compare LHS
  int ret = left->left->ntIndex - right->left->ntIndex;
  if (ret) return ret;
  
  // RHS elts one at a time
  return left->right.compareAsLists(right->right,
    &GrammarAnalysis::arbitraryRHSEltOrder);
}

STATICDEF int GrammarAnalysis::arbitraryRHSEltOrder
  (Production::RHSElt const *left, Production::RHSElt const *right, void*)
{
  int ret = (int)left->sym->isTerminal() - (int)right->sym->isTerminal();
  if (ret) return ret;
  
  return left->sym->getTermOrNontermIndex() - right->sym->getTermOrNontermIndex();
}


void GrammarAnalysis::computeParseTables(bool allowAmbig)
{
  tables = new ParseTables(numTerms, numNonterms, itemSets.count(), numProds,
                           startState->id,
                           0 /* slight hack: assume it's the first production */);

  if (ENABLE_CRS_COMPRESSION) {
    // first-state info
    bool doingTerms = true;
    int prevSymCode = -1;
    FOREACH_OBJLIST(ItemSet, itemSets, iter) {
      ItemSet const *state = iter.data();
      Symbol const *sym = state->getStateSymbolC();
      if (!sym) continue;     // skip start state
      int symCode = sym->getTermOrNontermIndex();

      if (sym->isTerminal() == doingTerms &&
          symCode == prevSymCode) {
        // continuing the current run, do nothing
        continue;
      }

      if (sym->isNonterminal() && doingTerms) {
        // transition from terminals to nonterminals
        doingTerms = false;
      }
      else {
        // continue current phase, with new code; states must
        // already have been sorted into increasing order
        xassert(sym->isTerminal() == doingTerms);
        xassert(prevSymCode < symCode);
      }

      if (doingTerms) {
        tables->setFirstWithTerminal(symCode, state->id);
      }
      else {
        tables->setFirstWithNonterminal(symCode, state->id);
      }

      prevSymCode = symCode;
    }
  }

  // count total number of conflicts of each kind
  int sr=0, rr=0;

  // for each state...
  FOREACH_OBJLIST(ItemSet, itemSets, stateIter) {
    ItemSet const *state = stateIter.data();
    bool printedConflictHeader = false;

    // ---- fill in this row in the action table ----
    // for each possible lookahead...
    for (int termId=0; termId < numTerms; termId++) {
      Terminal const *terminal = getTerminal(termId);

      // can shift?
      ItemSet const *shiftDest = state->transitionC(terminal);

      // can reduce?
      ProductionList reductions;
      state->getPossibleReductions(reductions, terminal,
                                   false /*parsing*/);

      // try to resolve conflicts; this may print warnings about
      // the conflicts, depending on various factors; if 'allowAmbig'
      // is false, this will remove all but one action
      resolveConflicts(state, terminal, shiftDest, reductions,
                       allowAmbig, printedConflictHeader, sr, rr);

      // what to do in this cell
      ActionEntry cellAction;

      // still conflicts?
      int actions = (shiftDest? 1 : 0) + reductions.count();
      if (actions >= 2) {
        // make a new ambiguous-action entry-set
        ArrayStack<ActionEntry> set;

        // fill in the actions
        if (shiftDest) {
          set.push(tables->encodeShift(shiftDest->id, termId));
        }
        SFOREACH_PRODUCTION(reductions, prodIter) {
          set.push(tables->encodeReduce(prodIter.data()->prodIndex, state->id));
        }                                
        xassert(set.length() == actions);

        cellAction = tables->encodeAmbig(set, state->id);
      }

      else {
        // single action
        if (shiftDest) {
          xassert(reductions.count() == 0);
          cellAction = tables->encodeShift(shiftDest->id, termId);
        }
        else if (reductions.isNotEmpty()) {
          xassert(reductions.count() == 1);
          cellAction = tables->encodeReduce(reductions.first()->prodIndex, state->id);
        }
        else {
          cellAction = tables->encodeError();
        }
      }

      // add this entry to the table
      tables->setActionEntry(state->id, termId, cellAction);

      // based on the contents of 'reductions', decide whether this
      // state is delayed or not; to be delayed, the state must be
      // able to reduce by a production which:
      //   - has an ambiguous nonterminal as the last symbol on its RHS
      //   - is not reducing to the *same* nonterminal as the last symbol
      //     (rationale: eagerly reduce "E -> E + E")
      // UPDATE: removed last condition because it actually makes things
      // worse..
      bool delayed = false;
      if (reductions.isNotEmpty()) {    // no reductions: eager (irrelevant, actually)
        SFOREACH_PRODUCTION(reductions, prodIter) {
          Production const &prod = *prodIter.data();
          if (prod.rhsLength() >= 1) {                 // nonempty RHS?
            Symbol const *lastSym = prod.right.lastC()->sym;
            if (isAmbiguousNonterminal(lastSym)        // last RHS ambig?
                /*&& lastSym != prod.left*/) {         // not same as LHS?
              delayed = true;
            }
          }
        }
      }
    }

    // ---- fill in this row in the goto table ----
    // for each nonterminal...
    for (int nontermId=0; nontermId<numNonterms; nontermId++) {
      Nonterminal const *nonterminal = getNonterminal(nontermId);

      // where do we go when we reduce to this nonterminal?
      ItemSet const *gotoDest = state->transitionC(nonterminal);

      GotoEntry cellGoto;
      if (gotoDest) {
        cellGoto = tables->encodeGoto(gotoDest->id, nonterminal->ntIndex);
      }
      else {
        // this should never be accessed at parse time..
        cellGoto = tables->encodeGotoError();
      }

      // fill in entry
      tables->setGotoEntry(state->id, nontermId, cellGoto);
    }

    // get the state symbol
    xassert((unsigned)(state->id) < (unsigned)(tables->getNumStates()));
    tables->setStateSymbol(state->id,
      encodeSymbolId(state->getStateSymbolC()));
  }

  // report on conflict counts
  reportUnexpected(sr, expectedSR, "shift/reduce conflicts");
  reportUnexpected(rr, expectedRR, "reduce/reduce conflicts");

  // report on cyclicity
  for (int nontermId=0; nontermId<numNonterms; nontermId++) {
    Nonterminal const *nonterminal = getNonterminal(nontermId);
    if (nonterminal->cyclic) {
      cout << "grammar symbol " << nonterminal->name << " is cyclic\n";
    }
  }

  // fill in 'prodInfo'
  for (int p=0; p<numProds; p++) {
    Production const *prod = getProduction(p);
    tables->setProdInfo(p, prod->rhsLength(), prod->left->ntIndex);
  }
  
  // use the derivability relation to compute a total order
  // on nonterminals                    
  BitArray seen(numNonterms);
  int nextOrdinal = numNonterms-1;
  for (int nt=0; nt < numNonterms; nt++) {               
    // expand from 'nt' in case it's disconnected; this will be
    // a no-op if we've already 'seen' it
    topologicalSort(tables->getWritableNontermOrder(), nextOrdinal, nt, seen);
  }
  xassert(nextOrdinal == -1);    // should have used them all
  
  if (ENABLE_EEF_COMPRESSION) {
    tables->computeErrorBits();
  }

  if (ENABLE_GCS_COMPRESSION) {
    if (ENABLE_GCS_COLUMN_COMPRESSION) {
      tables->mergeActionColumns();
    }
    tables->mergeActionRows();

    if (ENABLE_GCS_COLUMN_COMPRESSION) {
      tables->mergeGotoColumns();
    }
    tables->mergeGotoRows();
  }
}


// this is a depth-first traversal of the 'derivable' relation;
// when we reach a nonterminal that can't derive any others not
// already in the order, we give its entry the latest ordinal
// that isn't already taken ('nextOrdinal')
void GrammarAnalysis::topologicalSort(
  NtIndex *order,    // table we're filling with ordinals
  int &nextOrdinal,  // latest ordinal not yet used
  NtIndex current,   // current nonterminal to expand
  BitArray &seen)    // set of nonterminals we've already seen
{
  if (seen.test(current)) {
    // already expanded this one
    return;
  }

  // don't expand this one again
  seen.set(current);

  // look at all nonterminals this one can derive
  for (int nt=0; nt < numNonterms; nt++) {
    if (derivable->get(point(nt, current))) {
      // 'nt' can derive 'current'; expand 'nt' first, thus making
      // it later in the order, so we'll reduce to 'current' before
      // reducing to 'nt' (when token spans are equal)
      xassert((NtIndex)nt == nt);
      topologicalSort(order, nextOrdinal, (NtIndex)nt, seen);
    }
  }

  // finally, put 'current' into the order
  order[current] = nextOrdinal;
  nextOrdinal--;
}


SymbolId encodeSymbolId(Symbol const *sym)
{
  int ret;
  if (!sym) {
    ret = 0;
  }
  else if (sym->isTerminal()) {
    ret = sym->asTerminalC().termIndex + 1;
  }
  else /*nonterminal*/ {
    ret = - sym->asNonterminalC().ntIndex - 1;
    
    // verify encoding of nonterminals is sufficiently wide
    int idx = sym->asNonterminalC().ntIndex;
    xassert((NtIndex)idx == idx);
  }      
  
  // verify encoding is lossless
  SymbolId ret2 = (SymbolId)ret;
  xassert((int)ret2 == ret);
  return ret2;
}


// --------------- sample inputs -------------------
// yield a sequence of names of symbols (terminals and nonterminals) that
// will lead to the given state, from the start state
sm_string GrammarAnalysis::leftContextString(ItemSet const *state) const
{
  SymbolList ctx;
  leftContext(ctx, state);                // get as list
  return symbolSequenceToString(ctx);     // convert to sm_string
}


// yield the left-context as a sequence of symbols
// CONSTNESS: want output as list of const pointers
void GrammarAnalysis::leftContext(SymbolList &output,
                                  ItemSet const *state) const
{
  // since we have the BFS tree, generating sample input (at least, if
  // it's allowed to contain nonterminals) is a simple matter of walking
  // the tree towards the root

  // for each parent..
  while (state->BFSparent) {
    // get that parent
    ItemSet *parent = state->BFSparent;

    // find a symbol on which we would transition from the parent
    // to the current state
    Symbol const *sym = inverseTransitionC(parent, state);

    // prepend that symbol's name to our current context
    output.prepend(const_cast<Symbol*>(sym));

    // move to our parent and repeat
    state = parent;
  }
}


// compare two-element quantities where one dominates and the other is
// only for tie-breaking; return <0/=0/>0 if a's quantities are
// fewer/equal/grearter (this fn is a candidate for adding to a
// library somewhere)
int priorityCompare(int a_dominant, int b_dominant,
                    int a_recessive, int b_recessive)
{
  if (a_dominant < b_dominant) return -1;
  if (a_dominant > b_dominant) return +1;
  return a_recessive - b_recessive;
}

int priorityFewer(int a_dominant, int b_dominant,
                  int a_recessive, int b_recessive)
{
  return priorityCompare(a_dominant, b_dominant,
                         a_recessive, b_recessive) < 1;
}


// sample input (terminals only) that can lead to a state
sm_string GrammarAnalysis::sampleInput(ItemSet const *state) const
{
  // get left-context as terminals and nonterminals
  SymbolList symbols;
  leftContext(symbols, state);

  // reduce the nonterminals to terminals
  TerminalList terminals;
  if (!rewriteAsTerminals(terminals, symbols)) {
    return sm_string("(failed to reduce!!)");
  }
  
  // convert to a sm_string
  return terminalSequenceToString(terminals);
}


// given a sequence of symbols (terminals and nonterminals), use the
// productions to rewrite it as a (hopefully minimal) sequence of
// terminals only; return true if it works, false if we get stuck
// in an infinite loop
// CONSTNESS: ideally, 'output' would contain const ptrs to terminals
bool GrammarAnalysis::rewriteAsTerminals(TerminalList &output, SymbolList const &input) const
{
  // we detect looping by noticing if we ever reduce via the same
  // production more than once in a single vertical recursive slice
  ProductionList reductionStack;      // starts empty

  // start the recursive version
  return rewriteAsTerminalsHelper(output, input, reductionStack);
}


// (nonterminals and terminals) -> terminals;
// if this returns false, it's guaranteed to return with 'output'
// unchanged from when the function was invoked
bool GrammarAnalysis::
  rewriteAsTerminalsHelper(TerminalList &output, SymbolList const &input,
                           ProductionList &reductionStack) const
{
  // remember the initial 'output' length so we can restore
  int origLength = output.count();

  // walk down the input list, creating the output list by copying
  // terminals and reducing nonterminals
  SFOREACH_SYMBOL(input, symIter) {
    Symbol const *sym = symIter.data();

    if (sym->isEmptyString) {
      // easy; no-op
    }

    else if (sym->isTerminal()) {
      // no sweat, just copy it (er, copy the pointer)
      output.append(const_cast<Terminal*>(&sym->asTerminalC()));
    }

    else {
      // not too bad either, just reduce it, sticking the result
      // directly into our output list
      if (!rewriteSingleNTAsTerminals(output, &sym->asNonterminalC(),
                                      reductionStack)) {
        // oops.. restore 'output'
        while (output.count() > origLength) {
          output.removeAt(origLength);
        }
        return false;
      }
    }
  }

  // ok!
  return true;
}


// for rewriting into sequences of terminals, we prefer rules with
// fewer nonterminals on the RHS, and then (to break ties) rules with
// fewer RHS symbols altogether; overriding all of this, if one
// production's RHS contains a symbol already expanded, and the other
// does not, then prefer the RHS which hasn't already been expanded
int compareProductionsForRewriting(Production const *p1, Production const *p2, 
                                   void *extra)
{                                             
  ProductionList *reductionStack = (ProductionList*)extra;
   
  bool p1RHSSeen=false, p2RHSSeen=false;
  SFOREACH_PRODUCTION(*reductionStack, iter) {
    if (p1->rhsHasSymbol( iter.data()->left )) {
      p1RHSSeen = true;
    }
    if (p2->rhsHasSymbol( iter.data()->left )) {
      p2RHSSeen = true;
    }
  }                                     
  
  if (p1RHSSeen != p2RHSSeen) {  
    // e.g.: p1RHSSeen=true, so p2 is preferred; this will yield +1,
    // meaning p1>p2, so p2 comes first in an increasing order sort
    return (int)p1RHSSeen - (int)p2RHSSeen;
  }

  return priorityCompare(p1->numRHSNonterminals(), p2->numRHSNonterminals(),
                         p1->rhsLength(), p2->rhsLength());
}

// nonterminal -> terminals
// CONSTNESS: want 'reductionStack' to be list of const ptrs
bool GrammarAnalysis::
  rewriteSingleNTAsTerminals(TerminalList &output, Nonterminal const *nonterminal,
                             ProductionList &reductionStack) const
{
  // get all of 'nonterminal's productions that are not recursive
  ProductionList candidates;
  FOREACH_PRODUCTION(productions, prodIter) {
    Production const *prod = prodIter.data();
    if (prod->left != nonterminal) continue;

    // if 'prod' has 'nonterminal' on RHS, that would certainly
    // lead to looping (though it's not the only way -- consider
    // mutual recursion), so don't even consider it
    if (prod->rhsHasSymbol(nonterminal)) {
      continue;
    }

    // if this production has already been used, don't use it again
    if (reductionStack.contains(prod)) {
      continue;
    }

    // it's a candidate
    candidates.prepend(const_cast<Production*>(prod));   // constness
  }

  if (candidates.isEmpty()) {
    // I don't expect this... either the NT doesn't have any rules,
    // or all of them are recursive (which means the language doesn't
    // have any finite sentences)
    trace("rewrite") << "couldn't find any unused, non-recursive rules for "
                     << nonterminal->name << endl;
    return false;
  }

  // sort them into order of preference
  candidates.mergeSort(compareProductionsForRewriting, &reductionStack);

  // try each in turn until one succeeds; this effectively uses
  // backtracking when one fails
  bool retval = false;
  SFOREACH_PRODUCTION(candidates, candIter) {
    Production const *prod = candIter.data();

    // add chosen production to the stack
    reductionStack.prepend(const_cast<Production*>(prod));

    // now, the chosen rule provides a RHS, which is a sequence of
    // terminals and nonterminals; recursively reduce that sequence
    SymbolList rhsSymbols;
    prod->getRHSSymbols(rhsSymbols);
    retval = rewriteAsTerminalsHelper(output, rhsSymbols, reductionStack);

    // remove chosen production from stack
    Production *temp = reductionStack.removeFirst();
    xassert(temp == prod);

    if (retval) {
      // success!
      break;
    }
    else {
      // failed; try the next production
    }
  }

  // and we succeed only if we found a valid rewriting
  return retval;
}

// --------------- END of sample inputs -------------------


// this is mostly [ASU] algorithm 4.7, p.218-219: an SLR(1) parser
void GrammarAnalysis::lrParse(char const *input)
{
  // tokenize the input
  StrtokParse tok(input, " \t");

  // parser state
  int currentToken = 0;               // index of current token
  StateId state = startState->id;     // current parser state
  ArrayStack<StateId> stateStack;     // stack of parser states; top==state
  stateStack.push(state);
  ArrayStack<Symbol const*> symbolStack;    // stack of shifted symbols

  // for each token of input
  while (currentToken < tok) {
    // map the token text to a symbol
    Terminal *symbol = findTerminal(tok[currentToken]);     // (constness)

    // consult action table
    ActionEntry action = tables->getActionEntry(state, symbol->termIndex);

    // see what kind of action it is
    if (tables->isShiftAction(action)) {
      // shift
      StateId destState = tables->decodeShift(action, symbol->termIndex);

      // push current state and symbol
      state = destState;
      stateStack.push(state);
      symbolStack.push(symbol);

      // next input symbol
      currentToken++;

      // debugging
      trace("parse")
        << "moving to state " << state
        << " after shifting symbol " << symbol->name << endl;
    }

    else if (tables->isReduceAction(action)) {
      // reduce
      int prodIndex = tables->decodeReduce(action, state);
      ParseTables::ProdInfo const &info = tables->getProdInfo(prodIndex);

      // it is here that an action or tree-building step would
      // take place

      // pop as many symbols off stacks as there are symbols on
      // the right-hand side of 'prod'
      stateStack.popMany(info.rhsLen);
      state = stateStack.top();
      symbolStack.popMany(info.rhsLen);

      // find out where to go
      StateId destState = tables->decodeGoto(
        tables->getGotoEntry(state, info.lhsIndex), info.lhsIndex);

      // go there
      state = destState;
      stateStack.push(state);

      // and push the reduced nonterminal
      symbolStack.push(getNonterminal(info.lhsIndex));

      // debugging
      trace("parse")
        << "moving to state " << state
        << " after reducing by rule id " << prodIndex << endl;
    }

    else if (tables->isErrorAction(action)) {
      // error
      trace("parse")
        << "no actions defined for symbol " << symbol->name
        << " in state " << state << endl;
      break;       // stop parsing
    }

    else {
      // conflict
      trace("parse")
        << "conflict for symbol " << symbol->name
        << " in state " << state
        << "; possible actions:\n";

      // get actions
      ActionEntry *entry = tables->decodeAmbigAction(action, state);

      // explain each one
      for (int i=0; i<entry[0]; i++) {
        action = entry[i+1];
        if (tables->isShiftAction(action)) {
          trace("parse") << "  shift, and move to state "
                         << tables->decodeShift(action, symbol->termIndex) << endl;
        }
        else if (tables->isReduceAction(action)) {
          trace("parse") << "  reduce by rule id "
                         << tables->decodeReduce(action, state) << endl;
        }
        else {
          // no other alternative makes sense
          xfailure("bad code in ambiguous action table");
        }
      }

      break;       // stop parsing
    }
  }

  // print final contents of stack; if the parse was successful,
  // I want to see what remains; if not, it's interesting anyway
  trace("parse") << "final contents of stacks (right is top):\n";

  ostream &os = trace("parse") << "  state stack:";
  int i;
  for (i=0; i < stateStack.length(); i++) {
    os << " " << stateStack[i];
  }
  os << " <-- current" << endl;

  os << "  symbol stack:";
  for (i=0; i < symbolStack.length(); i++) {
    os << " " << symbolStack[i]->name;
  }
  os << endl;
}


// ------------------- grammar transformations ------------------
void GrammarAnalysis::addTreebuildingActions()
{
  #define STR(s) LITERAL_LOCSTRING(grammarStringTable.add(s))

  // prepend an #include to the verbatim
  {
    StringRef extra = grammarStringTable.add(
      "\n#include \"ptreenode.h\"     // PTreeNode\n");
    verbatim.prepend(new LITERAL_LOCSTRING(extra));
  }

  // get handles to the sm_strings we want to emit
  LocString param = STR("n");
  LocString dupCode = STR("return n;");    // dup is identity
  LocString delCode = STR("");             // del is no-op
  LocString svalType = STR("PTreeNode*");

  // merge relies on chaining scheme for alternatives
  LocString mergeParam1 = STR("L");
  LocString mergeParam2 = STR("R");
  LocString mergeCode = STR("L->addAlternative(R); return L;");

  // write dup/del/merge for nonterminals
  MUTATE_EACH_OBJLIST(Nonterminal, nonterminals, ntIter) {
    Nonterminal *nt = ntIter.data();

    nt->dupParam = param;
    nt->dupCode = dupCode;

    nt->delParam = param;
    nt->delCode = delCode;

    nt->type = svalType;

    nt->mergeParam1 = mergeParam1;
    nt->mergeParam2 = mergeParam2;
    nt->mergeCode = mergeCode;
  }

  // write treebuilding actions for productions
  MUTATE_EACH_OBJLIST(Production, productions, prodIter) {
    Production *p = prodIter.data();

    // build up the code
    sm_stringBuilder code;
    code << "return new PTreeNode(\"" << p->left->name << " -> "
         << encodeWithEscapes(p->rhsString(false /*printTags*/, 
                                           true /*quoteAliases*/))
         << "\"";

    int ct=1;
    MUTATE_EACH_OBJLIST(Production::RHSElt, p->right, rIter) {
      Production::RHSElt *elt = rIter.data();

      // connect nonterminal subtrees; drop lexemes on the floor
      if (elt->sym->isNonterminal()) {
        // use a generic tag
        sm_string tag = sm_stringc << "t" << ct++;
        elt->tag = STR(tag);

        code << ", " << tag;
      }
    }

    code << ");";

    // insert the code into the production    
    p->action = LocString(SL_UNKNOWN, 
                          grammarStringTable.add(code));
  }

  #undef STR
}


// ---------------------------- main --------------------------------
void pretendUsed(...)
{}


void GrammarAnalysis::exampleGrammar()
{
  // at one time I was using this to verify my LR item set
  // construction code; this function isn't even called anymore..
  readGrammarFile(*this, "examples/asu419.gr");

  char const *input[] = {
    " id                 $",
    " id + id            $",
    " id * id            $",
    " id + id * id       $",
    " id * id + id       $",
    " ( id + id ) * id   $",
    " id + id + id       $",
    " id + ( id + id )   $"
  };

  // verify we got what we expected
  printProductions(trace("grammar") << endl);


  // run analyses
  runAnalyses(NULL);


  // do some test parses
  INTLOOP(i, 0, (int)TABLESIZE(input)) {
    trace("parse") << "------ parsing: `" << input[i] << "' -------\n";
    lrParse(input[i]);
  }
}


void GrammarAnalysis::runAnalyses(char const *setsFname)
{            
  // prepare for symbol of interest
  {
    char const *name = getenv("SYM_OF_INTEREST");
    if (name != NULL) {
      symOfInterest = findSymbolC(name);
      if (!symOfInterest) {
        cout << "warning: " << name << " isn't in the grammar\n";
      }
    }
  }

  // reset error count so it might be possible to reuse the object
  // for another grammar
  errors = 0;

  checkWellFormed();

  // precomputations
  traceProgress(1) << "init...\n";
  initializeAuxData();

  traceProgress(1) << "derivability relation...\n";
  computeWhatCanDeriveWhat();

  computeSupersets();

  traceProgress(1) << "first...\n";
  computeFirst();
  computeDProdFirsts();

  traceProgress(1) << "follow...\n";
  computeFollow();

  // print results
  {
    ostream &tracer = trace("terminals") << "Terminals:\n";
    printSymbols(tracer, toObjList(terminals));
  }
  {
    ostream &tracer = trace("nonterminals") << "Nonterminals:\n";
    tracer << "  " << emptyString << endl;
    printSymbols(tracer, toObjList(nonterminals));
  }

  if (tracingSys("derivable")) {
    derivable->print();
  }

  // testing closure
  #if 0
  {
    // make a singleton set out of the first production, and
    // with the dot at the start
    ObjList<LRItem> itemSet;
    LRItem *kernel = productions.nth(0)->getDProd(0);  // (serf)
    itemSet.append(kernel);

    // compute its closure
    itemSetClosure(itemSet);

    // print it
    cout << "Closure of: ";
    kernel->print(cout);
    cout << endl;
                 
    SFOREACH_OBJLIST(LRItem, itemSet, dprod) {
      cout << "  ";
      dprod.data()->print(cout);
      cout << endl;
    }
  }
  #endif // 0


  // LR stuff
  traceProgress(1) << "LR item sets...\n";
  constructLRItemSets();

  traceProgress(1) << "state renumbering...\n";
  renumberStates();

  traceProgress(1) << "parse tables...\n";
  computeParseTables(!tracingSys("deterministic"));

  #if 0     // old code; need it for just a while longer
  {
    int sr=0, rr=0;           // numbers of each kind of conflict
    findSLRConflicts(sr, rr);
    if (sr + rr > 0) {
      cout << sr << " shift/reduce conflicts and "
           << rr << " reduce/reduce conflicts\n";
    }
  }
  #endif // 0

  // if we want to print, do so before throwing away the items
  if (tracingSys("itemsets")) {
    printProductionsAndItems(cout, true /*code*/);
  }

  // open debug output file
  ofstream *setsOutput = NULL;
  if (setsFname) {
    setsOutput = new ofstream(setsFname);
    if (!*setsOutput) {
      cout << "couldn't open " << setsFname << " to write item sets\n";
      delete setsOutput;
      setsOutput = NULL;
    }
  }

  // count the number of unreachable nonterminals & terminals
  {                   
    if (setsOutput) {
      *setsOutput << "unreachable nonterminals:\n";
    }
    int ct=0;
    FOREACH_NONTERMINAL(nonterminals, iter) {
      if (!iter.data()->reachable) {
        ct++;

        if (setsOutput) {
          *setsOutput << "  " << iter.data()->name << "\n";
        }
      }
    }

    reportUnexpected(ct, expectedUNRNonterms, "unreachable nonterminals");

    // bison also reports the number of productions under all the
    // unreachable nonterminals, but that doesn't seem especially
    // useful to me

    if (setsOutput) {
      *setsOutput << "unreachable terminals:\n";
    }
    ct=0;
    FOREACH_TERMINAL(terminals, jter) {
      if (!jter.data()->reachable) {
        ct++;

        if (setsOutput) {
          *setsOutput << "  " << jter.data()->name << "\n";
        }
      }
    }

    reportUnexpected(ct, expectedUNRTerms, "unreachable terminals");
  }

  // print the item sets
  if (setsOutput) {
    traceProgress() << "printing item sets to " << setsFname << " ..." << endl;
    *setsOutput << "NOTE: Item set numbers can change depending on what flags\n"
                << "are passed to 'elkhound'!\n\n\n";
    // only print the nonkernel items if they're explicitly requested,
    // since they are more noise than signal, usually
    printItemSets(*setsOutput, tracingSys("nonkernel"));
  }

  // print information about all tokens
  if (setsOutput) {
    *setsOutput << "terminals:\n";
    FOREACH_TERMINAL(terminals, iter) {
      Terminal const *t = iter.data();
      *setsOutput << "  ";
      t->print(*setsOutput);
      *setsOutput << "\n";
    }

    // and nonterminals
    *setsOutput << "nonterminals:\n";
    FOREACH_NONTERMINAL(nonterminals, ntIter) {
      Nonterminal const *nt = ntIter.data();
      *setsOutput << "  ";
      nt->print(*setsOutput);
      *setsOutput << "\n";
    }

    // and productions
    *setsOutput << "productions:\n";
    for (int p=0; p<numProds; p++) {
      *setsOutput << "  ";
      getProduction(p)->print(*setsOutput);
      *setsOutput << "\n";
    }
  }


  delete setsOutput;

  // I don't need (most of) the item sets during parsing, so
  // throw them away once I'm done analyzing the grammar
  MUTATE_EACH_OBJLIST(ItemSet, itemSets, iter) {
    iter.data()->throwAwayItems();
  }


  // another analysis
  //computePredictiveParsingTable();

  // silence warnings
  //pretendUsed(a,b,c,d,e, S,A,B,C,D);
}


// ------------------ emitting action code -----------------------
// prototypes for this section; some of them accept Grammar simply
// because that's all they need; there's no problem upgrading them
// to GrammarAnalysis
void emitDescriptions(GrammarAnalysis const &g, EmitCode &out);
void emitActionCode(GrammarAnalysis const &g, char const *hFname,
                    char const *ccFname, char const *srcFname);
void emitUserCode(EmitCode &out, LocString const &code, bool braces = true);
void emitActions(Grammar const &g, EmitCode &out, EmitCode &dcl);
void emitDupDelMerge(GrammarAnalysis const &g, EmitCode &out, EmitCode &dcl);
void emitFuncDecl(Grammar const &g, EmitCode &out, EmitCode &dcl,
                  char const *rettype, char const *params);
void emitDDMInlines(Grammar const &g, EmitCode &out, EmitCode &dcl,
                    Symbol const &sym);
void emitSwitchCode(Grammar const &g, EmitCode &out,
                    char const *signature, char const *switchVar,
                    ObjList<Symbol> const &syms, int whichFunc,
                    char const *templateCode, char const *actUpon);


// yield the name of the inline function for this production; naming
// design motivated by desire to make debugging easier
sm_string actionFuncName(Production const &prod)
{
  return sm_stringc << "action" << prod.prodIndex
                 << "_" << prod.left->name;
}


// emit the user's action code to a file
void emitActionCode(GrammarAnalysis const &g, char const *hFname,
                    char const *ccFname, char const *srcFname)
{
  EmitCode dcl(hFname);
  if (!dcl) {
    throw_XOpen(hFname);
  }

  sm_string latchName = replace(replace(replace(
                       sm_stringToupper(hFname),
                         ".", "_"),
                         "/", "_"),
                         "-", "_");
      
  // prologue
  dcl << "// " << hFname << "\n"
      << "// *** DO NOT EDIT BY HAND ***\n"
      << "// automatically generated by elkhound, from " << srcFname << "\n"
      << "\n"
      << "#ifndef " << latchName << "\n"
      << "#define " << latchName << "\n"
      << "\n"
      << "#include \"elk_useract.h\"     // UserActions\n"
      << "\n"
      ;

  // insert the stand-alone verbatim sections
  {FOREACH_OBJLIST(LocString, g.verbatim, iter) {
    emitUserCode(dcl, *(iter.data()), false /*braces*/);
  }}

  // insert each of the context class definitions; the last one
  // is the one whose name is 'g.actionClassName' and into which
  // the action functions are inserted as methods
  {
    int ct=0;
    FOREACH_OBJLIST(LocString, g.actionClasses, iter) {
      if (ct++ > 0) {
        // end the previous class; the following body will open
        // another one, and the brace following the action list
        // will close the last one
        dcl << "};\n";
      }

      dcl << "\n"
          << "// parser context class\n"
          << "class ";
      emitUserCode(dcl, *(iter.data()), false /*braces*/);
  }}

  // we end the context class with declarations of the action functions
  dcl << "\n"
      << "private:\n"
      << "  USER_ACTION_FUNCTIONS      // see useract.h\n"
      << "\n"
      << "  // declare the actual action function\n"
      << "  static SemanticValue doReductionAction(\n"
      << "    " << g.actionClassName << " *ths,\n"
      << "    int productionId, SemanticValue const *semanticValues"
         SOURCELOC( << ",\n  SourceLoc loc" )
      << ");\n"
      << "\n"
      << "  // declare the classifier function\n"
      << "  static int reclassifyToken(\n"
      << "    " << g.actionClassName << " *ths,\n"
      << "    int oldTokenType, SemanticValue sval);\n"
      << "\n"
      ;

  EmitCode out(ccFname);
  if (!out) {
    throw_XOpen(ccFname);
  }

  out << "// " << ccFname << "\n";
  out << "// *** DO NOT EDIT BY HAND ***\n";
  out << "// automatically generated by gramanl, from " << srcFname << "\n";
  out << "\n";
  #ifdef NO_GLR_SOURCELOC
    // we need to make sure the USER_ACTION_FUNCTIONS use
    // the declarations consistent with how we're printing
    // the definitions
    out << "#ifndef NO_GLR_SOURCELOC\n";
    out << "  #define NO_GLR_SOURCELOC\n";
    out << "#endif\n";
  #else
    out << "// GLR source location information is enabled\n";
  #endif
  out << "\n";
  out << "#include \"" << sm_basename(hFname).pchar() << "\"     // " << g.actionClassName << "\n";
  out << "#include \"elk_parsetables.h\" // ParseTables\n";
  out << "#include \"sm_srcloc.h\"      // SourceLoc\n";
  out << "\n";
  out << "#include <assert.h>      // assert\n";
  out << "#include <iostream.h>    // cout\n";
  out << "#include <stdlib.h>      // abort\n";
  out << "\n";

  NOSOURCELOC(
    out << "// parser-originated location information is disabled by\n"
        << "// NO_GLR_SOURCELOC; any rule which refers to 'loc' will get this one\n"
        << "static SourceLoc loc = SL_UNKNOWN;\n"
        << "\n\n";
  )

  emitDescriptions(g, out);
  // 'emitDescriptions' prints two newlines itself..

  emitActions(g, out, dcl);
  out << "\n";
  out << "\n";

  emitDupDelMerge(g, out, dcl);
  out << "\n";
  out << "\n";

  g.tables->finishTables();
  g.tables->emitConstructionCode(out, g.actionClassName, "makeTables");

  // I put this last in the context class, and make it public
  dcl << "\n"
      << "// the function which makes the parse tables\n"
      << "public:\n"
      << "  virtual ParseTables *makeTables();\n"
      << "};\n"
      << "\n"
      << "#endif // " << latchName << "\n"
      ;
      
  // finish the implementation file with the impl_verbatim sections
  FOREACH_OBJLIST(LocString, g.implVerbatim, iter) {
    emitUserCode(out, *(iter.data()), false /*braces*/);
  }
}


void emitUserCode(EmitCode &out, LocString const &code, bool braces)
{
  out << "\n";
  if (code.validLoc()) {
    out << lineDirective(code.loc);
  }
  
  // 7/27/03: swapped so that braces are inside the line directive
  if (braces) {
    out << "{";
  }

  out << code;

  // the final brace is on the same line so errors reported at the
  // last brace go to user code
  if (braces) {
    out << " }";
  }

  if (code.validLoc()) {
    out << "\n" << restoreLine;
  }
  out << "\n";
}


// bit of a hack: map "void" to "SemanticValue" so that the compiler
// won't mind when I try to declare parameters of that type
char const *notVoid(char const *type)
{
  if (0==strcmp(type, "void")) {
    return "SemanticValue";
  }
  else {
    return type;
  }
}

// yield the given type, but if it's NULL, then yield
// something to use instead
char const *typeString(char const *type, LocString const &tag)
{
  if (!type) {
    xbase(sm_stringc << tag.locString() << ": Production tag \"" << tag
                  << "\" on a symbol with no type.\n");
    return NULL;     // silence warning
  }
  else {
    return notVoid(type);
  }
}


// return true if the type starts with the word "enum"
bool isEnumType(char const *type)
{
  return 0==strncmp(type, "enum", 4);
}


void emitDescriptions(GrammarAnalysis const &g, EmitCode &out)
{
  // emit a map of terminal ids to their names
  {
    out << "static char const *termNames[] = {\n";
    for (int code=0; code < g.numTerminals(); code++) {
      Terminal const *t = g.getTerminal(code);
      if (!t) {
        // no terminal for that code
        out << "  \"(no terminal)\",  // " << code << "\n";
      }
      else {
        out << "  \"" << t->name << "\",  // " << code << "\n";
      }
    }
    out << "};\n"
        << "\n";
  }

  // emit a function to describe terminals; at some point I'd like to
  // extend my grammar format to allow the user to supply
  // token-specific description functions, but for now I will just
  // use the information easily available the synthesize one;
  // I print "sval % 100000" so I get a 5-digit number, which is
  // easy for me to compare for equality without adding much clutter
  out << "sm_string " << g.actionClassName
      << "::terminalDescription(int termId, SemanticValue sval)\n"
      << "{\n"
      << "  return sm_stringc << termNames[termId]\n"
      << "                 << \"(\" << (sval % 100000) << \")\";\n"
      << "}\n"
      << "\n"
      << "\n"
      ;

  // emit a map of nonterminal ids to their names
  {
    out << "static char const *nontermNames[] = {\n";
    for (int code=0; code < g.numNonterminals(); code++) {
      Nonterminal const *nt = g.getNonterminal(code);
      if (!nt) {
        // no nonterminal for that code
        out << "  \"(no nonterminal)\",  // " << code << "\n";
      }
      else {
        out << "  \"" << nt->name << "\",  // " << code << "\n";
      }
    }
    out << "};\n"
        << "\n";
  }

  // and a function to describe nonterminals also
  out << "sm_string " << g.actionClassName
      << "::nonterminalDescription(int nontermId, SemanticValue sval)\n"
      << "{\n"
      << "  return sm_stringc << nontermNames[nontermId]\n"
      << "                 << \"(\" << (sval % 100000) << \")\";\n"
      << "}\n"
      << "\n"
      << "\n"
      ;
      
  // emit functions to get access to the static maps
  out << "char const *" << g.actionClassName
      << "::terminalName(int termId)\n"
      << "{\n"
      << "  return termNames[termId];\n"
      << "}\n"
      << "\n"
      << "char const *" << g.actionClassName
      << "::nonterminalName(int nontermId)\n"
      << "{\n"
      << "  return nontermNames[nontermId];\n"
      << "}\n"
      << "\n"
      ;
}


void emitActions(Grammar const &g, EmitCode &out, EmitCode &dcl)
{
  out << "// ------------------- actions ------------------\n";

  // iterate over productions, emitting inline action functions
  {FOREACH_OBJLIST(Production, g.productions, iter) {
    Production const &prod = *(iter.data());

    // there's no syntax for a typeless nonterminal, so this shouldn't
    // be triggerable by the user
    xassert(prod.left->type);

    // put the production in comments above the defn
    out << "// " << prod.toString() << "\n";

    out << "inline " << prod.left->type << " "
        << g.actionClassName << "::" << actionFuncName(prod)
        << "("
        SOURCELOC( << "SourceLoc loc" )
        ;

    dcl << "  " << prod.left->type << " " << actionFuncName(prod) << "("
        SOURCELOC( << "SourceLoc loc" )
        ;

    int ct=0;
    SOURCELOC( ct++ );    // if we printed the 'loc' param, count it

    // iterate over RHS elements, emitting formals for each with a tag
    FOREACH_OBJLIST(Production::RHSElt, prod.right, rhsIter) {
      Production::RHSElt const &elt = *(rhsIter.data());
      if (elt.tag.length() == 0) continue;

      if (ct++ > 0) {
        out << ", ";
        dcl << ", ";
      }

      out << typeString(elt.sym->type, elt.tag);
      dcl << typeString(elt.sym->type, elt.tag);

      // the tag becomes the formal parameter's name
      out << " " << elt.tag;
      dcl << " " << elt.tag;
    }

    out << ")";
    dcl << ");\n";

    // now insert the user's code, to execute in this environment of
    // properly-typed semantic values
    emitUserCode(out, prod.action);
  }}

  out << "\n";

  // main action function; calls the inline functions emitted above
  out << "/*static*/ SemanticValue " << g.actionClassName << "::doReductionAction(\n"
      << "  " << g.actionClassName << " *ths,\n"
      << "  int productionId, SemanticValue const *semanticValues"
      SOURCELOC( << ",\n  SourceLoc loc" )
      << ")\n";
  out << "{\n";
  out << "  switch (productionId) {\n";

  // iterate over productions
  FOREACH_OBJLIST(Production, g.productions, iter) {
    Production const &prod = *(iter.data());

    out << "    case " << prod.prodIndex << ":\n";
    out << "      return (SemanticValue)(ths->" << actionFuncName(prod) << "("
        SOURCELOC( << "loc" )
        ;

    // iterate over RHS elements, emitting arguments for each with a tag
    int index = -1;      // index into 'semanticValues'
    int ct=0;
    SOURCELOC( ct++ );   // count 'loc' if it is passed
    FOREACH_OBJLIST(Production::RHSElt, prod.right, rhsIter) {
      Production::RHSElt const &elt = *(rhsIter.data());

      // we have semantic values in the array for all RHS elements,
      // even if they didn't get a tag
      index++;

      if (elt.tag.length() == 0) continue;

      if (ct++ > 0) {
        out << ", ";
      }

      // cast SemanticValue to proper type
      out << "(" << typeString(elt.sym->type, elt.tag) << ")";
      if (isEnumType(elt.sym->type)) {
        // egcs-1.1.2 complains when I cast from void* to enum, even
        // when there is a cast!  so let's put an intermediate cast
        // to int
        out << "(int)";
      }
      out << "(semanticValues[" << index << "])";
    }

    out << ")";     // end of argument list

    if (0==strcmp(prod.left->type, "void")) {
      // cute hack: turn the expression into a comma expression, with
      // the value returned being 0
      out << ", 0";
    }

    out << ");\n";
  }

  out << "    default:\n";
  out << "      assert(!\"invalid production code\");\n";
  out << "      return (SemanticValue)0;   // silence warning\n";
  out << "  }\n";
  out << "}\n";


  // now emit the UserActions function which returns the doReductionAction
  // function pointer
  out << "\n";
  out << "UserActions::ReductionActionFunc " << g.actionClassName << "::getReductionAction()\n";
  out << "{\n";
  out << "  return (ReductionActionFunc)&" << g.actionClassName << "::doReductionAction;\n";
  out << "}\n";

}


void emitDupDelMerge(GrammarAnalysis const &g, EmitCode &out, EmitCode &dcl)
{
  out << "// ---------------- dup/del/merge/keep nonterminals ---------------\n"
      << "\n";

  // emit inlines for dup/del/merge of nonterminals
  FOREACH_OBJLIST(Nonterminal, g.nonterminals, ntIter) {
    emitDDMInlines(g, out, dcl, *(ntIter.data()));
  }

  // emit dup-nonterm
  emitSwitchCode(g, out,
    "SemanticValue $acn::duplicateNontermValue(int nontermId, SemanticValue sval)",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    0 /*dupCode*/,
    "      return (SemanticValue)dup_$symName(($symType)sval);\n",
    NULL);

  // emit del-nonterm
  emitSwitchCode(g, out,
    "void $acn::deallocateNontermValue(int nontermId, SemanticValue sval)",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    1 /*delCode*/,
    "      del_$symName(($symType)sval);\n"
    "      return;\n",
    "deallocate nonterm");

  // emit merge-nonterm
  emitSwitchCode(g, out,
    "SemanticValue $acn::mergeAlternativeParses(int nontermId, SemanticValue left,\n"
    "                                           SemanticValue right"
    SOURCELOC(",  SourceLoc loc")
    ")",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    2 /*mergeCode*/,
    "      return (SemanticValue)merge_$symName(($symType)left, ($symType)right);\n",
    "merge nonterm");

  // emit keep-nonterm
  emitSwitchCode(g, out,
    "bool $acn::keepNontermValue(int nontermId, SemanticValue sval)",
    "nontermId",
    (ObjList<Symbol> const&)g.nonterminals,
    3 /*keepCode*/,
    "      return keep_$symName(($symType)sval);\n",
    NULL);


  out << "\n";
  out << "// ---------------- dup/del/classify terminals ---------------\n";
  // emit inlines for dup/del of terminals
  FOREACH_OBJLIST(Terminal, g.terminals, termIter) {
    emitDDMInlines(g, out, dcl, *(termIter.data()));
  }

  // emit dup-term
  emitSwitchCode(g, out,
    "SemanticValue $acn::duplicateTerminalValue(int termId, SemanticValue sval)",
    "termId",
    (ObjList<Symbol> const&)g.terminals,
    0 /*dupCode*/,
    "      return (SemanticValue)dup_$symName(($symType)sval);\n",
    NULL);

  // emit del-term
  emitSwitchCode(g, out,
    "void $acn::deallocateTerminalValue(int termId, SemanticValue sval)",
    "termId",
    (ObjList<Symbol> const&)g.terminals,
    1 /*delCode*/,
    "      del_$symName(($symType)sval);\n"
    "      return;\n",
    "deallocate terminal");

  // emit classify-term
  emitSwitchCode(g, out,
    "/*static*/ int $acn::reclassifyToken($acn *ths, int oldTokenType, SemanticValue sval)",
    "oldTokenType",
    (ObjList<Symbol> const&)g.terminals,
    4 /*classifyCode*/,
    "      return ths->classify_$symName(($symType)sval);\n",
    NULL);
    
  // and the virtual method which returns the classifier
  out << "UserActions::ReclassifyFunc " << g.actionClassName << "::getReclassifier()\n"
      << "{\n"
      << "  return (ReclassifyFunc)&" << g.actionClassName << "::reclassifyToken;\n"
      << "}\n";
}


// emit both the function decl for the .h file, and the beginning of
// the function definition for the .cc file
void emitFuncDecl(Grammar const &g, EmitCode &out, EmitCode &dcl,
                  char const *rettype, char const *params)
{
  out << "inline " << rettype << " " << g.actionClassName
      << "::" << params;

  dcl << "  inline " << rettype << " " << params << ";\n";
}


void emitDDMInlines(Grammar const &g, EmitCode &out, EmitCode &dcl,
                    Symbol const &sym)
{
  Terminal const *term = sym.ifTerminalC();
  Nonterminal const *nonterm = sym.ifNonterminalC();

  if (sym.dupCode) {
    emitFuncDecl(g, out, dcl, sym.type,
      sm_stringc << "dup_" << sym.name
              << "(" << sym.type << " " << sym.dupParam << ") ");
    emitUserCode(out, sym.dupCode);
  }

  if (sym.delCode) {
    emitFuncDecl(g, out, dcl, "void",
      sm_stringc << "del_" << sym.name
              << "(" << sym.type << " "
              << (sym.delParam? sym.delParam : "") << ") ");
    emitUserCode(out, sym.delCode);
  }

  if (nonterm && nonterm->mergeCode) {
    emitFuncDecl(g, out, dcl, notVoid(sym.type),
      sm_stringc << "merge_" << sym.name
              << "(" << notVoid(sym.type) << " " << nonterm->mergeParam1
              << ", " << notVoid(sym.type) << " " << nonterm->mergeParam2 << ") ");
    emitUserCode(out, nonterm->mergeCode);
  }

  if (nonterm && nonterm->keepCode) {
    emitFuncDecl(g, out, dcl, "bool",
      sm_stringc << "keep_" << sym.name
              << "(" << sym.type << " " << nonterm->keepParam << ") ");
    emitUserCode(out, nonterm->keepCode);
  }

  if (term && term->classifyCode) {
    emitFuncDecl(g, out, dcl, "int",
      sm_stringc << "classify_" << sym.name
              << "(" << sym.type << " " << term->classifyParam << ") ");
    emitUserCode(out, term->classifyCode);
  }
}

void emitSwitchCode(Grammar const &g, EmitCode &out,
                    char const *signature, char const *switchVar,
                    ObjList<Symbol> const &syms, int whichFunc,
                    char const *templateCode, char const *actUpon)
{
  out << replace(signature, "$acn", g.actionClassName) << "\n"
         "{\n"
         "  switch (" << switchVar << ") {\n";

  FOREACH_OBJLIST(Symbol, syms, symIter) {
    Symbol const &sym = *(symIter.data());

    if (whichFunc==0 && sym.dupCode ||
        whichFunc==1 && sym.delCode ||
        whichFunc==2 && sym.asNonterminalC().mergeCode ||
        whichFunc==3 && sym.asNonterminalC().keepCode ||
        whichFunc==4 && sym.asTerminalC().classifyCode) {
      out << "    case " << sym.getTermOrNontermIndex() << ":\n";
      out << replace(replace(templateCode,
               "$symName", sym.name),
               "$symType", notVoid(sym.type));
    }
  }

  out << "    default:\n";
  switch (whichFunc) {
    default:
      xfailure("bad func code");

    case 0:    // unspecified dup
      if (!g.useGCDefaults) {
        // not using GC, return NULL so silent sharing doesn't happen
        out << "      return (SemanticValue)0;\n";
      }
      else {
        // using GC, sharing is fine
        out << "      return sval;\n";
      }
      break;

    case 1:    // unspecified del
      if (!g.useGCDefaults) {
        // warn about unspec'd del, since it's probably a memory leak
        if (syms.firstC()->isNonterminal()) {
          // use the nonterminal map
          out << "      cout << \"WARNING: there is no action to deallocate nonterm \"\n"
                 "           << nontermNames[" << switchVar << "] << endl;\n";
        }
        else {
          // use the terminal map
          out << "      cout << \"WARNING: there is no action to deallocate terminal \"\n"
                 "           << termNames[" << switchVar << "] << endl;\n";
        }
      }
      else {
        // in gc mode, just ignore del
        out << "      break;\n";
      }
      break;

    case 2:    // unspecified merge: warn, but then use left (arbitrarily)
      out << "      cout << toString(loc) \n"
          << "           << \": WARNING: there is no action to merge nonterm \"\n"
          << "           << nontermNames[" << switchVar << "] << endl;\n";
      if (g.defaultMergeAborts) {
        out << "      abort();\n";
      }
      else {
        out << "      return left;\n";
      }
      break;

    case 3:    // unspecified keep: keep it
      out << "      return true;\n";
      break;

    case 4:    // unspecified classifier: identity map
      out << "      return oldTokenType;\n";
      break;
  }

  out << "  }\n"
         "}\n"
         "\n";
}


// ------------------------- main --------------------------
// TODO: split this into its own source file
#ifdef GRAMANL_MAIN

#include "sm_bflatten.h"
#include "sm_test.h"
#include "elk_gramast.ast.gen.h"

#include <stdio.h>             // remove
#include <stdlib.h>            // system


int inner_entry(int argc, char **argv)
{
  #define SHIFT argc--; argv++ /* user ; */

  char const *progName = argv[0];
  SHIFT;

  // disable 'Exception thrown' reports
  xBase::logExceptions = false;

  // as long as this remains 0-length, it means to use
  // the default naming scheme
  sm_string prefix;

  // true to use ML, false to use C
  bool useML = false;

  while (argv[0] && argv[0][0] == '-') {
    char const *op = argv[0]+1;
    if (0==strcmp(op, "tr")) {
      SHIFT;
      traceAddMultiSys(argv[0]);
      SHIFT;
    }
    else if (0==strcmp(op, "v")) {
      SHIFT;
      traceAddSys("progress");
    }
    else if (0==strcmp(op, "o")) {
      SHIFT;
      prefix = argv[0];
      SHIFT;
    }
    else if (0==strcmp(op, "testRW")) {
      SHIFT;
      cout << "The testRW option has been removed because I wasn't using\n"
              "it, and the code that implements it has bit-rotted.\n";
      exit(3);
    }
    else if (0==strcmp(op, "ocaml")) {
      SHIFT;
      useML = true;
    }
    else {
      cout << "unknown option: " << argv[0] << endl;
      exit(2);
    }
  }

  if (!argv[0]) {
    cout << "usage: " << progName << " [options] filename.gr [extension.gr [...]]\n"
            "  Generates parse tables to parse with the given grammar.\n"
            "  The optional extension modules can add rules, etc.\n"
            "\n"
            "options:\n"
            "  -tr <traceFlags>: turn on some flags (separate with commas):\n"
            "      conflict    : print LALR(1) conflicts\n"
            "      prec        : show how prec/assoc are used to resolve conflicts\n"
            "      lrtable     : print LR parsing tables to <prefix>.out\n"
            "      nonkernel   : include non-kernel items in <prefix>.out\n"
            "      treebuild   : replace given actions with treebuilding actions\n"
            "      grammar     : echo grammar to stdout (after merging modules)\n"
            "  -v              : print stages of processing\n"
            "  -o <prefix>     : name outputs <prefix>.h and <prefix>.cc\n"
            "                    (default is filename.gen.h, filename.gen.cc)\n"
            "  -ocaml          : generate ocaml parser instead of C++ parser\n"
            ;
    return 0;
  }

  if (!prefix.length()) {
    // default naming scheme
    prefix = replace(argv[0], ".gr", "");
  }

  SourceLocManager mgr;

  // parse the grammar
  sm_string grammarFname = argv[0];
  SHIFT;
  Owner<GrammarAST> ast(parseGrammarFile(grammarFname, useML));

  // parse and merge its extension modules
  while (argv[0]) {
    Owner<GrammarAST> ext(parseGrammarFile(argv[0], useML));

    traceProgress() << "merging module: " << argv[0] << endl;
    mergeGrammar(ast, ext);

    SHIFT;
  }

  // parse the AST into a Grammar
  GrammarAnalysis g;
  if (useML) {
    g.targetLang = "OCaml";
  }
  parseGrammarAST(g, ast);
  ast.del();              // done with it

  if (tracingSys("treebuild")) {
    cout << "replacing given actions with treebuilding actions\n";
    g.addTreebuildingActions();
  }
  g.printProductions(trace("grammar") << endl);

  sm_string setsFname = sm_stringc << prefix << ".out";
  g.runAnalyses(tracingSys("lrtable")? setsFname.pcharc() : NULL);
  if (g.errors) {
    return 2;
  }

  if (!useML) {
    // emit some C++ code
    sm_string hFname = sm_stringc << prefix << ".h";
    sm_string ccFname = sm_stringc << prefix << ".cc";
    traceProgress() << "emitting C++ code to " << ccFname
                    << " and " << hFname << " ...\n";

    emitActionCode(g, hFname, ccFname, grammarFname);
  }
  else {
    // emit some ML code
    sm_string mliFname = sm_stringc << prefix << ".mli";
    sm_string mlFname = sm_stringc << prefix << ".ml";
    traceProgress() << "emitting OCaml code to " << mlFname 
                    << " and " << mliFname << " ...\n";

    emitMLActionCode(g, mliFname, mlFname, grammarFname);
  }

  // before using 'xfer' we have to tell it about the sm_string table
  flattenStrTable = &grammarStringTable;

  // write it in a bison-compatible format as well
  if (tracingSys("bison")) {
    sm_string bisonFname = sm_stringc << prefix << ".y";
    traceProgress() << "writing bison-compatible grammar to " << bisonFname << endl;
    ofstream out(bisonFname);
    g.printAsBison(out);
  }

  traceProgress() << "done\n";

  // this doesn't work
  if (tracingSys("explore")) {
    grammarExplorer(g);
  }

  return 0;
}

void entry(int argc, char **argv)
{
  int ret = inner_entry(argc, argv);
  if (ret != 0) {
    exit(ret);
  }
}

ARGS_MAIN

#endif // GRAMANL_MAIN
@h=tangler('elk/elk_gramast.ast.gen.cpp')
@select(h)
// gramast.ast.gen.cc
// *** DO NOT EDIT ***
// generated automatically by astgen, from gramast.ast

#include "elk_gramast.ast.gen.h"


// ------------------ GrammarAST -------------------
// *** DO NOT EDIT ***
GrammarAST::~GrammarAST()
{
  forms.deleteAll();
}

void GrammarAST::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, GrammarAST);

  PRINT_LIST(TopForm, forms);
}

GrammarAST *GrammarAST::clone() const
{
  GrammarAST *ret = new GrammarAST(
    cloneASTList(forms)
  );
  return ret;
}


// ------------------ TopForm -------------------
// *** DO NOT EDIT ***
TopForm::~TopForm()
{
}

char const * const TopForm::kindNames[TopForm::NUM_KINDS] = {
  "TF_context",
  "TF_verbatim",
  "TF_option",
  "TF_terminals",
  "TF_nonterm",
};

void TopForm::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
}

DEFN_AST_DOWNCASTS(TopForm, TF_context, TF_CONTEXT)

TF_context::~TF_context()
{
}

void TF_context::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TF_context);

  TopForm::debugPrint(os, indent, subtreeName);

  PRINT_GENERIC(body);
}

TF_context *TF_context::clone() const
{
  TF_context *ret = new TF_context(
    body.clone()
  );
  return ret;
}

DEFN_AST_DOWNCASTS(TopForm, TF_verbatim, TF_VERBATIM)

TF_verbatim::~TF_verbatim()
{
}

void TF_verbatim::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TF_verbatim);

  TopForm::debugPrint(os, indent, subtreeName);

  PRINT_BOOL(isImpl);
  PRINT_GENERIC(code);
}

TF_verbatim *TF_verbatim::clone() const
{
  TF_verbatim *ret = new TF_verbatim(
    isImpl,
    code.clone()
  );
  return ret;
}

DEFN_AST_DOWNCASTS(TopForm, TF_option, TF_OPTION)

TF_option::~TF_option()
{
}

void TF_option::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TF_option);

  TopForm::debugPrint(os, indent, subtreeName);

  PRINT_GENERIC(name);
  PRINT_GENERIC(value);
}

TF_option *TF_option::clone() const
{
  TF_option *ret = new TF_option(
    name.clone(),
    value
  );
  return ret;
}

DEFN_AST_DOWNCASTS(TopForm, TF_terminals, TF_TERMINALS)

TF_terminals::~TF_terminals()
{
  decls.deleteAll();
  types.deleteAll();
  prec.deleteAll();
}

void TF_terminals::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TF_terminals);

  TopForm::debugPrint(os, indent, subtreeName);

  PRINT_LIST(TermDecl, decls);
  PRINT_LIST(TermType, types);
  PRINT_LIST(PrecSpec, prec);
}

TF_terminals *TF_terminals::clone() const
{
  TF_terminals *ret = new TF_terminals(
    cloneASTList(decls),
    cloneASTList(types),
    cloneASTList(prec)
  );
  return ret;
}

DEFN_AST_DOWNCASTS(TopForm, TF_nonterm, TF_NONTERM)

TF_nonterm::~TF_nonterm()
{
  funcs.deleteAll();
  productions.deleteAll();
  subsets.deleteAll();
}

void TF_nonterm::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TF_nonterm);

  TopForm::debugPrint(os, indent, subtreeName);

  PRINT_GENERIC(name);
  PRINT_GENERIC(type);
  PRINT_LIST(SpecFunc, funcs);
  PRINT_LIST(ProdDecl, productions);
  PRINT_LIST(LocString, subsets);
}

TF_nonterm *TF_nonterm::clone() const
{
  TF_nonterm *ret = new TF_nonterm(
    name.clone(),
    type.clone(),
    cloneASTList(funcs),
    cloneASTList(productions),
    cloneASTList(subsets)
  );
  return ret;
}


// ------------------ TermDecl -------------------
// *** DO NOT EDIT ***
TermDecl::~TermDecl()
{
}

void TermDecl::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TermDecl);

  PRINT_GENERIC(code);
  PRINT_GENERIC(name);
  PRINT_GENERIC(alias);
}

TermDecl *TermDecl::clone() const
{
  TermDecl *ret = new TermDecl(
    code,
    name.clone(),
    alias.clone()
  );
  return ret;
}


// ------------------ TermType -------------------
// *** DO NOT EDIT ***
TermType::~TermType()
{
  funcs.deleteAll();
}

void TermType::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, TermType);

  PRINT_GENERIC(name);
  PRINT_GENERIC(type);
  PRINT_LIST(SpecFunc, funcs);
}

TermType *TermType::clone() const
{
  TermType *ret = new TermType(
    name.clone(),
    type.clone(),
    cloneASTList(funcs)
  );
  return ret;
}


// ------------------ PrecSpec -------------------
// *** DO NOT EDIT ***
PrecSpec::~PrecSpec()
{
  tokens.deleteAll();
}

void PrecSpec::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, PrecSpec);

  PRINT_GENERIC(kind);
  PRINT_GENERIC(prec);
  PRINT_LIST(LocString, tokens);
}

PrecSpec *PrecSpec::clone() const
{
  PrecSpec *ret = new PrecSpec(
    kind,
    prec,
    cloneASTList(tokens)
  );
  return ret;
}


// ------------------ SpecFunc -------------------
// *** DO NOT EDIT ***
SpecFunc::~SpecFunc()
{
  formals.deleteAll();
}

void SpecFunc::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, SpecFunc);

  PRINT_GENERIC(name);
  PRINT_LIST(LocString, formals);
  PRINT_GENERIC(code);
}

SpecFunc *SpecFunc::clone() const
{
  SpecFunc *ret = new SpecFunc(
    name.clone(),
    cloneASTList(formals),
    code.clone()
  );
  return ret;
}


// ------------------ ProdDecl -------------------
// *** DO NOT EDIT ***
ProdDecl::~ProdDecl()
{
  rhs.deleteAll();
}

void ProdDecl::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, ProdDecl);

  PRINT_LIST(RHSElt, rhs);
  PRINT_GENERIC(actionCode);
}

ProdDecl *ProdDecl::clone() const
{
  ProdDecl *ret = new ProdDecl(
    cloneASTList(rhs),
    actionCode.clone()
  );
  return ret;
}


// ------------------ RHSElt -------------------
// *** DO NOT EDIT ***
RHSElt::~RHSElt()
{
}

char const * const RHSElt::kindNames[RHSElt::NUM_KINDS] = {
  "RH_name",
  "RH_sm_string",
  "RH_prec",
};

void RHSElt::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
}

DEFN_AST_DOWNCASTS(RHSElt, RH_name, RH_NAME)

RH_name::~RH_name()
{
}

void RH_name::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, RH_name);

  RHSElt::debugPrint(os, indent, subtreeName);

  PRINT_GENERIC(tag);
  PRINT_GENERIC(name);
}

RH_name *RH_name::clone() const
{
  RH_name *ret = new RH_name(
    tag.clone(),
    name.clone()
  );
  return ret;
}

DEFN_AST_DOWNCASTS(RHSElt, RH_sm_string, RH_STRING)

RH_sm_string::~RH_sm_string()
{
}

void RH_sm_string::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, RH_sm_string);

  RHSElt::debugPrint(os, indent, subtreeName);

  PRINT_GENERIC(tag);
  PRINT_GENERIC(str);
}

RH_sm_string *RH_sm_string::clone() const
{
  RH_sm_string *ret = new RH_sm_string(
    tag.clone(),
    str.clone()
  );
  return ret;
}

DEFN_AST_DOWNCASTS(RHSElt, RH_prec, RH_PREC)

RH_prec::~RH_prec()
{
}

void RH_prec::debugPrint(ostream &os, int indent, char const *subtreeName) const
{
  PRINT_HEADER(subtreeName, RH_prec);

  RHSElt::debugPrint(os, indent, subtreeName);

  PRINT_GENERIC(tokName);
}

RH_prec *RH_prec::clone() const
{
  RH_prec *ret = new RH_prec(
    tokName.clone()
  );
  return ret;
}




@h=tangler('elk/elk_gramlex.yy.cpp')
@select(h)
/* A lexical scanner generated by flex */

/* Scanner skeleton version:
 * $Header$
 */

#define FLEX_SCANNER
#define YY_FLEX_MAJOR_VERSION 2
#define YY_FLEX_MINOR_VERSION 5



/* cfront 1.2 defines "c_plusplus" instead of "__cplusplus" */
#ifdef c_plusplus
#ifndef __cplusplus
#define __cplusplus
#endif
#endif


#ifdef __cplusplus

#include <stdlib.h>
#include <iostream>
using namespace std;

/* Use prototypes in function declarations. */
#define YY_USE_PROTOS

/* The "const" storage-class-modifier is valid. */
#define YY_USE_CONST

#else	/* ! __cplusplus */

#if __STDC__

#define YY_USE_PROTOS
#define YY_USE_CONST

#endif	/* __STDC__ */
#endif	/* ! __cplusplus */

#ifdef __TURBOC__
 #pragma warn -rch
 #pragma warn -use
#include <io.h>
#include <stdlib.h>
#define YY_USE_CONST
#define YY_USE_PROTOS
#endif

#ifdef YY_USE_CONST
#define yyconst const
#else
#define yyconst
#endif


#ifdef YY_USE_PROTOS
#define YY_PROTO(proto) proto
#else
#define YY_PROTO(proto) ()
#endif

/* Returned upon end-of-file. */
#define YY_NULL 0

/* Promotes a possibly negative, possibly signed char to an unsigned
 * integer for use as an array index.  If the signed char is negative,
 * we want to instead treat it as an 8-bit unsigned char, hence the
 * double cast.
 */
#define YY_SC_TO_UI(c) ((unsigned int) (unsigned char) c)

/* Enter a start condition.  This macro really ought to take a parameter,
 * but we do it the disgusting crufty way forced on us by the ()-less
 * definition of BEGIN.
 */
#define BEGIN yy_start = 1 + 2 *

/* Translate the current start state into a value that can be later handed
 * to BEGIN to return to the state.  The YYSTATE alias is for lex
 * compatibility.
 */
#define YY_START ((yy_start - 1) / 2)
#define YYSTATE YY_START

/* Action number for EOF rule of a given start state. */
#define YY_STATE_EOF(state) (YY_END_OF_BUFFER + state + 1)

/* Special action meaning "start processing a new file". */
#define YY_NEW_FILE yyrestart( yyin )

#define YY_END_OF_BUFFER_CHAR 0

/* Size of default input buffer. */
#define YY_BUF_SIZE 16384

typedef struct yy_buffer_state *YY_BUFFER_STATE;

extern int yyleng;

#define EOB_ACT_CONTINUE_SCAN 0
#define EOB_ACT_END_OF_FILE 1
#define EOB_ACT_LAST_MATCH 2

/* The funky do-while in the following #define is used to turn the definition
 * int a single C statement (which needs a semi-colon terminator).  This
 * avoids problems with code like:
 *
 * 	if ( condition_holds )
 *		yyless( 5 );
 *	else
 *		do_something_else();
 *
 * Prior to using the do-while the compiler would get upset at the
 * "else" because it interpreted the "if" statement as being all
 * done when it reached the ';' after the yyless() call.
 */

/* Return all but the first 'n' matched characters back to the input stream. */

#define yyless(n) \
	do \
		{ \
		/* Undo effects of setting up yytext. */ \
		*yy_cp = yy_hold_char; \
		YY_RESTORE_YY_MORE_OFFSET \
		yy_c_buf_p = yy_cp = yy_bp + n - YY_MORE_ADJ; \
		YY_DO_BEFORE_ACTION; /* set up yytext again */ \
		} \
	while ( 0 )

#define unput(c) yyunput( c, yytext_ptr )

/* The following is because we cannot portably get our hands on size_t
 * (without autoconf's help, which isn't available because we want
 * flex-generated scanners to compile on their own).
 */
typedef unsigned int yy_size_t;


struct yy_buffer_state
	{
	istream* yy_input_file;

	char *yy_ch_buf;		/* input buffer */
	char *yy_buf_pos;		/* current position in input buffer */

	/* Size of input buffer in bytes, not including room for EOB
	 * characters.
	 */
	yy_size_t yy_buf_size;

	/* Number of characters read into yy_ch_buf, not including EOB
	 * characters.
	 */
	int yy_n_chars;

	/* Whether we "own" the buffer - i.e., we know we created it,
	 * and can realloc() it to grow it, and should free() it to
	 * delete it.
	 */
	int yy_is_our_buffer;

	/* Whether this is an "interactive" input source; if so, and
	 * if we're using stdio for input, then we want to use getc()
	 * instead of fread(), to make sure we stop fetching input after
	 * each newline.
	 */
	int yy_is_interactive;

	/* Whether we're considered to be at the beginning of a line.
	 * If so, '^' rules will be active on the next match, otherwise
	 * not.
	 */
	int yy_at_bol;

	/* Whether to try to fill the input buffer when we reach the
	 * end of it.
	 */
	int yy_fill_buffer;

	int yy_buffer_status;
#define YY_BUFFER_NEW 0
#define YY_BUFFER_NORMAL 1
	/* When an EOF's been seen but there's still some text to process
	 * then we mark the buffer as YY_EOF_PENDING, to indicate that we
	 * shouldn't try reading from the input source any more.  We might
	 * still have a bunch of tokens to match, though, because of
	 * possible backing-up.
	 *
	 * When we actually see the EOF, we change the status to "new"
	 * (via yyrestart()), so that the user can continue scanning by
	 * just pointing yyin at a new input file.
	 */
#define YY_BUFFER_EOF_PENDING 2
	};


/* We provide macros for accessing buffer states in case in the
 * future we want to put the buffer states in a more general
 * "scanner state".
 */
#define YY_CURRENT_BUFFER yy_current_buffer



static void *yy_flex_alloc YY_PROTO(( yy_size_t ));
static void *yy_flex_realloc YY_PROTO(( void *, yy_size_t ));
static void yy_flex_free YY_PROTO(( void * ));

#define yy_new_buffer yy_create_buffer

#define yy_set_interactive(is_interactive) \
	{ \
	if ( ! yy_current_buffer ) \
		yy_current_buffer = yy_create_buffer( yyin, YY_BUF_SIZE ); \
	yy_current_buffer->yy_is_interactive = is_interactive; \
	}

#define yy_set_bol(at_bol) \
	{ \
	if ( ! yy_current_buffer ) \
		yy_current_buffer = yy_create_buffer( yyin, YY_BUF_SIZE ); \
	yy_current_buffer->yy_at_bol = at_bol; \
	}

#define YY_AT_BOL() (yy_current_buffer->yy_at_bol)


#define yywrap() 1
#define YY_SKIP_YYWRAP
typedef unsigned char YY_CHAR;
#define yytext_ptr yytext
#define YY_INTERACTIVE

#include "sm_flexlexer.h"
int yyFlexLexer::yylex()
	{
	LexerError( "yyFlexLexer::yylex invoked but %option yyclass used" );
	return 0;
	}

#define YY_DECL int GrammarLexer::yylex()


/* Done after the current pattern has been matched and before the
 * corresponding action - sets up yytext.
 */
#define YY_DO_BEFORE_ACTION \
	yytext_ptr = yy_bp; \
	yyleng = (int) (yy_cp - yy_bp); \
	yy_hold_char = *yy_cp; \
	*yy_cp = '\0'; \
	yy_c_buf_p = yy_cp;

#define YY_NUM_RULES 40
#define YY_END_OF_BUFFER 41
static yyconst short int yy_accept[159] =
    {   0,
        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
        0,    0,    0,    0,    0,    0,   41,   39,    2,    1,
       39,   24,   10,   11,   39,   39,   37,    9,   21,   36,
       17,   36,   36,   36,   36,   36,   36,   36,   36,   36,
       36,   20,    8,    5,    6,    5,   33,   33,   33,   34,
       35,   27,   28,   29,   19,   23,    2,    0,   38,   18,
        3,    0,   37,   36,   36,   36,   36,   36,   36,   36,
       36,   36,   36,   36,   36,   36,    4,    0,    0,    0,
        0,   34,   27,    0,    7,   36,   36,   25,   36,   36,
       36,   36,   36,   36,   36,   36,   36,    0,   36,   36,

       36,   36,   36,   36,   36,   36,   36,   36,   36,    0,
       36,   36,   36,   36,   36,   36,   36,   36,   36,   22,
       36,    0,   32,   36,   15,   36,   36,   36,   14,   36,
       36,   36,   36,   36,   36,   31,   36,   16,   36,   36,
       36,   36,   36,   36,   26,   36,   36,   36,   12,   36,
       36,   13,   36,   36,   36,   36,   30,    0
    } ;

static yyconst int yy_ec[256] =
    {   0,
        1,    1,    1,    1,    1,    1,    1,    1,    2,    3,
        2,    2,    2,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    2,    1,    4,    1,    1,    1,    1,    1,    5,
        6,    7,    1,    8,    9,    1,   10,   11,   11,   11,
       11,   11,   11,   11,   11,   11,   11,   12,   13,    1,
        1,   14,    1,    1,   15,   15,   15,   15,   15,   15,
       15,   15,   15,   15,   15,   15,   15,   15,   15,   15,
       15,   15,   15,   15,   15,   15,   15,   15,   15,   15,
       16,   17,   18,    1,   19,    1,   20,   21,   22,   23,

       24,   25,   15,   15,   26,   15,   27,   28,   29,   30,
       31,   32,   15,   33,   34,   35,   36,   37,   15,   38,
       15,   15,   39,    1,   40,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,

        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1
    } ;

static yyconst int yy_meta[41] =
    {   0,
        1,    1,    2,    3,    1,    4,    1,    1,    1,    1,
        5,    1,    1,    1,    5,    1,    6,    4,    5,    5,
        5,    5,    5,    5,    5,    5,    5,    5,    5,    5,
        5,    5,    5,    5,    5,    5,    5,    5,    1,    4
    } ;

static yyconst short int yy_base[169] =
    {   0,
        0,    0,   38,   39,   42,   46,  224,  223,   46,   47,
      186,  185,   30,   41,   50,   53,  223,  228,  220,  228,
      217,  228,  228,  228,  206,   49,  208,  228,  228,    0,
      228,  187,  179,  180,   31,  184,  182,  180,  176,   43,
      187,  228,  228,  228,  228,  200,  228,   66,   68,    0,
      228,    0,  228,  228,  228,  228,  207,  204,  228,  228,
      228,  204,  195,    0,  175,  172,  173,  170,  179,  170,
      164,  174,  176,  163,  168,  161,  228,   71,   73,   77,
        0,    0,    0,  190,  228,  157,  167,    0,  162,  161,
      153,  161,  164,  151,  155,  159,  161,  177,  156,  157,

      159,  141,  152,  144,  150,  149,  146,  141,  150,   76,
      131,  133,  130,  143,  132,  134,  140,  127,  131,    0,
      125,   82,  228,  124,    0,  134,  133,  127,    0,  131,
      120,  133,  126,  132,  117,    0,  119,    0,  120,  118,
      124,  124,  120,  107,    0,  103,  109,   99,    0,   98,
       56,    0,   56,   59,   49,   33,    0,  228,   92,   98,
      104,  110,  116,   52,  121,  127,  133,  139
    } ;

static yyconst short int yy_def[169] =
    {   0,
      158,    1,  159,  159,  160,  160,  161,  161,  162,  162,
        1,    1,    1,    1,    1,    1,  158,  158,  158,  158,
      163,  158,  158,  158,  158,  158,  158,  158,  158,  164,
      158,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  158,  158,  158,  158,  158,  158,  158,  158,  165,
      158,  166,  158,  158,  158,  158,  158,  163,  158,  158,
      158,  167,  158,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  158,  158,  158,  158,
      168,  165,  166,  167,  158,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,  168,  164,  164,

      164,  164,  164,  164,  164,  164,  164,  164,  164,  158,
      164,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  158,  158,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,    0,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158
    } ;

static yyconst short int yy_nxt[269] =
    {   0,
       18,   19,   20,   21,   22,   23,   18,   24,   25,   26,
       27,   28,   29,   18,   30,   31,   18,   18,   30,   30,
       30,   32,   30,   33,   34,   35,   30,   30,   30,   36,
       37,   38,   30,   39,   40,   30,   41,   30,   42,   43,
       45,   45,   18,   48,   46,   46,   49,   48,   53,   53,
       49,   54,   54,   18,   56,   61,   64,   56,   62,   68,
       69,  145,   18,   54,   54,   18,   74,   78,   55,   80,
       79,   81,   78,   75,   80,   79,   81,  122,   80,   55,
       81,  123,  157,  122,  156,   54,   54,  123,   18,  155,
      154,   18,   44,   44,   44,   44,   44,   44,   47,   47,

       47,   47,   47,   47,   50,   50,   50,   50,   50,   50,
       52,   52,   52,   52,   52,   52,   58,  153,   58,   58,
       58,   82,  152,   82,   82,   82,   82,   83,  151,   83,
      150,   83,   83,   84,   84,   84,   84,   84,   84,   98,
      149,  148,   98,   98,  147,  146,  145,  144,  143,  142,
      141,  140,  139,  138,  137,  120,  136,  135,  134,  133,
      132,  131,  130,  129,  128,  127,  126,  125,  124,  121,
      120,  119,  118,  117,  116,  115,  114,  113,  112,  111,
      110,  109,  108,  107,  106,  105,  104,  103,  102,  101,
      100,   99,   85,   97,   96,   95,   94,   93,   92,   91,

       90,   89,   88,   87,   86,   63,   85,   59,   57,   77,
       76,   73,   72,   71,   70,   67,   66,   65,   63,   60,
       59,   57,  158,   55,   55,   51,   51,   17,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158
    } ;

static yyconst short int yy_chk[269] =
    {   0,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        3,    4,   13,    5,    3,    4,    5,    6,    9,   10,
        6,    9,   10,   14,   15,   26,  164,   16,   26,   35,
       35,  156,   15,    9,   10,   16,   40,   48,   13,   49,
       48,   49,   78,   40,   79,   78,   79,  110,   80,   14,
       80,  110,  155,  122,  154,    9,   10,  122,   15,  153,
      151,   16,  159,  159,  159,  159,  159,  159,  160,  160,

      160,  160,  160,  160,  161,  161,  161,  161,  161,  161,
      162,  162,  162,  162,  162,  162,  163,  150,  163,  163,
      163,  165,  148,  165,  165,  165,  165,  166,  147,  166,
      146,  166,  166,  167,  167,  167,  167,  167,  167,  168,
      144,  143,  168,  168,  142,  141,  140,  139,  137,  135,
      134,  133,  132,  131,  130,  128,  127,  126,  124,  121,
      119,  118,  117,  116,  115,  114,  113,  112,  111,  109,
      108,  107,  106,  105,  104,  103,  102,  101,  100,   99,
       98,   97,   96,   95,   94,   93,   92,   91,   90,   89,
       87,   86,   84,   76,   75,   74,   73,   72,   71,   70,

       69,   68,   67,   66,   65,   63,   62,   58,   57,   46,
       41,   39,   38,   37,   36,   34,   33,   32,   27,   25,
       21,   19,   17,   12,   11,    8,    7,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158
    } ;

/* The intent behind this definition is that it'll catch
 * any uses of REJECT which flex missed.
 */
#define REJECT reject_used_but_not_detected
#define yymore() yymore_used_but_not_detected
#define YY_MORE_ADJ 0
#define YY_RESTORE_YY_MORE_OFFSET
#line 1 "gramlex.lex"
#define INITIAL 0
/* grammar.lex
 * lexical analyzer for my grammar input format
 *
 * The variety of syntaxes for embedded literal code cause this lexer
 * to have some of the context sensitivity usually associated with a
 * parser.  This context doesn't nest arbitrarily deeply, so the
 * language recognized is still regular, but clearly there's some
 * design tension.
 */
/* ----------------- C definitions -------------------- */
#line 13 "gramlex.lex"

// pull in my declaration of the lexer class -- this defines
// the additional lexer state, some of which is used in the
// action rules below (this is in the ../ast/ directory now)
#include "ast_gramlex.h"

// pull in the bison-generated token codes
#include "elk_grampar.codes.h"

#include <string.h>     // strchr, strrchr

// for maintaining column count
#define TOKEN_START  tokenStartLoc = fileState.loc /* user ; */
#define UPD_COL      \
  fileState.loc = sourceLocManager->advCol(fileState.loc, yyleng)  /* user ; */
#define TOK_UPD_COL  TOKEN_START; UPD_COL  /* user ; */

/* -------------------- flex options ------------------ */
/* no wrapping is needed; setting this means we don't have to link with libfl.a */
/* don't use the default-echo rules */
/* generate a c++ lexer */
/* and I will define the class */
/* ------------------- definitions -------------------- */
/* any character, including newline */
/* any character except newline */
/* starting character in a name */
/* starting character in a numeric literal */
/* double-quote */
/* character that can appear in a quoted string */
/* (I currently don't have any backslash codes, but I want to
 * leave open that possibility, so for now backslashes are illegal) */
/* horizontal whitespace */
/* --------------- start conditions ------------------- */
/* eating a comment delimited by slash-star and star-slash; note
 * that we remember our current state when entering C_COMMENT,
 * and restore it on exit */
#define C_COMMENT 1

/* looking for the file name in an "include" directive */
#define INCLUDE 2

/* recovering from an error by skipping to the next newline */
#define EAT_TO_NEWLINE 3

/* gathering literal embedded code; the delimiter is specified
 * in the 'embedFinish' variable */
#define LITCODE 4

/* tokenizing the right-hand side of a production; this one is not
 * exclusive because tokenization is virtually the same in RHS
 * mode as in INITIAL mode */
#define RHS 5

/* tokenizing parameter list of a function, leading into the
 * embedded code that is its body */
#define FUN 6

/* looking for the start of a type that follows "token" or "nonterm",
 * or the TOK_NAME meaning the type has been omitted */
#define OPTIONAL_TYPE 7

/* ---------------------- rules ----------------------- */
#line 514 "lex.yy.cc"

/* Macros after this point can all be overridden by user definitions in
 * section 1.
 */

#ifndef YY_SKIP_YYWRAP
#ifdef __cplusplus
extern "C" int yywrap YY_PROTO(( void ));
#else
extern int yywrap YY_PROTO(( void ));
#endif
#endif


#ifndef yytext_ptr
static void yy_flex_strncpy YY_PROTO(( char *, yyconst char *, int ));
#endif

#ifdef YY_NEED_STRLEN
static int yy_flex_strlen YY_PROTO(( yyconst char * ));
#endif

#ifndef YY_NO_INPUT
#endif

#if YY_STACK_USED
static int yy_start_stack_ptr = 0;
static int yy_start_stack_depth = 0;
static int *yy_start_stack = 0;
#ifndef YY_NO_PUSH_STATE
static void yy_push_state YY_PROTO(( int new_state ));
#endif
#ifndef YY_NO_POP_STATE
static void yy_pop_state YY_PROTO(( void ));
#endif
#ifndef YY_NO_TOP_STATE
static int yy_top_state YY_PROTO(( void ));
#endif

#else
#define YY_NO_PUSH_STATE 1
#define YY_NO_POP_STATE 1
#define YY_NO_TOP_STATE 1
#endif

#ifdef YY_MALLOC_DECL
YY_MALLOC_DECL
#else
#if __STDC__
#ifndef __cplusplus
#include <stdlib.h>
#endif
#else
/* Just try to get by without declaring the routines.  This will fail
 * miserably on non-ANSI systems for which sizeof(size_t) != sizeof(int)
 * or sizeof(void*) != sizeof(int).
 */
#endif
#endif

/* Amount of stuff to slurp up with each read. */
#ifndef YY_READ_BUF_SIZE
#define YY_READ_BUF_SIZE 8192
#endif

/* Copy whatever the last rule matched to the standard output. */

#ifndef ECHO
#define ECHO LexerOutput( yytext, yyleng )
#endif

/* Gets input and stuffs it into "buf".  number of characters read, or YY_NULL,
 * is returned in "result".
 */
#ifndef YY_INPUT
#define YY_INPUT(buf,result,max_size) \
	if ( (result = LexerInput( (char *) buf, max_size )) < 0 ) \
		YY_FATAL_ERROR( "input in flex scanner failed" );
#endif

/* No semi-colon after return; correct usage is to write "yyterminate();" -
 * we don't want an extra ';' after the "return" because that will cause
 * some compilers to complain about unreachable statements.
 */
#ifndef yyterminate
#define yyterminate() return YY_NULL
#endif

/* Number of entries by which start-condition stack grows. */
#ifndef YY_START_STACK_INCR
#define YY_START_STACK_INCR 25
#endif

/* Report a fatal error. */
#ifndef YY_FATAL_ERROR
#define YY_FATAL_ERROR(msg) LexerError( msg )
#endif

/* Default declaration of generated scanner - a define so the user can
 * easily add parameters.
 */
#ifndef YY_DECL
#define YY_DECL int yyFlexLexer::yylex()
#endif

/* Code executed at the beginning of each rule, after yytext and yyleng
 * have been set up.
 */
#ifndef YY_USER_ACTION
#define YY_USER_ACTION
#endif

/* Code executed at the end of each rule. */
#ifndef YY_BREAK
#define YY_BREAK break;
#endif

#define YY_RULE_SETUP \
	YY_USER_ACTION

YY_DECL
	{
	register yy_state_type yy_current_state;
	register char *yy_cp = NULL, *yy_bp = NULL;
	register int yy_act;

#line 102 "gramlex.lex"


  /* -------- whitespace ------ */
#line 645 "lex.yy.cc"

	if ( yy_init )
		{
		yy_init = 0;

#ifdef YY_USER_INIT
		YY_USER_INIT;
#endif

		if ( ! yy_start )
			yy_start = 1;	/* first start state */

		if ( ! yyin )
			yyin = &cin;

		if ( ! yyout )
			yyout = &cout;

		if ( ! yy_current_buffer )
			yy_current_buffer =
				yy_create_buffer( yyin, YY_BUF_SIZE );

		yy_load_buffer_state();
		}

	while ( 1 )		/* loops until end-of-file is reached */
		{
		yy_cp = yy_c_buf_p;

		/* Support of yytext. */
		*yy_cp = yy_hold_char;

		/* yy_bp points to the position in yy_ch_buf of the start of
		 * the current run.
		 */
		yy_bp = yy_cp;

		yy_current_state = yy_start;
yy_match:
		do
			{
			register YY_CHAR yy_c = yy_ec[YY_SC_TO_UI(*yy_cp)];
			if ( yy_accept[yy_current_state] )
				{
				yy_last_accepting_state = yy_current_state;
				yy_last_accepting_cpos = yy_cp;
				}
			while ( yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state )
				{
				yy_current_state = (int) yy_def[yy_current_state];
				if ( yy_current_state >= 159 )
					yy_c = yy_meta[(unsigned int) yy_c];
				}
			yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
			++yy_cp;
			}
		while ( yy_base[yy_current_state] != 228 );

yy_find_action:
		yy_act = yy_accept[yy_current_state];
		if ( yy_act == 0 )
			{ /* have to back up */
			yy_cp = yy_last_accepting_cpos;
			yy_current_state = yy_last_accepting_state;
			yy_act = yy_accept[yy_current_state];
			}

		YY_DO_BEFORE_ACTION;


do_action:	/* This label is used only to access EOF actions. */


		switch ( yy_act )
	{ /* beginning of action switch */
			case 0: /* must back up */
			/* undo the effects of YY_DO_BEFORE_ACTION */
			*yy_cp = yy_hold_char;
			yy_cp = yy_last_accepting_cpos;
			yy_current_state = yy_last_accepting_state;
			goto yy_find_action;

case 1:
YY_RULE_SETUP
#line 105 "gramlex.lex"
{
  newLine();
}
	YY_BREAK
case 2:
YY_RULE_SETUP
#line 109 "gramlex.lex"
{
  UPD_COL;
}
	YY_BREAK
/* -------- comments -------- */
case 3:
YY_RULE_SETUP
#line 114 "gramlex.lex"
{
  /* C-style comments */
  TOKEN_START;
  UPD_COL;
  prevState = YY_START;
  BEGIN(C_COMMENT);
}
	YY_BREAK

case 4:
YY_RULE_SETUP
#line 123 "gramlex.lex"
{
    /* end of comment */
    UPD_COL;
    BEGIN(prevState);
  }
	YY_BREAK
case 5:
YY_RULE_SETUP
#line 129 "gramlex.lex"
{
    /* anything but slash-star or newline -- eat it */
    UPD_COL;
  }
	YY_BREAK
case 6:
YY_RULE_SETUP
#line 134 "gramlex.lex"
{
    newLine();
  }
	YY_BREAK
case YY_STATE_EOF(C_COMMENT):
#line 138 "gramlex.lex"
{
    UPD_COL;      // <<EOF>> yyleng is 1!
    errorUnterminatedComment();
    return TOK_EOF;
  }
	YY_BREAK

case 7:
YY_RULE_SETUP
#line 146 "gramlex.lex"
{
  /* C++-style comment -- eat it */
  TOKEN_START;
  advCol(yyleng-1);   // don't count newline
  newLine();          // count it here
}
	YY_BREAK
/* -------- punctuators, operators, keywords --------- */
case 8:
YY_RULE_SETUP
#line 155 "gramlex.lex"
TOK_UPD_COL;  return TOK_RBRACE;
	YY_BREAK
case 9:
YY_RULE_SETUP
#line 156 "gramlex.lex"
TOK_UPD_COL;  return TOK_COLON;
	YY_BREAK
case 10:
YY_RULE_SETUP
#line 157 "gramlex.lex"
TOK_UPD_COL;  return TOK_RPAREN;
	YY_BREAK
case 11:
YY_RULE_SETUP
#line 158 "gramlex.lex"
TOK_UPD_COL;  return TOK_COMMA;
	YY_BREAK
case 12:
YY_RULE_SETUP
#line 160 "gramlex.lex"
TOK_UPD_COL;  return TOK_TERMINALS;
	YY_BREAK
case 13:
YY_RULE_SETUP
#line 161 "gramlex.lex"
TOK_UPD_COL;  return TOK_PRECEDENCE;
	YY_BREAK
case 14:
YY_RULE_SETUP
#line 162 "gramlex.lex"
TOK_UPD_COL;  return TOK_OPTION;
	YY_BREAK
case 15:
YY_RULE_SETUP
#line 163 "gramlex.lex"
TOK_UPD_COL;  return TOK_EXPECT;
	YY_BREAK
case 16:
YY_RULE_SETUP
#line 164 "gramlex.lex"
TOK_UPD_COL;  return TOK_SUBSETS;
	YY_BREAK
/* ----------- sequences that begin literal code ------------ */
/* for the time being, a "[" will always start an embedded sequence;
   * eventually, I'll remove this in favor of the brace- and paren-
   * delimited embedded sequences */
case 17:
YY_RULE_SETUP
#line 171 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(LITCODE);
  beginEmbed(']', TOK_LIT_CODE);
}
	YY_BREAK
/* the "->" operator moves us into RHS mode, which is special because
   * in this mode any "{" is interpreted as the beginning of an embedded
   * section of literal code */
case 18:
YY_RULE_SETUP
#line 180 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(RHS);
  return TOK_ARROW;
}
	YY_BREAK
/* "{" in a RHS begins embedded */
case 19:
YY_RULE_SETUP
#line 187 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(LITCODE);
  beginEmbed('}', TOK_LIT_CODE);
}
	YY_BREAK
/* otherwise it's just a "{" */
case 20:
YY_RULE_SETUP
#line 194 "gramlex.lex"
{
  TOK_UPD_COL;
  return TOK_LBRACE;
}
	YY_BREAK
/* since right-hand-sides can end with either embedded code or a simple
   * ";", the semicolon gets out of RHS mode */
case 21:
YY_RULE_SETUP
#line 201 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(INITIAL);     // if in RHS, reset to INITIAL
  return TOK_SEMICOLON;
}
	YY_BREAK
/* "token" and "nonterm" are always followed by an optional type,
   * and then a TOK_NAME.  So, until we see a TOK_NAME, "(" will mean
   * the start of an embedded sequence. */
case 22:
YY_RULE_SETUP
#line 210 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(OPTIONAL_TYPE);
  return yytext[0]=='t'? TOK_TOKEN : TOK_NONTERM;
}
	YY_BREAK
/* so now this begins embedded */
case 23:
YY_RULE_SETUP
#line 217 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(LITCODE);
  beginEmbed(')', TOK_LIT_CODE);
}
	YY_BREAK
/* otherwise it's just itself */
case 24:
YY_RULE_SETUP
#line 224 "gramlex.lex"
{
  TOK_UPD_COL;
  return TOK_LPAREN;
}
	YY_BREAK
/* function beginning */
case 25:
YY_RULE_SETUP
#line 230 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(FUN);            // treat "{" as beginning literal code
  return TOK_FUN;
}
	YY_BREAK
/* verbatim beginning */
case 26:
YY_RULE_SETUP
#line 237 "gramlex.lex"
{
  TOK_UPD_COL;
  BEGIN(FUN);            // close enough
  return yytext[0]=='v'? TOK_VERBATIM : TOK_IMPL_VERBATIM;
}
	YY_BREAK
/* --------- embedded literal code --------- */
/* no TOKEN_START here; we'll use the tokenStartLoc that
   * was computed in the opening punctuation */

case 27:
YY_RULE_SETUP
#line 248 "gramlex.lex"
{
    UPD_COL;
    embedded->handle(yytext, yyleng, embedFinish);
  }
	YY_BREAK
case 28:
YY_RULE_SETUP
#line 253 "gramlex.lex"
{
    newLine();
    embedded->handle(yytext, yyleng, embedFinish);
  }
	YY_BREAK
case 29:
YY_RULE_SETUP
#line 258 "gramlex.lex"
{
    UPD_COL;
    if (embedded->zeroNesting()) {
      // done
      BEGIN(INITIAL);

      // check for balanced delimiter
      if (embedFinish != yytext[0]) {
        err("unbalanced literal code delimiter");
      }

      // don't add "return" or ";"
      embedded->exprOnly = false;

      // can't extract anything
      embedded->isDeclaration = false;

      // caller can get text from embedded->text
      return embedMode;
    }
    else {
      // delimeter paired within the embedded code, mostly ignore it
      embedded->handle(yytext, yyleng, embedFinish);
    }
  }
	YY_BREAK
case YY_STATE_EOF(LITCODE):
#line 284 "gramlex.lex"
{
    err(sm_stringc << "hit end of file while looking for final `"
                << embedFinish << "'");
    yyterminate();
  }
	YY_BREAK

/* embedded *type* description */
case 30:
YY_RULE_SETUP
#line 293 "gramlex.lex"
{
  /* caller will get text from yytext and yyleng */
  TOK_UPD_COL;

  /* drop into literal-code processing */
  BEGIN(LITCODE);

  /* I reset the initial nesting to -1 so that the '{' at the
   * beginning of the class body sets nesting to 0, thus when
   * I see the final '}' I'll see that at level 0 and stop */
  beginEmbed('}', TOK_LIT_CODE, -1);

  return TOK_CONTEXT_CLASS;
}
	YY_BREAK
/* ---------- includes ----------- */
case 31:
YY_RULE_SETUP
#line 310 "gramlex.lex"
{
  TOK_UPD_COL;    /* hence no TOKEN_START in INCLUDE area */
  BEGIN(INCLUDE);
}
	YY_BREAK

case 32:
YY_RULE_SETUP
#line 316 "gramlex.lex"
{
    /* e.g.: ("filename") */
    /* file name to include */
    UPD_COL;

    /* find quotes */
    char *leftq = strchr(yytext, '"');
    char *rightq = strchr(leftq+1, '"');
    xassert(leftq && rightq);

    /* extract filename string */
    includeFileName = addString(leftq+1, rightq-leftq-1);

    /* go back to normal processing */
    BEGIN(INITIAL);
    return TOK_INCLUDE;
  }
	YY_BREAK
case 33:
YY_RULE_SETUP
#line 334 "gramlex.lex"
{
    /* anything else: malformed */
    UPD_COL;
    errorMalformedInclude();

    /* rudimentary error recovery.. */
    BEGIN(EAT_TO_NEWLINE);
  }
	YY_BREAK


case 34:
YY_RULE_SETUP
#line 345 "gramlex.lex"
{
    UPD_COL;
    /* not newline, eat it */
  }
	YY_BREAK
case 35:
YY_RULE_SETUP
#line 350 "gramlex.lex"
{
    /* get out of here */
    newLine();
    BEGIN(INITIAL);
  }
	YY_BREAK

/* -------- name literal --------- */
case 36:
YY_RULE_SETUP
#line 358 "gramlex.lex"
{
  /* get text from yytext and yyleng */
  TOK_UPD_COL;
  if (YY_START == OPTIONAL_TYPE) {
    BEGIN(INITIAL);      // bail out of OPTIONAL_TYPE mode
  }
  return TOK_NAME;
}
	YY_BREAK
/* -------- numeric literal ------ */
case 37:
YY_RULE_SETUP
#line 368 "gramlex.lex"
{
  TOK_UPD_COL;
  integerLiteral = strtoul(yytext, NULL, 10 /*radix*/);
  return TOK_INTEGER;
}
	YY_BREAK
/* ----------- string literal ----- */
case 38:
YY_RULE_SETUP
#line 375 "gramlex.lex"
{
  TOK_UPD_COL;
  sm_stringLiteral = addString(yytext+1, yyleng-2);        // strip quotes
  return TOK_STRING;
}
	YY_BREAK
/* --------- illegal ------------- */
case 39:
YY_RULE_SETUP
#line 382 "gramlex.lex"
{
  TOK_UPD_COL;
  errorIllegalCharacter(yytext[0]);
}
	YY_BREAK
case 40:
YY_RULE_SETUP
#line 388 "gramlex.lex"
YY_FATAL_ERROR( "flex scanner jammed" );
	YY_BREAK
#line 1137 "lex.yy.cc"
case YY_STATE_EOF(INITIAL):
case YY_STATE_EOF(INCLUDE):
case YY_STATE_EOF(EAT_TO_NEWLINE):
case YY_STATE_EOF(RHS):
case YY_STATE_EOF(FUN):
case YY_STATE_EOF(OPTIONAL_TYPE):
	yyterminate();

	case YY_END_OF_BUFFER:
		{
		/* Amount of text matched not including the EOB char. */
		int yy_amount_of_matched_text = (int) (yy_cp - yytext_ptr) - 1;

		/* Undo the effects of YY_DO_BEFORE_ACTION. */
		*yy_cp = yy_hold_char;
		YY_RESTORE_YY_MORE_OFFSET

		if ( yy_current_buffer->yy_buffer_status == YY_BUFFER_NEW )
			{
			/* We're scanning a new file or input source.  It's
			 * possible that this happened because the user
			 * just pointed yyin at a new source and called
			 * yylex().  If so, then we have to assure
			 * consistency between yy_current_buffer and our
			 * globals.  Here is the right place to do so, because
			 * this is the first action (other than possibly a
			 * back-up) that will match for the new input source.
			 */
			yy_n_chars = yy_current_buffer->yy_n_chars;
			yy_current_buffer->yy_input_file = yyin;
			yy_current_buffer->yy_buffer_status = YY_BUFFER_NORMAL;
			}

		/* Note that here we test for yy_c_buf_p "<=" to the position
		 * of the first EOB in the buffer, since yy_c_buf_p will
		 * already have been incremented past the NUL character
		 * (since all states make transitions on EOB to the
		 * end-of-buffer state).  Contrast this with the test
		 * in input().
		 */
		if ( yy_c_buf_p <= &yy_current_buffer->yy_ch_buf[yy_n_chars] )
			{ /* This was really a NUL. */
			yy_state_type yy_next_state;

			yy_c_buf_p = yytext_ptr + yy_amount_of_matched_text;

			yy_current_state = yy_get_previous_state();

			/* Okay, we're now positioned to make the NUL
			 * transition.  We couldn't have
			 * yy_get_previous_state() go ahead and do it
			 * for us because it doesn't know how to deal
			 * with the possibility of jamming (and we don't
			 * want to build jamming into it because then it
			 * will run more slowly).
			 */

			yy_next_state = yy_try_NUL_trans( yy_current_state );

			yy_bp = yytext_ptr + YY_MORE_ADJ;

			if ( yy_next_state )
				{
				/* Consume the NUL. */
				yy_cp = ++yy_c_buf_p;
				yy_current_state = yy_next_state;
				goto yy_match;
				}

			else
				{
				yy_cp = yy_c_buf_p;
				goto yy_find_action;
				}
			}

		else switch ( yy_get_next_buffer() )
			{
			case EOB_ACT_END_OF_FILE:
				{
				yy_did_buffer_switch_on_eof = 0;

				if ( yywrap() )
					{
					/* Note: because we've taken care in
					 * yy_get_next_buffer() to have set up
					 * yytext, we can now set up
					 * yy_c_buf_p so that if some total
					 * hoser (like flex itself) wants to
					 * call the scanner after we return the
					 * YY_NULL, it'll still work - another
					 * YY_NULL will get returned.
					 */
					yy_c_buf_p = yytext_ptr + YY_MORE_ADJ;

					yy_act = YY_STATE_EOF(YY_START);
					goto do_action;
					}

				else
					{
					if ( ! yy_did_buffer_switch_on_eof )
						YY_NEW_FILE;
					}
				break;
				}

			case EOB_ACT_CONTINUE_SCAN:
				yy_c_buf_p =
					yytext_ptr + yy_amount_of_matched_text;

				yy_current_state = yy_get_previous_state();

				yy_cp = yy_c_buf_p;
				yy_bp = yytext_ptr + YY_MORE_ADJ;
				goto yy_match;

			case EOB_ACT_LAST_MATCH:
				yy_c_buf_p =
				&yy_current_buffer->yy_ch_buf[yy_n_chars];

				yy_current_state = yy_get_previous_state();

				yy_cp = yy_c_buf_p;
				yy_bp = yytext_ptr + YY_MORE_ADJ;
				goto yy_find_action;
			}
		break;
		}

	default:
		YY_FATAL_ERROR(
			"fatal flex scanner internal error--no action found" );
	} /* end of action switch */
		} /* end of scanning one token */
	} /* end of yylex */

yyFlexLexer::yyFlexLexer( istream* arg_yyin, ostream* arg_yyout )
	{
	yyin = arg_yyin;
	yyout = arg_yyout;
	yy_c_buf_p = 0;
	yy_init = 1;
	yy_start = 0;
	yy_flex_debug = 0;
	yylineno = 1;	// this will only get updated if %option yylineno

	yy_did_buffer_switch_on_eof = 0;

	yy_looking_for_trail_begin = 0;
	yy_more_flag = 0;
	yy_more_len = 0;
	yy_more_offset = yy_prev_more_offset = 0;

	yy_start_stack_ptr = yy_start_stack_depth = 0;
	yy_start_stack = 0;

	yy_current_buffer = 0;

#ifdef YY_USES_REJECT
	yy_state_buf = new yy_state_type[YY_BUF_SIZE + 2];
#else
	yy_state_buf = 0;
#endif
	}

yyFlexLexer::~yyFlexLexer()
	{
	delete yy_state_buf;
	yy_delete_buffer( yy_current_buffer );
	}

void yyFlexLexer::switch_streams( istream* new_in, ostream* new_out )
	{
	if ( new_in )
		{
		yy_delete_buffer( yy_current_buffer );
		yy_switch_to_buffer( yy_create_buffer( new_in, YY_BUF_SIZE ) );
		}

	if ( new_out )
		yyout = new_out;
	}

#ifdef YY_INTERACTIVE
int yyFlexLexer::LexerInput( char* buf, int /* max_size */ )
#else
int yyFlexLexer::LexerInput( char* buf, int max_size )
#endif
	{
	if ( yyin->eof() || yyin->fail() )
		return 0;

#ifdef YY_INTERACTIVE
	yyin->get( buf[0] );

	if ( yyin->eof() )
		return 0;

	if ( yyin->bad() )
		return -1;

	return 1;

#else
	(void) yyin->read( buf, max_size );

	if ( yyin->bad() )
		return -1;
	else
		return yyin->gcount();
#endif
	}

void yyFlexLexer::LexerOutput( const char* buf, int size )
	{
	(void) yyout->write( buf, size );
	}

/* yy_get_next_buffer - try to read in a new buffer
 *
 * Returns a code representing an action:
 *	EOB_ACT_LAST_MATCH -
 *	EOB_ACT_CONTINUE_SCAN - continue scanning from current position
 *	EOB_ACT_END_OF_FILE - end of file
 */

int yyFlexLexer::yy_get_next_buffer()
	{
	register char *dest = yy_current_buffer->yy_ch_buf;
	register char *source = yytext_ptr;
	register int number_to_move, i;
	int ret_val;

	if ( yy_c_buf_p > &yy_current_buffer->yy_ch_buf[yy_n_chars + 1] )
		YY_FATAL_ERROR(
		"fatal flex scanner internal error--end of buffer missed" );

	if ( yy_current_buffer->yy_fill_buffer == 0 )
		{ /* Don't try to fill the buffer, so this is an EOF. */
		if ( yy_c_buf_p - yytext_ptr - YY_MORE_ADJ == 1 )
			{
			/* We matched a single character, the EOB, so
			 * treat this as a final EOF.
			 */
			return EOB_ACT_END_OF_FILE;
			}

		else
			{
			/* We matched some text prior to the EOB, first
			 * process it.
			 */
			return EOB_ACT_LAST_MATCH;
			}
		}

	/* Try to read more data. */

	/* First move last chars to start of buffer. */
	number_to_move = (int) (yy_c_buf_p - yytext_ptr) - 1;

	for ( i = 0; i < number_to_move; ++i )
		*(dest++) = *(source++);

	if ( yy_current_buffer->yy_buffer_status == YY_BUFFER_EOF_PENDING )
		/* don't do the read, it's not guaranteed to return an EOF,
		 * just force an EOF
		 */
		yy_current_buffer->yy_n_chars = yy_n_chars = 0;

	else
		{
		int num_to_read =
			yy_current_buffer->yy_buf_size - number_to_move - 1;

		while ( num_to_read <= 0 )
			{ /* Not enough room in the buffer - grow it. */
#ifdef YY_USES_REJECT
			YY_FATAL_ERROR(
"input buffer overflow, can't enlarge buffer because scanner uses REJECT" );
#else

			/* just a shorter name for the current buffer */
			YY_BUFFER_STATE b = yy_current_buffer;

			int yy_c_buf_p_offset =
				(int) (yy_c_buf_p - b->yy_ch_buf);

			if ( b->yy_is_our_buffer )
				{
				int new_size = b->yy_buf_size * 2;

				if ( new_size <= 0 )
					b->yy_buf_size += b->yy_buf_size / 8;
				else
					b->yy_buf_size *= 2;

				b->yy_ch_buf = (char *)
					/* Include room in for 2 EOB chars. */
					yy_flex_realloc( (void *) b->yy_ch_buf,
							 b->yy_buf_size + 2 );
				}
			else
				/* Can't grow it, we don't own it. */
				b->yy_ch_buf = 0;

			if ( ! b->yy_ch_buf )
				YY_FATAL_ERROR(
				"fatal error - scanner input buffer overflow" );

			yy_c_buf_p = &b->yy_ch_buf[yy_c_buf_p_offset];

			num_to_read = yy_current_buffer->yy_buf_size -
						number_to_move - 1;
#endif
			}

		if ( num_to_read > YY_READ_BUF_SIZE )
			num_to_read = YY_READ_BUF_SIZE;

		/* Read in more data. */
		YY_INPUT( (&yy_current_buffer->yy_ch_buf[number_to_move]),
			yy_n_chars, num_to_read );

		yy_current_buffer->yy_n_chars = yy_n_chars;
		}

	if ( yy_n_chars == 0 )
		{
		if ( number_to_move == YY_MORE_ADJ )
			{
			ret_val = EOB_ACT_END_OF_FILE;
			yyrestart( yyin );
			}

		else
			{
			ret_val = EOB_ACT_LAST_MATCH;
			yy_current_buffer->yy_buffer_status =
				YY_BUFFER_EOF_PENDING;
			}
		}

	else
		ret_val = EOB_ACT_CONTINUE_SCAN;

	yy_n_chars += number_to_move;
	yy_current_buffer->yy_ch_buf[yy_n_chars] = YY_END_OF_BUFFER_CHAR;
	yy_current_buffer->yy_ch_buf[yy_n_chars + 1] = YY_END_OF_BUFFER_CHAR;

	yytext_ptr = &yy_current_buffer->yy_ch_buf[0];

	return ret_val;
	}


/* yy_get_previous_state - get the state just before the EOB char was reached */

yy_state_type yyFlexLexer::yy_get_previous_state()
	{
	register yy_state_type yy_current_state;
	register char *yy_cp;

	yy_current_state = yy_start;

	for ( yy_cp = yytext_ptr + YY_MORE_ADJ; yy_cp < yy_c_buf_p; ++yy_cp )
		{
		register YY_CHAR yy_c = (*yy_cp ? yy_ec[YY_SC_TO_UI(*yy_cp)] : 1);
		if ( yy_accept[yy_current_state] )
			{
			yy_last_accepting_state = yy_current_state;
			yy_last_accepting_cpos = yy_cp;
			}
		while ( yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state )
			{
			yy_current_state = (int) yy_def[yy_current_state];
			if ( yy_current_state >= 159 )
				yy_c = yy_meta[(unsigned int) yy_c];
			}
		yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
		}

	return yy_current_state;
	}


/* yy_try_NUL_trans - try to make a transition on the NUL character
 *
 * synopsis
 *	next_state = yy_try_NUL_trans( current_state );
 */

yy_state_type yyFlexLexer::yy_try_NUL_trans( yy_state_type yy_current_state )
	{
	register int yy_is_jam;
	register char *yy_cp = yy_c_buf_p;

	register YY_CHAR yy_c = 1;
	if ( yy_accept[yy_current_state] )
		{
		yy_last_accepting_state = yy_current_state;
		yy_last_accepting_cpos = yy_cp;
		}
	while ( yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state )
		{
		yy_current_state = (int) yy_def[yy_current_state];
		if ( yy_current_state >= 159 )
			yy_c = yy_meta[(unsigned int) yy_c];
		}
	yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
	yy_is_jam = (yy_current_state == 158);

	return yy_is_jam ? 0 : yy_current_state;
	}


void yyFlexLexer::yyunput( int c, register char* yy_bp )
	{
	register char *yy_cp = yy_c_buf_p;

	/* undo effects of setting up yytext */
	*yy_cp = yy_hold_char;

	if ( yy_cp < yy_current_buffer->yy_ch_buf + 2 )
		{ /* need to shift things up to make room */
		/* +2 for EOB chars. */
		register int number_to_move = yy_n_chars + 2;
		register char *dest = &yy_current_buffer->yy_ch_buf[
					yy_current_buffer->yy_buf_size + 2];
		register char *source =
				&yy_current_buffer->yy_ch_buf[number_to_move];

		while ( source > yy_current_buffer->yy_ch_buf )
			*--dest = *--source;

		yy_cp += (int) (dest - source);
		yy_bp += (int) (dest - source);
		yy_current_buffer->yy_n_chars =
			yy_n_chars = yy_current_buffer->yy_buf_size;

		if ( yy_cp < yy_current_buffer->yy_ch_buf + 2 )
			YY_FATAL_ERROR( "flex scanner push-back overflow" );
		}

	*--yy_cp = (char) c;


	yytext_ptr = yy_bp;
	yy_hold_char = *yy_cp;
	yy_c_buf_p = yy_cp;
	}


int yyFlexLexer::yyinput()
	{
	int c;

	*yy_c_buf_p = yy_hold_char;

	if ( *yy_c_buf_p == YY_END_OF_BUFFER_CHAR )
		{
		/* yy_c_buf_p now points to the character we want to return.
		 * If this occurs *before* the EOB characters, then it's a
		 * valid NUL; if not, then we've hit the end of the buffer.
		 */
		if ( yy_c_buf_p < &yy_current_buffer->yy_ch_buf[yy_n_chars] )
			/* This was really a NUL. */
			*yy_c_buf_p = '\0';

		else
			{ /* need more input */
			int offset = yy_c_buf_p - yytext_ptr;
			++yy_c_buf_p;

			switch ( yy_get_next_buffer() )
				{
				case EOB_ACT_LAST_MATCH:
					/* This happens because yy_g_n_b()
					 * sees that we've accumulated a
					 * token and flags that we need to
					 * try matching the token before
					 * proceeding.  But for input(),
					 * there's no matching to consider.
					 * So convert the EOB_ACT_LAST_MATCH
					 * to EOB_ACT_END_OF_FILE.
					 */

					/* Reset buffer status. */
					yyrestart( yyin );

					/* fall through */

				case EOB_ACT_END_OF_FILE:
					{
					if ( yywrap() )
						return EOF;

					if ( ! yy_did_buffer_switch_on_eof )
						YY_NEW_FILE;
#ifdef __cplusplus
					return yyinput();
#else
					return input();
#endif
					}

				case EOB_ACT_CONTINUE_SCAN:
					yy_c_buf_p = yytext_ptr + offset;
					break;
				}
			}
		}

	c = *(unsigned char *) yy_c_buf_p;	/* cast for 8-bit char's */
	*yy_c_buf_p = '\0';	/* preserve yytext */
	yy_hold_char = *++yy_c_buf_p;


	return c;
	}

void yyFlexLexer::yyrestart( istream* input_file )
	{
	if ( ! yy_current_buffer )
		yy_current_buffer = yy_create_buffer( yyin, YY_BUF_SIZE );

	yy_init_buffer( yy_current_buffer, input_file );
	yy_load_buffer_state();
	}


void yyFlexLexer::yy_switch_to_buffer( YY_BUFFER_STATE new_buffer )
	{
	if ( yy_current_buffer == new_buffer )
		return;

	if ( yy_current_buffer )
		{
		/* Flush out information for old buffer. */
		*yy_c_buf_p = yy_hold_char;
		yy_current_buffer->yy_buf_pos = yy_c_buf_p;
		yy_current_buffer->yy_n_chars = yy_n_chars;
		}

	yy_current_buffer = new_buffer;
	yy_load_buffer_state();

	/* We don't actually know whether we did this switch during
	 * EOF (yywrap()) processing, but the only time this flag
	 * is looked at is after yywrap() is called, so it's safe
	 * to go ahead and always set it.
	 */
	yy_did_buffer_switch_on_eof = 1;
	}


void yyFlexLexer::yy_load_buffer_state()
	{
	yy_n_chars = yy_current_buffer->yy_n_chars;
	yytext_ptr = yy_c_buf_p = yy_current_buffer->yy_buf_pos;
	yyin = yy_current_buffer->yy_input_file;
	yy_hold_char = *yy_c_buf_p;
	}


YY_BUFFER_STATE yyFlexLexer::yy_create_buffer( istream* file, int size )
	{
	YY_BUFFER_STATE b;

	b = (YY_BUFFER_STATE) yy_flex_alloc( sizeof( struct yy_buffer_state ) );
	if ( ! b )
		YY_FATAL_ERROR( "out of dynamic memory in yy_create_buffer()" );

	b->yy_buf_size = size;

	/* yy_ch_buf has to be 2 characters longer than the size given because
	 * we need to put in 2 end-of-buffer characters.
	 */
	b->yy_ch_buf = (char *) yy_flex_alloc( b->yy_buf_size + 2 );
	if ( ! b->yy_ch_buf )
		YY_FATAL_ERROR( "out of dynamic memory in yy_create_buffer()" );

	b->yy_is_our_buffer = 1;

	yy_init_buffer( b, file );

	return b;
	}


void yyFlexLexer::yy_delete_buffer( YY_BUFFER_STATE b )
	{
	if ( ! b )
		return;

	if ( b == yy_current_buffer )
		yy_current_buffer = (YY_BUFFER_STATE) 0;

	if ( b->yy_is_our_buffer )
		yy_flex_free( (void *) b->yy_ch_buf );

	yy_flex_free( (void *) b );
	}


void yyFlexLexer::yy_init_buffer( YY_BUFFER_STATE b, istream* file )

	{
	yy_flush_buffer( b );

	b->yy_input_file = file;
	b->yy_fill_buffer = 1;

	b->yy_is_interactive = 0;
	}


void yyFlexLexer::yy_flush_buffer( YY_BUFFER_STATE b )
	{
	if ( ! b )
		return;

	b->yy_n_chars = 0;

	/* We always need two end-of-buffer characters.  The first causes
	 * a transition to the end-of-buffer state.  The second causes
	 * a jam in that state.
	 */
	b->yy_ch_buf[0] = YY_END_OF_BUFFER_CHAR;
	b->yy_ch_buf[1] = YY_END_OF_BUFFER_CHAR;

	b->yy_buf_pos = &b->yy_ch_buf[0];

	b->yy_at_bol = 1;
	b->yy_buffer_status = YY_BUFFER_NEW;

	if ( b == yy_current_buffer )
		yy_load_buffer_state();
	}


#ifndef YY_NO_SCAN_BUFFER
#endif


#ifndef YY_NO_SCAN_STRING
#endif


#ifndef YY_NO_SCAN_BYTES
#endif


#ifndef YY_NO_PUSH_STATE
void yyFlexLexer::yy_push_state( int new_state )
	{
	if ( yy_start_stack_ptr >= yy_start_stack_depth )
		{
		yy_size_t new_size;

		yy_start_stack_depth += YY_START_STACK_INCR;
		new_size = yy_start_stack_depth * sizeof( int );

		if ( ! yy_start_stack )
			yy_start_stack = (int *) yy_flex_alloc( new_size );

		else
			yy_start_stack = (int *) yy_flex_realloc(
					(void *) yy_start_stack, new_size );

		if ( ! yy_start_stack )
			YY_FATAL_ERROR(
			"out of memory expanding start-condition stack" );
		}

	yy_start_stack[yy_start_stack_ptr++] = YY_START;

	BEGIN(new_state);
	}
#endif


#ifndef YY_NO_POP_STATE
void yyFlexLexer::yy_pop_state()
	{
	if ( --yy_start_stack_ptr < 0 )
		YY_FATAL_ERROR( "start-condition stack underflow" );

	BEGIN(yy_start_stack[yy_start_stack_ptr]);
	}
#endif


#ifndef YY_NO_TOP_STATE
int yyFlexLexer::yy_top_state()
	{
	return yy_start_stack[yy_start_stack_ptr - 1];
	}
#endif

#ifndef YY_EXIT_FAILURE
#define YY_EXIT_FAILURE 2
#endif


void yyFlexLexer::LexerError( yyconst char msg[] )
	{
	cerr << msg << '\n';
	exit( YY_EXIT_FAILURE );
	}


/* Redefine yyless() so it works in section 3 code. */

#undef yyless
#define yyless(n) \
	do \
		{ \
		/* Undo effects of setting up yytext. */ \
		yytext[yyleng] = yy_hold_char; \
		yy_c_buf_p = yytext + n; \
		yy_hold_char = *yy_c_buf_p; \
		*yy_c_buf_p = '\0'; \
		yyleng = n; \
		} \
	while ( 0 )


/* Internal utility routines. */

#ifndef yytext_ptr
#ifdef YY_USE_PROTOS
static void yy_flex_strncpy( char *s1, yyconst char *s2, int n )
#else
static void yy_flex_strncpy( s1, s2, n )
char *s1;
yyconst char *s2;
int n;
#endif
	{
	register int i;
	for ( i = 0; i < n; ++i )
		s1[i] = s2[i];
	}
#endif

#ifdef YY_NEED_STRLEN
#ifdef YY_USE_PROTOS
static int yy_flex_strlen( yyconst char *s )
#else
static int yy_flex_strlen( s )
yyconst char *s;
#endif
	{
	register int n;
	for ( n = 0; s[n]; ++n )
		;

	return n;
	}
#endif


#ifdef YY_USE_PROTOS
static void *yy_flex_alloc( yy_size_t size )
#else
static void *yy_flex_alloc( size )
yy_size_t size;
#endif
	{
	return (void *) malloc( size );
	}

#ifdef YY_USE_PROTOS
static void *yy_flex_realloc( void *ptr, yy_size_t size )
#else
static void *yy_flex_realloc( ptr, size )
void *ptr;
yy_size_t size;
#endif
	{
	/* The cast to (char *) in the following accommodates both
	 * implementations that use char* generic pointers, and those
	 * that use void* generic pointers.  It works with the latter
	 * because both ANSI C and C++ allow castless assignment from
	 * any pointer type to void*, and deal with argument conversions
	 * as though doing an assignment.
	 */
	return (void *) realloc( (char *) ptr, size );
	}

#ifdef YY_USE_PROTOS
static void yy_flex_free( void *ptr )
#else
static void yy_flex_free( ptr )
void *ptr;
#endif
	{
	free( ptr );
	}

#if YY_MAIN
int main()
	{
	yylex();
	return 0;
	}
#endif
#line 388 "gramlex.lex"

/* -------------------- additional C code -------------------- */

// identify tokens representing embedded text
bool isGramlexEmbed(int code)
{
  return code == TOK_LIT_CODE;
}

@h=tangler('elk/elk_gramlex.yy.cpp.old')
@select(h)
/* A lexical scanner generated by flex */

/* Scanner skeleton version:
 * $Header$
 */

#define FLEX_SCANNER
#define YY_FLEX_MAJOR_VERSION 2
#define YY_FLEX_MINOR_VERSION 5



/* cfront 1.2 defines "c_plusplus" instead of "__cplusplus" */
#ifdef c_plusplus
#ifndef __cplusplus
#define __cplusplus
#endif
#endif


#ifdef __cplusplus

#include <stdlib.h>
#include <iostream>
using namespace std;

/* Use prototypes in function declarations. */
#define YY_USE_PROTOS

/* The "const" storage-class-modifier is valid. */
#define YY_USE_CONST

#else   /* ! __cplusplus */

#if __STDC__

#define YY_USE_PROTOS
#define YY_USE_CONST

#endif  /* __STDC__ */
#endif  /* ! __cplusplus */

#ifdef __TURBOC__
 #pragma warn -rch
 #pragma warn -use
#include <io.h>
#include <stdlib.h>
#define YY_USE_CONST
#define YY_USE_PROTOS
#endif

#ifdef YY_USE_CONST
#define yyconst const
#else
#define yyconst
#endif


#ifdef YY_USE_PROTOS
#define YY_PROTO(proto) proto
#else
#define YY_PROTO(proto) ()
#endif

/* Returned upon end-of-file. */
#define YY_NULL 0

/* Promotes a possibly negative, possibly signed char to an unsigned
 * integer for use as an array index.  If the signed char is negative,
 * we want to instead treat it as an 8-bit unsigned char, hence the
 * double cast.
 */
#define YY_SC_TO_UI(c) ((unsigned int) (unsigned char) c)

/* Enter a start condition.  This macro really ought to take a parameter,
 * but we do it the disgusting crufty way forced on us by the ()-less
 * definition of BEGIN.
 */
#define BEGIN yy_start = 1 + 2 *

/* Translate the current start state into a value that can be later handed
 * to BEGIN to return to the state.  The YYSTATE alias is for lex
 * compatibility.
 */
#define YY_START ((yy_start - 1) / 2)
#define YYSTATE YY_START

/* Action number for EOF rule of a given start state. */
#define YY_STATE_EOF(state) (YY_END_OF_BUFFER + state + 1)

/* Special action meaning "start processing a new file". */
#define YY_NEW_FILE yyrestart( yyin )

#define YY_END_OF_BUFFER_CHAR 0

/* Size of default input buffer. */
#define YY_BUF_SIZE 16384

typedef struct yy_buffer_state *YY_BUFFER_STATE;

extern int yyleng;

#define EOB_ACT_CONTINUE_SCAN 0
#define EOB_ACT_END_OF_FILE 1
#define EOB_ACT_LAST_MATCH 2

/* The funky do-while in the following #define is used to turn the definition
 * int a single C statement (which needs a semi-colon terminator).  This
 * avoids problems with code like:
 *
 *      if ( condition_holds )
 *              yyless( 5 );
 *      else
 *              do_something_else();
 *
 * Prior to using the do-while the compiler would get upset at the
 * "else" because it interpreted the "if" statement as being all
 * done when it reached the ';' after the yyless() call.
 */

/* Return all but the first 'n' matched characters back to the input stream. */

#define yyless(n) \
        do \
                { \
                /* Undo effects of setting up yytext. */ \
                *yy_cp = yy_hold_char; \
                YY_RESTORE_YY_MORE_OFFSET \
                yy_c_buf_p = yy_cp = yy_bp + n - YY_MORE_ADJ; \
                YY_DO_BEFORE_ACTION; /* set up yytext again */ \
                } \
        while ( 0 )

#define unput(c) yyunput( c, yytext_ptr )

/* The following is because we cannot portably get our hands on size_t
 * (without autoconf's help, which isn't available because we want
 * flex-generated scanners to compile on their own).
 */
typedef unsigned int yy_size_t;


struct yy_buffer_state
        {
        istream* yy_input_file;

        char *yy_ch_buf;                /* input buffer */
        char *yy_buf_pos;               /* current position in input buffer */

        /* Size of input buffer in bytes, not including room for EOB
         * characters.
         */
        yy_size_t yy_buf_size;

        /* Number of characters read into yy_ch_buf, not including EOB
         * characters.
         */
        int yy_n_chars;

        /* Whether we "own" the buffer - i.e., we know we created it,
         * and can realloc() it to grow it, and should free() it to
         * delete it.
         */
        int yy_is_our_buffer;

        /* Whether this is an "interactive" input source; if so, and
         * if we're using stdio for input, then we want to use getc()
         * instead of fread(), to make sure we stop fetching input after
         * each newline.
         */
        int yy_is_interactive;

        /* Whether we're considered to be at the beginning of a line.
         * If so, '^' rules will be active on the next match, otherwise
         * not.
         */
        int yy_at_bol;

        /* Whether to try to fill the input buffer when we reach the
         * end of it.
         */
        int yy_fill_buffer;

        int yy_buffer_status;
#define YY_BUFFER_NEW 0
#define YY_BUFFER_NORMAL 1
        /* When an EOF's been seen but there's still some text to process
         * then we mark the buffer as YY_EOF_PENDING, to indicate that we
         * shouldn't try reading from the input source any more.  We might
         * still have a bunch of tokens to match, though, because of
         * possible backing-up.
         *
         * When we actually see the EOF, we change the status to "new"
         * (via yyrestart()), so that the user can continue scanning by
         * just pointing yyin at a new input file.
         */
#define YY_BUFFER_EOF_PENDING 2
        };


/* We provide macros for accessing buffer states in case in the
 * future we want to put the buffer states in a more general
 * "scanner state".
 */
#define YY_CURRENT_BUFFER yy_current_buffer



static void *yy_flex_alloc YY_PROTO(( yy_size_t ));
static void *yy_flex_realloc YY_PROTO(( void *, yy_size_t ));
static void yy_flex_free YY_PROTO(( void * ));

#define yy_new_buffer yy_create_buffer

#define yy_set_interactive(is_interactive) \
        { \
        if ( ! yy_current_buffer ) \
                yy_current_buffer = yy_create_buffer( yyin, YY_BUF_SIZE ); \
        yy_current_buffer->yy_is_interactive = is_interactive; \
        }

#define yy_set_bol(at_bol) \
        { \
        if ( ! yy_current_buffer ) \
                yy_current_buffer = yy_create_buffer( yyin, YY_BUF_SIZE ); \
        yy_current_buffer->yy_at_bol = at_bol; \
        }

#define YY_AT_BOL() (yy_current_buffer->yy_at_bol)


#define yywrap() 1
#define YY_SKIP_YYWRAP
typedef unsigned char YY_CHAR;
#define yytext_ptr yytext
#define YY_INTERACTIVE

#include "sm_flexlexer.h"
int yyFlexLexer::yylex()
        {
        LexerError( "yyFlexLexer::yylex invoked but %option yyclass used" );
        return 0;
        }

#define YY_DECL int GrammarLexer::yylex()


/* Done after the current pattern has been matched and before the
 * corresponding action - sets up yytext.
 */
#define YY_DO_BEFORE_ACTION \
        yytext_ptr = yy_bp; \
        yyleng = (int) (yy_cp - yy_bp); \
        yy_hold_char = *yy_cp; \
        *yy_cp = '\0'; \
        yy_c_buf_p = yy_cp;

#define YY_NUM_RULES 40
#define YY_END_OF_BUFFER 41
static yyconst short int yy_accept[159] =
    {   0,
        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
        0,    0,    0,    0,    0,    0,   41,   39,    2,    1,
       39,   24,   10,   11,   39,   39,   37,    9,   21,   36,
       17,   36,   36,   36,   36,   36,   36,   36,   36,   36,
       36,   20,    8,    5,    6,    5,   33,   33,   33,   34,
       35,   27,   28,   29,   19,   23,    2,    0,   38,   18,
        3,    0,   37,   36,   36,   36,   36,   36,   36,   36,
       36,   36,   36,   36,   36,   36,    4,    0,    0,    0,
        0,   34,   27,    0,    7,   36,   36,   25,   36,   36,
       36,   36,   36,   36,   36,   36,   36,    0,   36,   36,

       36,   36,   36,   36,   36,   36,   36,   36,   36,    0,
       36,   36,   36,   36,   36,   36,   36,   36,   36,   22,
       36,    0,   32,   36,   15,   36,   36,   36,   14,   36,
       36,   36,   36,   36,   36,   31,   36,   16,   36,   36,
       36,   36,   36,   36,   26,   36,   36,   36,   12,   36,
       36,   13,   36,   36,   36,   36,   30,    0
    } ;

static yyconst int yy_ec[256] =
    {   0,
        1,    1,    1,    1,    1,    1,    1,    1,    2,    3,
        4,    4,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    2,    1,    5,    1,    1,    1,    1,    1,    6,
        7,    8,    1,    9,   10,    1,   11,   12,   12,   12,
       12,   12,   12,   12,   12,   12,   12,   13,   14,    1,
        1,   15,    1,    1,   16,   16,   16,   16,   16,   16,
       16,   16,   16,   16,   16,   16,   16,   16,   16,   16,
       16,   16,   16,   16,   16,   16,   16,   16,   16,   16,
       17,   18,   19,    1,   20,    1,   21,   22,   23,   24,

       25,   26,   16,   16,   27,   16,   28,   29,   30,   31,
       32,   33,   16,   34,   35,   36,   37,   38,   16,   39,
       16,   16,   40,    1,   41,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,

        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1
    } ;

static yyconst int yy_meta[42] =
    {   0,
        1,    1,    2,    1,    3,    1,    4,    1,    1,    1,
        1,    5,    1,    1,    1,    5,    1,    6,    4,    5,
        5,    5,    5,    5,    5,    5,    5,    5,    5,    5,
        5,    5,    5,    5,    5,    5,    5,    5,    5,    1,
        4
    } ;

static yyconst short int yy_base[169] =
    {   0,
        0,    0,   39,   40,   43,   44,  227,  226,   48,   49,
      188,  187,   30,   39,   48,   51,  226,  231,   56,  231,
      220,  231,  231,  231,  209,   53,  211,  231,  231,    0,
      231,  190,  182,  183,   41,  187,  185,  183,  179,   34,
      190,  231,  231,  231,  231,  203,  231,   67,   72,    0,
      231,    0,  231,  231,  231,  231,   74,  208,  231,  231,
      231,  209,  199,    0,  179,  176,  177,  174,  183,  174,
      168,  178,  180,  167,  172,  165,  231,   78,   80,   81,
        0,    0,    0,  195,  231,  161,  171,    0,  166,  165,
      157,  165,  168,  155,  159,  163,  165,  181,  160,  161,

      163,  145,  156,  148,  154,  153,  150,  145,  154,   85,
      135,  137,  134,  147,  136,  138,  144,  131,  135,    0,
      129,   91,  231,  128,    0,  138,  137,  131,    0,  135,
      124,  137,  130,  136,  121,    0,  123,    0,  124,  122,
      128,  126,  124,  102,    0,  106,  108,   99,    0,   76,
       60,    0,   60,   67,   46,   45,    0,  231,   98,  104,
      110,  116,  122,   58,  127,  133,  139,  145
    } ;

static yyconst short int yy_def[169] =
    {   0,
      158,    1,  159,  159,  160,  160,  161,  161,  162,  162,
        1,    1,    1,    1,    1,    1,  158,  158,  158,  158,
      163,  158,  158,  158,  158,  158,  158,  158,  158,  164,
      158,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  158,  158,  158,  158,  158,  158,  158,  158,  165,
      158,  166,  158,  158,  158,  158,  158,  163,  158,  158,
      158,  167,  158,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  158,  158,  158,  158,
      168,  165,  166,  167,  158,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,  168,  164,  164,

      164,  164,  164,  164,  164,  164,  164,  164,  164,  158,
      164,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  158,  158,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,  164,  164,  164,
      164,  164,  164,  164,  164,  164,  164,    0,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158
    } ;

static yyconst short int yy_nxt[273] =
    {   0,
       18,   19,   20,   19,   21,   22,   23,   18,   24,   25,
       26,   27,   28,   29,   18,   30,   31,   18,   18,   30,
       30,   30,   32,   30,   33,   34,   35,   30,   30,   30,
       36,   37,   38,   30,   39,   40,   30,   41,   30,   42,
       43,   45,   45,   18,   48,   48,   46,   46,   49,   49,
       53,   53,   18,   56,   54,   54,   56,   57,   74,   57,
       61,   18,   64,   62,   18,   75,   54,   54,   78,   55,
       68,   69,   79,   80,  145,   57,   81,   57,   55,   78,
      157,   80,   80,   79,   81,   81,  122,   18,   54,   54,
       18,  123,  122,  156,  155,  154,  153,  123,   44,   44,

       44,   44,   44,   44,   47,   47,   47,   47,   47,   47,
       50,   50,   50,   50,   50,   50,   52,   52,   52,   52,
       52,   52,   58,  152,   58,   58,   58,   82,  151,   82,
       82,   82,   82,   83,  150,   83,  149,   83,   83,   84,
       84,   84,   84,   84,   84,   98,  148,  147,   98,   98,
      146,  145,  144,  143,  142,  141,  140,  139,  138,  137,
      120,  136,  135,  134,  133,  132,  131,  130,  129,  128,
      127,  126,  125,  124,  121,  120,  119,  118,  117,  116,
      115,  114,  113,  112,  111,  110,  109,  108,  107,  106,
      105,  104,  103,  102,  101,  100,   99,   85,   97,   96,

       95,   94,   93,   92,   91,   90,   89,   88,   87,   86,
       63,   85,   59,   77,   76,   73,   72,   71,   70,   67,
       66,   65,   63,   60,   59,  158,   55,   55,   51,   51,
       17,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158
    } ;

static yyconst short int yy_chk[273] =
    {   0,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
        1,    3,    4,   13,    5,    6,    3,    4,    5,    6,
        9,   10,   14,   15,    9,   10,   16,   19,   40,   19,
       26,   15,  164,   26,   16,   40,    9,   10,   48,   13,
       35,   35,   48,   49,  156,   57,   49,   57,   14,   78,
      155,   79,   80,   78,   79,   80,  110,   15,    9,   10,
       16,  110,  122,  154,  153,  151,  150,  122,  159,  159,

      159,  159,  159,  159,  160,  160,  160,  160,  160,  160,
      161,  161,  161,  161,  161,  161,  162,  162,  162,  162,
      162,  162,  163,  148,  163,  163,  163,  165,  147,  165,
      165,  165,  165,  166,  146,  166,  144,  166,  166,  167,
      167,  167,  167,  167,  167,  168,  143,  142,  168,  168,
      141,  140,  139,  137,  135,  134,  133,  132,  131,  130,
      128,  127,  126,  124,  121,  119,  118,  117,  116,  115,
      114,  113,  112,  111,  109,  108,  107,  106,  105,  104,
      103,  102,  101,  100,   99,   98,   97,   96,   95,   94,
       93,   92,   91,   90,   89,   87,   86,   84,   76,   75,

       74,   73,   72,   71,   70,   69,   68,   67,   66,   65,
       63,   62,   58,   46,   41,   39,   38,   37,   36,   34,
       33,   32,   27,   25,   21,   17,   12,   11,    8,    7,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158,  158,  158,  158,  158,  158,  158,  158,  158,
      158,  158
    } ;

/* The intent behind this definition is that it'll catch
 * any uses of REJECT which flex missed.
 */
#define REJECT reject_used_but_not_detected
#define yymore() yymore_used_but_not_detected
#define YY_MORE_ADJ 0
#define YY_RESTORE_YY_MORE_OFFSET
#define INITIAL 0
/* grammar.lex
 * lexical analyzer for my grammar input format
 *
 * The variety of syntaxes for embedded literal code cause this lexer
 * to have some of the context sensitivity usually associated with a
 * parser.  This context doesn't nest arbitrarily deeply, so the
 * language recognized is still regular, but clearly there's some
 * design tension.
 */
/* ----------------- C definitions -------------------- */

// pull in my declaration of the lexer class -- this defines
// the additional lexer state, some of which is used in the
// action rules below (this is in the ../ast/ directory now)
#include "ast_gramlex.h"

// pull in the bison-generated token codes
#include "elk_grampar.codes.h"

#include <string.h>     // strchr, strrchr

// for maintaining column count
#define TOKEN_START  tokenStartLoc = fileState.loc /* user ; */
#define UPD_COL      \
  fileState.loc = sourceLocManager->advCol(fileState.loc, yyleng)  /* user ; */
#define TOK_UPD_COL  TOKEN_START; UPD_COL  /* user ; */

/* -------------------- flex options ------------------ */
/* no wrapping is needed; setting this means we don't have to link with libfl.a */
/* don't use the default-echo rules */
/* generate a c++ lexer */
/* and I will define the class */
/* ------------------- definitions -------------------- */
/* any character, including newline */
/* any character except newline */
/* starting character in a name */
/* starting character in a numeric literal */
/* double-quote */
/* character that can appear in a quoted sm_string */
/* (I currently don't have any backslash codes, but I want to
 * leave open that possibility, so for now backslashes are illegal) */
/* horizontal whitespace */
/* whitespace that doesn't cross line a boundary */
/* --------------- start conditions ------------------- */
/* eating a comment delimited by slash-star and star-slash; note
 * that we remember our current state when entering C_COMMENT,
 * and restore it on exit */
#define C_COMMENT 1

/* looking for the file name in an "include" directive */
#define INCLUDE 2

/* recovering from an error by skipping to the next newline */
#define EAT_TO_NEWLINE 3

/* gathering literal embedded code; the delimiter is specified
 * in the 'embedFinish' variable */
#define LITCODE 4

/* tokenizing the right-hand side of a production; this one is not
 * exclusive because tokenization is virtually the same in RHS
 * mode as in INITIAL mode */
#define RHS 5

/* tokenizing parameter list of a function, leading into the
 * embedded code that is its body */
#define FUN 6

/* looking for the start of a type that follows "token" or "nonterm",
 * or the TOK_NAME meaning the type has been omitted */
#define OPTIONAL_TYPE 7

/* ---------------------- rules ----------------------- */

/* Macros after this point can all be overridden by user definitions in
 * section 1.
 */

#ifndef YY_SKIP_YYWRAP
#ifdef __cplusplus
extern "C" int yywrap YY_PROTO(( void ));
#else
extern int yywrap YY_PROTO(( void ));
#endif
#endif


#ifndef yytext_ptr
static void yy_flex_strncpy YY_PROTO(( char *, yyconst char *, int ));
#endif

#ifdef YY_NEED_STRLEN
static int yy_flex_strlen YY_PROTO(( yyconst char * ));
#endif

#ifndef YY_NO_INPUT
#endif

#if YY_STACK_USED
static int yy_start_stack_ptr = 0;
static int yy_start_stack_depth = 0;
static int *yy_start_stack = 0;
#ifndef YY_NO_PUSH_STATE
static void yy_push_state YY_PROTO(( int new_state ));
#endif
#ifndef YY_NO_POP_STATE
static void yy_pop_state YY_PROTO(( void ));
#endif
#ifndef YY_NO_TOP_STATE
static int yy_top_state YY_PROTO(( void ));
#endif

#else
#define YY_NO_PUSH_STATE 1
#define YY_NO_POP_STATE 1
#define YY_NO_TOP_STATE 1
#endif

#ifdef YY_MALLOC_DECL
YY_MALLOC_DECL
#else
#if __STDC__
#ifndef __cplusplus
#include <stdlib.h>
#endif
#else
/* Just try to get by without declaring the routines.  This will fail
 * miserably on non-ANSI systems for which sizeof(size_t) != sizeof(int)
 * or sizeof(void*) != sizeof(int).
 */
#endif
#endif

/* Amount of stuff to slurp up with each read. */
#ifndef YY_READ_BUF_SIZE
#define YY_READ_BUF_SIZE 8192
#endif

/* Copy whatever the last rule matched to the standard output. */

#ifndef ECHO
#define ECHO LexerOutput( yytext, yyleng )
#endif

/* Gets input and stuffs it into "buf".  number of characters read, or YY_NULL,
 * is returned in "result".
 */
#ifndef YY_INPUT
#define YY_INPUT(buf,result,max_size) \
        if ( (result = LexerInput( (char *) buf, max_size )) < 0 ) \
                YY_FATAL_ERROR( "input in flex scanner failed" );
#endif

/* No semi-colon after return; correct usage is to write "yyterminate();" -
 * we don't want an extra ';' after the "return" because that will cause
 * some compilers to complain about unreachable statements.
 */
#ifndef yyterminate
#define yyterminate() return YY_NULL
#endif

/* Number of entries by which start-condition stack grows. */
#ifndef YY_START_STACK_INCR
#define YY_START_STACK_INCR 25
#endif

/* Report a fatal error. */
#ifndef YY_FATAL_ERROR
#define YY_FATAL_ERROR(msg) LexerError( msg )
#endif

/* Default declaration of generated scanner - a define so the user can
 * easily add parameters.
 */
#ifndef YY_DECL
#define YY_DECL int yyFlexLexer::yylex()
#endif

/* Code executed at the beginning of each rule, after yytext and yyleng
 * have been set up.
 */
#ifndef YY_USER_ACTION
#define YY_USER_ACTION
#endif

/* Code executed at the end of each rule. */
#ifndef YY_BREAK
#define YY_BREAK break;
#endif

#define YY_RULE_SETUP \
        YY_USER_ACTION

YY_DECL
        {
        register yy_state_type yy_current_state;
        register char *yy_cp = NULL, *yy_bp = NULL;
        register int yy_act;



  /* -------- whitespace ------ */

        if ( yy_init )
                {
                yy_init = 0;

#ifdef YY_USER_INIT
                YY_USER_INIT;
#endif

                if ( ! yy_start )
                        yy_start = 1;   /* first start state */

                if ( ! yyin )
                        yyin = &cin;

                if ( ! yyout )
                        yyout = &cout;

                if ( ! yy_current_buffer )
                        yy_current_buffer =
                                yy_create_buffer( yyin, YY_BUF_SIZE );

                yy_load_buffer_state();
                }

        while ( 1 )             /* loops until end-of-file is reached */
                {
                yy_cp = yy_c_buf_p;

                /* Support of yytext. */
                *yy_cp = yy_hold_char;

                /* yy_bp points to the position in yy_ch_buf of the start of
                 * the current run.
                 */
                yy_bp = yy_cp;

                yy_current_state = yy_start;
yy_match:
                do
                        {
                        register YY_CHAR yy_c = yy_ec[YY_SC_TO_UI(*yy_cp)];
                        if ( yy_accept[yy_current_state] )
                                {
                                yy_last_accepting_state = yy_current_state;
                                yy_last_accepting_cpos = yy_cp;
                                }
                        while ( yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state )
                                {
                                yy_current_state = (int) yy_def[yy_current_state];
                                if ( yy_current_state >= 159 )
                                        yy_c = yy_meta[(unsigned int) yy_c];
                                }
                        yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
                        ++yy_cp;
                        }
                while ( yy_base[yy_current_state] != 231 );

yy_find_action:
                yy_act = yy_accept[yy_current_state];
                if ( yy_act == 0 )
                        { /* have to back up */
                        yy_cp = yy_last_accepting_cpos;
                        yy_current_state = yy_last_accepting_state;
                        yy_act = yy_accept[yy_current_state];
                        }

                YY_DO_BEFORE_ACTION;


do_action:      /* This label is used only to access EOF actions. */


                switch ( yy_act )
        { /* beginning of action switch */
                        case 0: /* must back up */
                        /* undo the effects of YY_DO_BEFORE_ACTION */
                        *yy_cp = yy_hold_char;
                        yy_cp = yy_last_accepting_cpos;
                        yy_current_state = yy_last_accepting_state;
                        goto yy_find_action;

case 1:
YY_RULE_SETUP
{
  newLine();
}
        YY_BREAK
case 2:
YY_RULE_SETUP
{
  UPD_COL;
}
        YY_BREAK
/* -------- comments -------- */
case 3:
YY_RULE_SETUP
{
  /* C-style comments */
  TOKEN_START;
  UPD_COL;
  prevState = YY_START;
  BEGIN(C_COMMENT);
}
        YY_BREAK

case 4:
YY_RULE_SETUP
{
    /* end of comment */
    UPD_COL;
    BEGIN(prevState);
  }
        YY_BREAK
case 5:
YY_RULE_SETUP
{
    /* anything but slash-star or newline -- eat it */
    UPD_COL;
  }
        YY_BREAK
case 6:
YY_RULE_SETUP
{
    newLine();
  }
        YY_BREAK
case YY_STATE_EOF(C_COMMENT):
{
    UPD_COL;      // <<EOF>> yyleng is 1!
    errorUnterminatedComment();
    return TOK_EOF;
  }
        YY_BREAK

case 7:
YY_RULE_SETUP
{
  /* C++-style comment -- eat it */
  TOKEN_START;
  advCol(yyleng-1);   // don't count newline
  newLine();          // count it here
}
        YY_BREAK
/* -------- punctuators, operators, keywords --------- */
case 8:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_RBRACE;
        YY_BREAK
case 9:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_COLON;
        YY_BREAK
case 10:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_RPAREN;
        YY_BREAK
case 11:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_COMMA;
        YY_BREAK
case 12:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_TERMINALS;
        YY_BREAK
case 13:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_PRECEDENCE;
        YY_BREAK
case 14:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_OPTION;
        YY_BREAK
case 15:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_EXPECT;
        YY_BREAK
case 16:
YY_RULE_SETUP
TOK_UPD_COL;  return TOK_SUBSETS;
        YY_BREAK
/* ----------- sequences that begin literal code ------------ */
/* for the time being, a "[" will always start an embedded sequence;
   * eventually, I'll remove this in favor of the brace- and paren-
   * delimited embedded sequences */
case 17:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(LITCODE);
  beginEmbed(']', TOK_LIT_CODE);
}
        YY_BREAK
/* the "->" operator moves us into RHS mode, which is special because
   * in this mode any "{" is interpreted as the beginning of an embedded
   * section of literal code */
case 18:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(RHS);
  return TOK_ARROW;
}
        YY_BREAK
/* "{" in a RHS begins embedded */
case 19:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(LITCODE);
  beginEmbed('}', TOK_LIT_CODE);
}
        YY_BREAK
/* otherwise it's just a "{" */
case 20:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  return TOK_LBRACE;
}
        YY_BREAK
/* since right-hand-sides can end with either embedded code or a simple
   * ";", the semicolon gets out of RHS mode */
case 21:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(INITIAL);     // if in RHS, reset to INITIAL
  return TOK_SEMICOLON;
}
        YY_BREAK
/* "token" and "nonterm" are always followed by an optional type,
   * and then a TOK_NAME.  So, until we see a TOK_NAME, "(" will mean
   * the start of an embedded sequence. */
case 22:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(OPTIONAL_TYPE);
  return yytext[0]=='t'? TOK_TOKEN : TOK_NONTERM;
}
        YY_BREAK
/* so now this begins embedded */
case 23:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(LITCODE);
  beginEmbed(')', TOK_LIT_CODE);
}
        YY_BREAK
/* otherwise it's just itself */
case 24:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  return TOK_LPAREN;
}
        YY_BREAK
/* function beginning */
case 25:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(FUN);            // treat "{" as beginning literal code
  return TOK_FUN;
}
        YY_BREAK
/* verbatim beginning */
case 26:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  BEGIN(FUN);            // close enough
  return yytext[0]=='v'? TOK_VERBATIM : TOK_IMPL_VERBATIM;
}
        YY_BREAK
/* --------- embedded literal code --------- */
/* no TOKEN_START here; we'll use the tokenStartLoc that
   * was computed in the opening punctuation */

case 27:
YY_RULE_SETUP
{
    UPD_COL;
    embedded->handle(yytext, yyleng, embedFinish);
  }
        YY_BREAK
case 28:
YY_RULE_SETUP
{
    newLine();
    embedded->handle(yytext, yyleng, embedFinish);
  }
        YY_BREAK
case 29:
YY_RULE_SETUP
{
    UPD_COL;
    if (embedded->zeroNesting()) {
      // done
      BEGIN(INITIAL);

      // check for balanced delimiter
      if (embedFinish != yytext[0]) {
        err("unbalanced literal code delimiter");
      }

      // don't add "return" or ";"
      embedded->exprOnly = false;

      // can't extract anything
      embedded->isDeclaration = false;

      // caller can get text from embedded->text
      return embedMode;
    }
    else {
      // delimeter paired within the embedded code, mostly ignore it
      embedded->handle(yytext, yyleng, embedFinish);
    }
  }
        YY_BREAK
case YY_STATE_EOF(LITCODE):
{
    err(sm_stringc << "hit end of file while looking for final `"
                << embedFinish << "'");
    yyterminate();
  }
        YY_BREAK

/* embedded *type* description */
case 30:
YY_RULE_SETUP
{
  /* caller will get text from yytext and yyleng */
  TOK_UPD_COL;

  /* drop into literal-code processing */
  BEGIN(LITCODE);

  /* I reset the initial nesting to -1 so that the '{' at the
   * beginning of the class body sets nesting to 0, thus when
   * I see the final '}' I'll see that at level 0 and stop */
  beginEmbed('}', TOK_LIT_CODE, -1);

  return TOK_CONTEXT_CLASS;
}
        YY_BREAK
/* ---------- includes ----------- */
case 31:
YY_RULE_SETUP
{
  TOK_UPD_COL;    /* hence no TOKEN_START in INCLUDE area */
  BEGIN(INCLUDE);
}
        YY_BREAK

case 32:
YY_RULE_SETUP
{
    /* e.g.: ("filename") */
    /* file name to include */
    UPD_COL;

    /* find quotes */
    char *leftq = strchr(yytext, '"');
    char *rightq = strchr(leftq+1, '"');
    xassert(leftq && rightq);

    /* extract filename sm_string */
    includeFileName = addString(leftq+1, rightq-leftq-1);

    /* go back to normal processing */
    BEGIN(INITIAL);
    return TOK_INCLUDE;
  }
        YY_BREAK
case 33:
YY_RULE_SETUP
{
    /* anything else: malformed */
    UPD_COL;
    errorMalformedInclude();

    /* rudimentary error recovery.. */
    BEGIN(EAT_TO_NEWLINE);
  }
        YY_BREAK


case 34:
YY_RULE_SETUP
{
    UPD_COL;
    /* not newline, eat it */
  }
        YY_BREAK
case 35:
YY_RULE_SETUP
{
    /* get out of here */
    newLine();
    BEGIN(INITIAL);
  }
        YY_BREAK

/* -------- name literal --------- */
case 36:
YY_RULE_SETUP
{
  /* get text from yytext and yyleng */
  TOK_UPD_COL;
  if (YY_START == OPTIONAL_TYPE) {
    BEGIN(INITIAL);      // bail out of OPTIONAL_TYPE mode
  }
  return TOK_NAME;
}
        YY_BREAK
/* -------- numeric literal ------ */
case 37:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  integerLiteral = strtoul(yytext, NULL, 10 /*radix*/);
  return TOK_INTEGER;
}
        YY_BREAK
/* ----------- sm_string literal ----- */
case 38:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  sm_stringLiteral = addString(yytext+1, yyleng-2);        // strip quotes
  return TOK_STRING;
}
        YY_BREAK
/* --------- illegal ------------- */
case 39:
YY_RULE_SETUP
{
  TOK_UPD_COL;
  errorIllegalCharacter(yytext[0]);
}
        YY_BREAK
case 40:
YY_RULE_SETUP
YY_FATAL_ERROR( "flex scanner jammed" );
        YY_BREAK
case YY_STATE_EOF(INITIAL):
case YY_STATE_EOF(INCLUDE):
case YY_STATE_EOF(EAT_TO_NEWLINE):
case YY_STATE_EOF(RHS):
case YY_STATE_EOF(FUN):
case YY_STATE_EOF(OPTIONAL_TYPE):
        yyterminate();

        case YY_END_OF_BUFFER:
                {
                /* Amount of text matched not including the EOB char. */
                int yy_amount_of_matched_text = (int) (yy_cp - yytext_ptr) - 1;

                /* Undo the effects of YY_DO_BEFORE_ACTION. */
                *yy_cp = yy_hold_char;
                YY_RESTORE_YY_MORE_OFFSET

                if ( yy_current_buffer->yy_buffer_status == YY_BUFFER_NEW )
                        {
                        /* We're scanning a new file or input source.  It's
                         * possible that this happened because the user
                         * just pointed yyin at a new source and called
                         * yylex().  If so, then we have to assure
                         * consistency between yy_current_buffer and our
                         * globals.  Here is the right place to do so, because
                         * this is the first action (other than possibly a
                         * back-up) that will match for the new input source.
                         */
                        yy_n_chars = yy_current_buffer->yy_n_chars;
                        yy_current_buffer->yy_input_file = yyin;
                        yy_current_buffer->yy_buffer_status = YY_BUFFER_NORMAL;
                        }

                /* Note that here we test for yy_c_buf_p "<=" to the position
                 * of the first EOB in the buffer, since yy_c_buf_p will
                 * already have been incremented past the NUL character
                 * (since all states make transitions on EOB to the
                 * end-of-buffer state).  Contrast this with the test
                 * in input().
                 */
                if ( yy_c_buf_p <= &yy_current_buffer->yy_ch_buf[yy_n_chars] )
                        { /* This was really a NUL. */
                        yy_state_type yy_next_state;

                        yy_c_buf_p = yytext_ptr + yy_amount_of_matched_text;

                        yy_current_state = yy_get_previous_state();

                        /* Okay, we're now positioned to make the NUL
                         * transition.  We couldn't have
                         * yy_get_previous_state() go ahead and do it
                         * for us because it doesn't know how to deal
                         * with the possibility of jamming (and we don't
                         * want to build jamming into it because then it
                         * will run more slowly).
                         */

                        yy_next_state = yy_try_NUL_trans( yy_current_state );

                        yy_bp = yytext_ptr + YY_MORE_ADJ;

                        if ( yy_next_state )
                                {
                                /* Consume the NUL. */
                                yy_cp = ++yy_c_buf_p;
                                yy_current_state = yy_next_state;
                                goto yy_match;
                                }

                        else
                                {
                                yy_cp = yy_c_buf_p;
                                goto yy_find_action;
                                }
                        }

                else switch ( yy_get_next_buffer() )
                        {
                        case EOB_ACT_END_OF_FILE:
                                {
                                yy_did_buffer_switch_on_eof = 0;

                                if ( yywrap() )
                                        {
                                        /* Note: because we've taken care in
                                         * yy_get_next_buffer() to have set up
                                         * yytext, we can now set up
                                         * yy_c_buf_p so that if some total
                                         * hoser (like flex itself) wants to
                                         * call the scanner after we return the
                                         * YY_NULL, it'll still work - another
                                         * YY_NULL will get returned.
                                         */
                                        yy_c_buf_p = yytext_ptr + YY_MORE_ADJ;

                                        yy_act = YY_STATE_EOF(YY_START);
                                        goto do_action;
                                        }

                                else
                                        {
                                        if ( ! yy_did_buffer_switch_on_eof )
                                                YY_NEW_FILE;
                                        }
                                break;
                                }

                        case EOB_ACT_CONTINUE_SCAN:
                                yy_c_buf_p =
                                        yytext_ptr + yy_amount_of_matched_text;

                                yy_current_state = yy_get_previous_state();

                                yy_cp = yy_c_buf_p;
                                yy_bp = yytext_ptr + YY_MORE_ADJ;
                                goto yy_match;

                        case EOB_ACT_LAST_MATCH:
                                yy_c_buf_p =
                                &yy_current_buffer->yy_ch_buf[yy_n_chars];

                                yy_current_state = yy_get_previous_state();

                                yy_cp = yy_c_buf_p;
                                yy_bp = yytext_ptr + YY_MORE_ADJ;
                                goto yy_find_action;
                        }
                break;
                }

        default:
                YY_FATAL_ERROR(
                        "fatal flex scanner internal error--no action found" );
        } /* end of action switch */
                } /* end of scanning one token */
        } /* end of yylex */

yyFlexLexer::yyFlexLexer( istream* arg_yyin, ostream* arg_yyout )
        {
        yyin = arg_yyin;
        yyout = arg_yyout;
        yy_c_buf_p = 0;
        yy_init = 1;
        yy_start = 0;
        yy_flex_debug = 0;
        yylineno = 1;   // this will only get updated if %option yylineno

        yy_did_buffer_switch_on_eof = 0;

        yy_looking_for_trail_begin = 0;
        yy_more_flag = 0;
        yy_more_len = 0;
        yy_more_offset = yy_prev_more_offset = 0;

        yy_start_stack_ptr = yy_start_stack_depth = 0;
        yy_start_stack = 0;

        yy_current_buffer = 0;

#ifdef YY_USES_REJECT
        yy_state_buf = new yy_state_type[YY_BUF_SIZE + 2];
#else
        yy_state_buf = 0;
#endif
        }

yyFlexLexer::~yyFlexLexer()
        {
        delete yy_state_buf;
        yy_delete_buffer( yy_current_buffer );
        }

void yyFlexLexer::switch_streams( istream* new_in, ostream* new_out )
        {
        if ( new_in )
                {
                yy_delete_buffer( yy_current_buffer );
                yy_switch_to_buffer( yy_create_buffer( new_in, YY_BUF_SIZE ) );
                }

        if ( new_out )
                yyout = new_out;
        }

#ifdef YY_INTERACTIVE
int yyFlexLexer::LexerInput( char* buf, int /* max_size */ )
#else
int yyFlexLexer::LexerInput( char* buf, int max_size )
#endif
        {
        if ( yyin->eof() || yyin->fail() )
                return 0;

#ifdef YY_INTERACTIVE
        yyin->get( buf[0] );

        if ( yyin->eof() )
                return 0;

        if ( yyin->bad() )
                return -1;

        return 1;

#else
        (void) yyin->read( buf, max_size );

        if ( yyin->bad() )
                return -1;
        else
                return yyin->gcount();
#endif
        }

void yyFlexLexer::LexerOutput( const char* buf, int size )
        {
        (void) yyout->write( buf, size );
        }

/* yy_get_next_buffer - try to read in a new buffer
 *
 * Returns a code representing an action:
 *      EOB_ACT_LAST_MATCH -
 *      EOB_ACT_CONTINUE_SCAN - continue scanning from current position
 *      EOB_ACT_END_OF_FILE - end of file
 */

int yyFlexLexer::yy_get_next_buffer()
        {
        register char *dest = yy_current_buffer->yy_ch_buf;
        register char *source = yytext_ptr;
        register int number_to_move, i;
        int ret_val;

        if ( yy_c_buf_p > &yy_current_buffer->yy_ch_buf[yy_n_chars + 1] )
                YY_FATAL_ERROR(
                "fatal flex scanner internal error--end of buffer missed" );

        if ( yy_current_buffer->yy_fill_buffer == 0 )
                { /* Don't try to fill the buffer, so this is an EOF. */
                if ( yy_c_buf_p - yytext_ptr - YY_MORE_ADJ == 1 )
                        {
                        /* We matched a single character, the EOB, so
                         * treat this as a final EOF.
                         */
                        return EOB_ACT_END_OF_FILE;
                        }

                else
                        {
                        /* We matched some text prior to the EOB, first
                         * process it.
                         */
                        return EOB_ACT_LAST_MATCH;
                        }
                }

        /* Try to read more data. */

        /* First move last chars to start of buffer. */
        number_to_move = (int) (yy_c_buf_p - yytext_ptr) - 1;

        for ( i = 0; i < number_to_move; ++i )
                *(dest++) = *(source++);

        if ( yy_current_buffer->yy_buffer_status == YY_BUFFER_EOF_PENDING )
                /* don't do the read, it's not guaranteed to return an EOF,
                 * just force an EOF
                 */
                yy_current_buffer->yy_n_chars = yy_n_chars = 0;

        else
                {
                int num_to_read =
                        yy_current_buffer->yy_buf_size - number_to_move - 1;

                while ( num_to_read <= 0 )
                        { /* Not enough room in the buffer - grow it. */
#ifdef YY_USES_REJECT
                        YY_FATAL_ERROR(
"input buffer overflow, can't enlarge buffer because scanner uses REJECT" );
#else

                        /* just a shorter name for the current buffer */
                        YY_BUFFER_STATE b = yy_current_buffer;

                        int yy_c_buf_p_offset =
                                (int) (yy_c_buf_p - b->yy_ch_buf);

                        if ( b->yy_is_our_buffer )
                                {
                                int new_size = b->yy_buf_size * 2;

                                if ( new_size <= 0 )
                                        b->yy_buf_size += b->yy_buf_size / 8;
                                else
                                        b->yy_buf_size *= 2;

                                b->yy_ch_buf = (char *)
                                        /* Include room in for 2 EOB chars. */
                                        yy_flex_realloc( (void *) b->yy_ch_buf,
                                                         b->yy_buf_size + 2 );
                                }
                        else
                                /* Can't grow it, we don't own it. */
                                b->yy_ch_buf = 0;

                        if ( ! b->yy_ch_buf )
                                YY_FATAL_ERROR(
                                "fatal error - scanner input buffer overflow" );

                        yy_c_buf_p = &b->yy_ch_buf[yy_c_buf_p_offset];

                        num_to_read = yy_current_buffer->yy_buf_size -
                                                number_to_move - 1;
#endif
                        }

                if ( num_to_read > YY_READ_BUF_SIZE )
                        num_to_read = YY_READ_BUF_SIZE;

                /* Read in more data. */
                YY_INPUT( (&yy_current_buffer->yy_ch_buf[number_to_move]),
                        yy_n_chars, num_to_read );

                yy_current_buffer->yy_n_chars = yy_n_chars;
                }

        if ( yy_n_chars == 0 )
                {
                if ( number_to_move == YY_MORE_ADJ )
                        {
                        ret_val = EOB_ACT_END_OF_FILE;
                        yyrestart( yyin );
                        }

                else
                        {
                        ret_val = EOB_ACT_LAST_MATCH;
                        yy_current_buffer->yy_buffer_status =
                                YY_BUFFER_EOF_PENDING;
                        }
                }

        else
                ret_val = EOB_ACT_CONTINUE_SCAN;

        yy_n_chars += number_to_move;
        yy_current_buffer->yy_ch_buf[yy_n_chars] = YY_END_OF_BUFFER_CHAR;
        yy_current_buffer->yy_ch_buf[yy_n_chars + 1] = YY_END_OF_BUFFER_CHAR;

        yytext_ptr = &yy_current_buffer->yy_ch_buf[0];

        return ret_val;
        }


/* yy_get_previous_state - get the state just before the EOB char was reached */

yy_state_type yyFlexLexer::yy_get_previous_state()
        {
        register yy_state_type yy_current_state;
        register char *yy_cp;

        yy_current_state = yy_start;

        for ( yy_cp = yytext_ptr + YY_MORE_ADJ; yy_cp < yy_c_buf_p; ++yy_cp )
                {
                register YY_CHAR yy_c = (*yy_cp ? yy_ec[YY_SC_TO_UI(*yy_cp)] : 1);
                if ( yy_accept[yy_current_state] )
                        {
                        yy_last_accepting_state = yy_current_state;
                        yy_last_accepting_cpos = yy_cp;
                        }
                while ( yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state )
                        {
                        yy_current_state = (int) yy_def[yy_current_state];
                        if ( yy_current_state >= 159 )
                                yy_c = yy_meta[(unsigned int) yy_c];
                        }
                yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
                }

        return yy_current_state;
        }


/* yy_try_NUL_trans - try to make a transition on the NUL character
 *
 * synopsis
 *      next_state = yy_try_NUL_trans( current_state );
 */

yy_state_type yyFlexLexer::yy_try_NUL_trans( yy_state_type yy_current_state )
        {
        register int yy_is_jam;
        register char *yy_cp = yy_c_buf_p;

        register YY_CHAR yy_c = 1;
        if ( yy_accept[yy_current_state] )
                {
                yy_last_accepting_state = yy_current_state;
                yy_last_accepting_cpos = yy_cp;
                }
        while ( yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state )
                {
                yy_current_state = (int) yy_def[yy_current_state];
                if ( yy_current_state >= 159 )
                        yy_c = yy_meta[(unsigned int) yy_c];
                }
        yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
        yy_is_jam = (yy_current_state == 158);

        return yy_is_jam ? 0 : yy_current_state;
        }


void yyFlexLexer::yyunput( int c, register char* yy_bp )
        {
        register char *yy_cp = yy_c_buf_p;

        /* undo effects of setting up yytext */
        *yy_cp = yy_hold_char;

        if ( yy_cp < yy_current_buffer->yy_ch_buf + 2 )
                { /* need to shift things up to make room */
                /* +2 for EOB chars. */
                register int number_to_move = yy_n_chars + 2;
                register char *dest = &yy_current_buffer->yy_ch_buf[
                                        yy_current_buffer->yy_buf_size + 2];
                register char *source =
                                &yy_current_buffer->yy_ch_buf[number_to_move];

                while ( source > yy_current_buffer->yy_ch_buf )
                        *--dest = *--source;

                yy_cp += (int) (dest - source);
                yy_bp += (int) (dest - source);
                yy_current_buffer->yy_n_chars =
                        yy_n_chars = yy_current_buffer->yy_buf_size;

                if ( yy_cp < yy_current_buffer->yy_ch_buf + 2 )
                        YY_FATAL_ERROR( "flex scanner push-back overflow" );
                }

        *--yy_cp = (char) c;


        yytext_ptr = yy_bp;
        yy_hold_char = *yy_cp;
        yy_c_buf_p = yy_cp;
        }


int yyFlexLexer::yyinput()
        {
        int c;

        *yy_c_buf_p = yy_hold_char;

        if ( *yy_c_buf_p == YY_END_OF_BUFFER_CHAR )
                {
                /* yy_c_buf_p now points to the character we want to return.
                 * If this occurs *before* the EOB characters, then it's a
                 * valid NUL; if not, then we've hit the end of the buffer.
                 */
                if ( yy_c_buf_p < &yy_current_buffer->yy_ch_buf[yy_n_chars] )
                        /* This was really a NUL. */
                        *yy_c_buf_p = '\0';

                else
                        { /* need more input */
                        int offset = yy_c_buf_p - yytext_ptr;
                        ++yy_c_buf_p;

                        switch ( yy_get_next_buffer() )
                                {
                                case EOB_ACT_LAST_MATCH:
                                        /* This happens because yy_g_n_b()
                                         * sees that we've accumulated a
                                         * token and flags that we need to
                                         * try matching the token before
                                         * proceeding.  But for input(),
                                         * there's no matching to consider.
                                         * So convert the EOB_ACT_LAST_MATCH
                                         * to EOB_ACT_END_OF_FILE.
                                         */

                                        /* Reset buffer status. */
                                        yyrestart( yyin );

                                        /* fall through */

                                case EOB_ACT_END_OF_FILE:
                                        {
                                        if ( yywrap() )
                                                return EOF;

                                        if ( ! yy_did_buffer_switch_on_eof )
                                                YY_NEW_FILE;
#ifdef __cplusplus
                                        return yyinput();
#else
                                        return input();
#endif
                                        }

                                case EOB_ACT_CONTINUE_SCAN:
                                        yy_c_buf_p = yytext_ptr + offset;
                                        break;
                                }
                        }
                }

        c = *(unsigned char *) yy_c_buf_p;      /* cast for 8-bit char's */
        *yy_c_buf_p = '\0';     /* preserve yytext */
        yy_hold_char = *++yy_c_buf_p;


        return c;
        }

void yyFlexLexer::yyrestart( istream* input_file )
        {
        if ( ! yy_current_buffer )
                yy_current_buffer = yy_create_buffer( yyin, YY_BUF_SIZE );

        yy_init_buffer( yy_current_buffer, input_file );
        yy_load_buffer_state();
        }


void yyFlexLexer::yy_switch_to_buffer( YY_BUFFER_STATE new_buffer )
        {
        if ( yy_current_buffer == new_buffer )
                return;

        if ( yy_current_buffer )
                {
                /* Flush out information for old buffer. */
                *yy_c_buf_p = yy_hold_char;
                yy_current_buffer->yy_buf_pos = yy_c_buf_p;
                yy_current_buffer->yy_n_chars = yy_n_chars;
                }

        yy_current_buffer = new_buffer;
        yy_load_buffer_state();

        /* We don't actually know whether we did this switch during
         * EOF (yywrap()) processing, but the only time this flag
         * is looked at is after yywrap() is called, so it's safe
         * to go ahead and always set it.
         */
        yy_did_buffer_switch_on_eof = 1;
        }


void yyFlexLexer::yy_load_buffer_state()
        {
        yy_n_chars = yy_current_buffer->yy_n_chars;
        yytext_ptr = yy_c_buf_p = yy_current_buffer->yy_buf_pos;
        yyin = yy_current_buffer->yy_input_file;
        yy_hold_char = *yy_c_buf_p;
        }


YY_BUFFER_STATE yyFlexLexer::yy_create_buffer( istream* file, int size )
        {
        YY_BUFFER_STATE b;

        b = (YY_BUFFER_STATE) yy_flex_alloc( sizeof( struct yy_buffer_state ) );
        if ( ! b )
                YY_FATAL_ERROR( "out of dynamic memory in yy_create_buffer()" );

        b->yy_buf_size = size;

        /* yy_ch_buf has to be 2 characters longer than the size given because
         * we need to put in 2 end-of-buffer characters.
         */
        b->yy_ch_buf = (char *) yy_flex_alloc( b->yy_buf_size + 2 );
        if ( ! b->yy_ch_buf )
                YY_FATAL_ERROR( "out of dynamic memory in yy_create_buffer()" );

        b->yy_is_our_buffer = 1;

        yy_init_buffer( b, file );

        return b;
        }


void yyFlexLexer::yy_delete_buffer( YY_BUFFER_STATE b )
        {
        if ( ! b )
                return;

        if ( b == yy_current_buffer )
                yy_current_buffer = (YY_BUFFER_STATE) 0;

        if ( b->yy_is_our_buffer )
                yy_flex_free( (void *) b->yy_ch_buf );

        yy_flex_free( (void *) b );
        }


void yyFlexLexer::yy_init_buffer( YY_BUFFER_STATE b, istream* file )

        {
        yy_flush_buffer( b );

        b->yy_input_file = file;
        b->yy_fill_buffer = 1;

        b->yy_is_interactive = 0;
        }


void yyFlexLexer::yy_flush_buffer( YY_BUFFER_STATE b )
        {
        if ( ! b )
                return;

        b->yy_n_chars = 0;

        /* We always need two end-of-buffer characters.  The first causes
         * a transition to the end-of-buffer state.  The second causes
         * a jam in that state.
         */
        b->yy_ch_buf[0] = YY_END_OF_BUFFER_CHAR;
        b->yy_ch_buf[1] = YY_END_OF_BUFFER_CHAR;

        b->yy_buf_pos = &b->yy_ch_buf[0];

        b->yy_at_bol = 1;
        b->yy_buffer_status = YY_BUFFER_NEW;

        if ( b == yy_current_buffer )
                yy_load_buffer_state();
        }


#ifndef YY_NO_SCAN_BUFFER
#endif


#ifndef YY_NO_SCAN_STRING
#endif


#ifndef YY_NO_SCAN_BYTES
#endif


#ifndef YY_NO_PUSH_STATE
void yyFlexLexer::yy_push_state( int new_state )
        {
        if ( yy_start_stack_ptr >= yy_start_stack_depth )
                {
                yy_size_t new_size;

                yy_start_stack_depth += YY_START_STACK_INCR;
                new_size = yy_start_stack_depth * sizeof( int );

                if ( ! yy_start_stack )
                        yy_start_stack = (int *) yy_flex_alloc( new_size );

                else
                        yy_start_stack = (int *) yy_flex_realloc(
                                        (void *) yy_start_stack, new_size );

                if ( ! yy_start_stack )
                        YY_FATAL_ERROR(
                        "out of memory expanding start-condition stack" );
                }

        yy_start_stack[yy_start_stack_ptr++] = YY_START;

        BEGIN(new_state);
        }
#endif


#ifndef YY_NO_POP_STATE
void yyFlexLexer::yy_pop_state()
        {
        if ( --yy_start_stack_ptr < 0 )
                YY_FATAL_ERROR( "start-condition stack underflow" );

        BEGIN(yy_start_stack[yy_start_stack_ptr]);
        }
#endif


#ifndef YY_NO_TOP_STATE
int yyFlexLexer::yy_top_state()
        {
        return yy_start_stack[yy_start_stack_ptr - 1];
        }
#endif

#ifndef YY_EXIT_FAILURE
#define YY_EXIT_FAILURE 2
#endif


void yyFlexLexer::LexerError( yyconst char msg[] )
        {
        cerr << msg << '\n';
        exit( YY_EXIT_FAILURE );
        }


/* Redefine yyless() so it works in section 3 code. */

#undef yyless
#define yyless(n) \
        do \
                { \
                /* Undo effects of setting up yytext. */ \
                yytext[yyleng] = yy_hold_char; \
                yy_c_buf_p = yytext + n; \
                yy_hold_char = *yy_c_buf_p; \
                *yy_c_buf_p = '\0'; \
                yyleng = n; \
                } \
        while ( 0 )


/* Internal utility routines. */

#ifndef yytext_ptr
#ifdef YY_USE_PROTOS
static void yy_flex_strncpy( char *s1, yyconst char *s2, int n )
#else
static void yy_flex_strncpy( s1, s2, n )
char *s1;
yyconst char *s2;
int n;
#endif
        {
        register int i;
        for ( i = 0; i < n; ++i )
                s1[i] = s2[i];
        }
#endif

#ifdef YY_NEED_STRLEN
#ifdef YY_USE_PROTOS
static int yy_flex_strlen( yyconst char *s )
#else
static int yy_flex_strlen( s )
yyconst char *s;
#endif
        {
        register int n;
        for ( n = 0; s[n]; ++n )
                ;

        return n;
        }
#endif


#ifdef YY_USE_PROTOS
static void *yy_flex_alloc( yy_size_t size )
#else
static void *yy_flex_alloc( size )
yy_size_t size;
#endif
        {
        return (void *) malloc( size );
        }

#ifdef YY_USE_PROTOS
static void *yy_flex_realloc( void *ptr, yy_size_t size )
#else
static void *yy_flex_realloc( ptr, size )
void *ptr;
yy_size_t size;
#endif
        {
        /* The cast to (char *) in the following accommodates both
         * implementations that use char* generic pointers, and those
         * that use void* generic pointers.  It works with the latter
         * because both ANSI C and C++ allow castless assignment from
         * any pointer type to void*, and deal with argument conversions
         * as though doing an assignment.
         */
        return (void *) realloc( (char *) ptr, size );
        }

#ifdef YY_USE_PROTOS
static void yy_flex_free( void *ptr )
#else
static void yy_flex_free( ptr )
void *ptr;
#endif
        {
        free( ptr );
        }

#if YY_MAIN
int main()
        {
        yylex();
        return 0;
        }
#endif

/* -------------------- additional C code -------------------- */

// identify tokens representing embedded text
bool isGramlexEmbed(int code)
{
  return code == TOK_LIT_CODE;
}
@h=tangler('elk/elk_grampar.cpp')
@select(h)
// grampar.cc            see license.txt for copyright and terms of use
// additional C++ code for the grammar parser; in essence,
// build the grammar internal representation out of what
// the user supplies in a .gr file

#include "elk_grampar.h"
#include "ast_gramlex.h"
#include "sm_trace.h"
#include "elk_gramast.ast.gen.h"
#include "elk_grammar.h"
#include "sm_owner.h"
#include "sm_syserr.h"
#include "sm_strutil.h"
#include "elk_grampar.tab.h"
#include "sm_array.h"
#include "elk_mlsstr.h"

#include <fstream.h>         // ifstream
#include <ctype.h>           // isspace, isalnum

#define LIT_STR(s) LocString(SL_INIT, grammarStringTable.add(s))


// ------------------------- Environment ------------------------
Environment::Environment(Grammar &G)
  : g(G),
    prevEnv(NULL),
    nontermDecls(),
    errorCount(0),
    errors(errorCount)
{}

Environment::Environment(Environment &prev)
  : g(prev.g),
    prevEnv(&prev),
    nontermDecls(prev.nontermDecls),
    errorCount(-1000),      // should never be used
    errors(prev.errors)     // copy parent's 'errors' reference
{}

Environment::~Environment()
{}


// -------------------- XASTParse --------------------
STATICDEF sm_string XASTParse::
  constructMsg(LocString const &tok, char const *msg)
{
  if (tok.validLoc()) {
    return sm_stringc << tok.locString() << ": near " << tok
                   << ", " << msg;
  }
  else {
    return sm_string(msg);
  }
}

XASTParse::XASTParse(LocString const &tok, char const *m)
  : xBase(constructMsg(tok, m)),
    failToken(tok),
    message(m)
{}


XASTParse::XASTParse(XASTParse const &obj)
  : xBase(obj),
    DMEMB(failToken),
    DMEMB(message)
{}

XASTParse::~XASTParse()
{}


// -------------------- AST parser support ---------------------
// fwd-decl of parsing fns
void astParseGrammar(Grammar &g, GrammarAST *treeTop);
void astParseTerminals(Environment &env, TF_terminals const &terms);
void astParseDDM(Environment &env, Symbol *sym,
                 ASTList<SpecFunc> const &funcs);
void astParseNonterm(Environment &env, TF_nonterm const *nt);
void astParseProduction(Environment &env, Nonterminal *nonterm,
                        ProdDecl const *prod);


// really a static semantic error, more than a parse error..
void astParseError(LocString const &failToken, char const *msg)
{
  THROW(XASTParse(failToken, msg));
}

void astParseError(char const *msg)
{
  LocString ls;   // no location info
  THROW(XASTParse(ls, msg));
}
                      
// print the same message, but keep going anyway
void astParseErrorCont(Environment &env, LocString const &failToken, 
                       char const *msg)
{
  XASTParse x(failToken, msg);
  cout << x.why() << endl;
  env.errors++;
}


// to put as the catch block; so far it's kind of ad-hoc where
// I actually put 'try' blocks..
#define CATCH_APPLY_CONTEXT(tok)        \
  catch (XASTParse &x) {                \
    /* leave unchanged */               \
    throw x;                            \
  }                                     \
  catch (xBase &x) {                    \
    /* add context */                   \
    astParseError(tok, x.why());        \
    throw 0;     /* silence warning */  \
  }


// ---------------------- AST "parser" --------------------------
// set the annotation pointers
void setAnnotations(GrammarAST *ast)
{
  // work through the toplevel forms
  FOREACH_ASTLIST_NC(TopForm, ast->forms, iter) {
    ASTSWITCH(TopForm, iter.data()) {
      ASTCASE(TF_terminals, t) {
        if (!ast->terms) {
          ast->terms = t;
        }
        else {
          astParseError("there is more than one 'Terminals' section");
        }
      }

      ASTNEXT(TF_nonterm, nt) {
        if (!ast->firstNT) {
          ast->firstNT = nt;
        }
      }

      ASTENDCASED
    }
  }

  if (!ast->terms) {
    astParseError("'Terminals' specification is missing");
  }
  if (!ast->firstNT) {
    astParseError("you have to have at least one nonterminal");
  }
}


LocString extractActionClassName(LocString const &body)
{
  // find start of first token
  char const *start = body.str;
  while (isspace(*start)) start++;

  // find end of first token
  char const *p = start;
  while (isspace(*p)) p++;
  while (isalnum(*p) || *p=='_') p++;
  
  // yield that, with the same source location
  return LocString(body.loc, grammarStringTable.add(sm_string(start, p-start)));
}


// handle TF_verbatim and TF_option
void astParseOptions(Grammar &g, GrammarAST *ast)
{
  // handle TF_verbatim and TF_option
  FOREACH_ASTLIST_NC(TopForm, ast->forms, iter) {
    ASTSWITCH(TopForm, iter.data()) {
      ASTCASE(TF_context, c) {
        // overwrite the context class name, and append to
        // its body verbatim list
        g.actionClassName = extractActionClassName(c->body);

        // 11/13/04: There is a subtle problem with keeping the body
        // from the base specification, when the following conditions
        // hold:
        //   - the base spec is compiled on its own (w/o the extension)
        //   - some translation unit "A" sees the resulting .gr.gen.h file
        //   - the extension spec is compiled
        //   - some translation unit "B" sees the resulting .gr.gen.h file
        //   - A and B are linked together in one executable
        // In that case, the context_class from the base will have an
        // inconsistent definition in A and B, since in A it will be
        // whatever the user wrote plus, the declarations for the
        // action functions, whereas in B it will be just what the
        // user wrote, since the action functions end up in the
        // extension context_class.
        //
        // What is even more subtle is the *manifestation* of this
        // problem, which is linking problems with vtables.  C++
        // compilers do not explicitly check that classes declared in
        // multiple translation units have identical declarations
        // (token for token), but they *do* of course rely on them
        // being so.  That reliance shows up in the decisions
        // regarding which module has the vtable, among other places.
        // So this problem did not show up immediately, and was only
        // revealed as initially mysterious portability problems
        // (since my development toolchain happend to be fairly
        // lenient w.r.t. vtable placement).
        //
        // Therefore the new policy is that context_classes from the
        // base are *not* emitted, and consequently it is impossible
        // to inherit from them in subsequent context_classes.  The
        // user must put data/functions that are meant to be shared
        // into a common base class that is *not* the context_class
        // of any grammar or extension.
        //
        // old:
        //g.actionClasses.append(new LocString(c->body));
        //
        // new:
        g.actionClasses.deleteAll();
        g.actionClasses.append(new LocString(c->body));
      }

      ASTNEXT(TF_verbatim, v) {
        if (v->isImpl) {
          g.implVerbatim.append(new LocString(v->code));
        }
        else {
          g.verbatim.append(new LocString(v->code));
        }
      }

      ASTNEXT(TF_option, op) {
        LocString const &name = op->name;
        int value = op->value;
        bool boolVal = !!value;

        if (name.equals("useGCDefaults")) {
          g.useGCDefaults = boolVal;
        }
        else if (name.equals("defaultMergeAborts")) {
          g.defaultMergeAborts = boolVal;
        }
        else if (name.equals("shift_reduce_conflicts")) {
          g.expectedSR = value;
        }
        else if (name.equals("reduce_reduce_conflicts")) {
          g.expectedRR = value;
        }
        else if (name.equals("unreachable_nonterminals")) {
          g.expectedUNRNonterms = value;
        }
        else if (name.equals("unreachable_terminals")) {
          g.expectedUNRTerms = value;
        }
        else if (name.equals("lang_OCaml")) {
          //g.targetLang = "OCaml";
          //
          // I'm retarded.. I need to know if we're parsing ocaml *before*
          // we actually parse it, otherwise I can't skip the embedded
          // action fragments properly!
          astParseError(name, "The `lang_OCaml' option has been replaced with "
                              "the `-ocaml' command-line switch.  Please use "
                              "that instead.  (Sorry for the inconvenience.)");
        }
        else {
          astParseError(name, "unknown option name");
        }
      }

      ASTENDCASED
    }
  }
}


// map the grammar definition AST into a Grammar data structure
void astParseGrammar(Grammar &g, GrammarAST *ast)
{
  // default, empty environment
  Environment env(g);

  // handle TF_terminals
  astParseTerminals(env, *(ast->terms));

  // process all nonterminal declarations first, so while we're
  // looking at their bodies we can tell if one isn't declared
  {
    FOREACH_ASTLIST(TopForm, ast->forms, iter) {
      if (!iter.data()->isTF_nonterm()) continue;
      TF_nonterm const *nt = iter.data()->asTF_nontermC();

      // check for already declared
      if (env.nontermDecls.isMapped(nt->name)) {
        astParseError(nt->name, "nonterminal already declared");
      }

      // make the Grammar object to represent the new nonterminal
      env.g.getOrMakeNonterminal(nt->name);

      // add this decl to our running list (in the original environment)
      env.nontermDecls.add(nt->name, const_cast<TF_nonterm*>(nt));
    }
  }

  // process nonterminal bodies
  {
    FOREACH_ASTLIST(TopForm, ast->forms, iter) {
      if (!iter.data()->isTF_nonterm()) continue;
      TF_nonterm const *nt = iter.data()->asTF_nontermC();

      // new environment since it can contain a grouping construct
      // (at this very moment it actually can't because there is no syntax..)
      Environment newEnv(env);

      // parse it
      astParseNonterm(newEnv, nt);
    }
  }

  if (!g.actionClassName.str) {
    astParseError("you must specify a context class; for example:\n"
                  "  context_class Context : public UserActions {};\n");
  }

  if (env.errors) {
    astParseError("halting due to previously reported errors");
  }
}


// validate 'name'
Terminal *astParseToken(Environment &env, LocString const &name)
{
  Terminal *t = env.g.findTerminal(name);
  if (!t) {
    astParseError(name, "undeclared token");
  }
  return t;
}


// needed to ensure the GrowArray below has its values initialized
// to false when the array expands
class InitFalseBool {
public:
  bool b;
public:
  InitFalseBool() : b(false) {}
};


void astParseTerminals(Environment &env, TF_terminals const &terms)
{
  // basic declarations
  {
    int maxCode = 0;
    GrowArray<InitFalseBool> codeHasTerm(200);
    FOREACH_ASTLIST(TermDecl, terms.decls, iter) {
      TermDecl const &term = *(iter.data());

      // process the terminal declaration
      int code = term.code;
      StringRef name = term.name;
      trace("grampar") << "token: code=" << code
                       << ", name=" << name << endl;

      if (!env.g.declareToken(term.name, code, term.alias)) {
        astParseError(term.name, "token already declared");
      }

      // track what terminals have codes
      maxCode = max(code, maxCode);
      codeHasTerm.ensureIndexDoubler(code);
      codeHasTerm[code].b = true;
    }

    // fill in any gaps in the code space; this is required because
    // later analyses assume the terminal code space is dense
    SourceLoc dummyLoc(HERE_SOURCELOC);
    for (int i=0; i<maxCode; i++) {
      if (!codeHasTerm[i].b) {
        LocString dummy(dummyLoc, grammarStringTable.add(
          sm_stringc << "__dummy_filler_token" << i));
        env.g.declareToken(dummy, i, dummy);
      }
    }
  }

  // type annotations
  {                  
    FOREACH_ASTLIST(TermType, terms.types, iter) {
      TermType const &type = *(iter.data());
      trace("grampar") << "token type: name=" << type.name
                       << ", type=" << type.type << endl;

      // look up the name
      Terminal *t = astParseToken(env, type.name);
      if (t->type) {
        astParseError(type.name, "this token already has a type");
      }

      // annotate with declared type
      t->type = type.type;

      // parse the dup/del/merge spec
      astParseDDM(env, t, type.funcs);
    }
  }

  // precedence specifications
  {
    FOREACH_ASTLIST(PrecSpec, terms.prec, iter) {
      PrecSpec const &spec = *(iter.data());

      FOREACH_ASTLIST(LocString, spec.tokens, tokIter) {
        LocString const &tokName = *(tokIter.data());
        trace("grampar") << "prec: " << toString(spec.kind)
                         << " " << spec.prec << " " << tokName;

        // look up the token
        Terminal *t = astParseToken(env, tokName);
        if (t->precedence) {
          astParseError(tokName,
            sm_stringc << tokName << " already has a specified precedence");
        }

        if (spec.prec == 0) {
          // 0 means precedence isn't specified
          astParseError(tokName,
            "you can't use 0 as a precedence level, because that value "
            "is used internally to mean something else");
        }

        // apply spec
        t->precedence = spec.prec;
        t->associativity = spec.kind;
      }
    }
  }
}


void astParseDDM(Environment &env, Symbol *sym,
                 ASTList<SpecFunc> const &funcs)
{
  Terminal *term = sym->ifTerminal();
  Nonterminal *nonterm = sym->ifNonterminal();

  FOREACH_ASTLIST(SpecFunc, funcs, iter) {
    SpecFunc const &func = *(iter.data());
    int numFormals = func.formals.count();

    // decide what to do based on the name

    if (func.name.equals("dup")) {
      if (numFormals != 1) {
        astParseError(func.name, "'dup' function must have one formal parameter");
      }
      sym->dupParam = func.nthFormal(0);
      sym->dupCode = func.code;
    }

    else if (func.name.equals("del")) {
      if (numFormals == 0) {
        // not specified is ok, since it means the 'del' function
        // doesn't use its parameter
        sym->delParam = NULL;
      }
      else if (numFormals == 1) {
        sym->delParam = func.nthFormal(0);
      }
      else {
        astParseError(func.name, "'del' function must have either zero or one formal parameters");
      }
      sym->delCode = func.code;
    }

    else if (func.name.equals("merge")) {
      if (nonterm) {
        if (numFormals != 2) {
          astParseError(func.name, "'merge' function must have two formal parameters");
        }
        nonterm->mergeParam1 = func.nthFormal(0);
        nonterm->mergeParam2 = func.nthFormal(1);
        nonterm->mergeCode = func.code;
      }
      else {
        astParseError(func.name, "'merge' can only be applied to nonterminals");
      }
    }

    else if (func.name.equals("keep")) {
      if (nonterm) {
        if (numFormals != 1) {
          astParseError(func.name, "'keep' function must have one formal parameter");
        }
        nonterm->keepParam = func.nthFormal(0);
        nonterm->keepCode = func.code;
      }
      else {
        astParseError(func.name, "'keep' can only be applied to nonterminals");
      }
    }

    else if (func.name.equals("classify")) {
      if (term) {
        if (numFormals != 1) {
          astParseError(func.name, "'classify' function must have one formal parameter");
        }
        term->classifyParam = func.nthFormal(0);
        term->classifyCode = func.code;
      }
      else {
        astParseError(func.name, "'classify' can only be applied to terminals");
      }
    }

    else if (func.name.equals("maximal")) {
      if (nonterm) {
        nonterm->maximal = true;     // function body has no meaning
      }
      else {
        astParseError(func.name, "'maximal' can only be applied to nonterminals");
      }
    }

    else {
      astParseError(func.name,
        sm_stringc << "unrecognized spec function \"" << func.name << "\"");
    }
  }
}


void addDefaultTypesActions(Grammar &g, GrammarAST *ast)
{
  // language defaults
  StringRef defaultType, defaultAction;
  if (g.targetLang.equals("OCaml")) {
    defaultType = grammarStringTable.add("unit");
    defaultAction = grammarStringTable.add("()");
  }
  else /*C*/ {
    defaultType = grammarStringTable.add("void");
    defaultAction = grammarStringTable.add("return;");
  }

  // hook to allow me to force defaults everywhere (this is useful
  // when I want to try a grammar written for one language using
  // another language's core)
  bool forceDefaults = tracingSys("forceDefaultActions");

  // iterate over nonterminals
  FOREACH_ASTLIST_NC(TopForm, ast->forms, iter) {
    if (!iter.data()->isTF_nonterm()) { continue; }
    TF_nonterm *nt = iter.data()->asTF_nonterm();

    // default type
    if (forceDefaults || nt->type.isNull()) {
      nt->type.str = defaultType;
    }

    // iterate over productions
    FOREACH_ASTLIST_NC(ProdDecl, nt->productions, iter2) {
      ProdDecl *pd = iter2.data();

      // default action
      if (forceDefaults || pd->actionCode.isNull()) {
        pd->actionCode.str = defaultAction;
      }
                          
      if (forceDefaults) {
        // clear RHSElt tags, since otherwise the lack of types
        // will provoke errors; and default actions don't refer to
        // the RHSElts anyway
        StringRef empty = grammarStringTable.add("");
        FOREACH_ASTLIST_NC(RHSElt, pd->rhs, iter3) {
          ASTSWITCH(RHSElt, iter3.data()) {
            ASTCASE(RH_name, n)
              n->tag.str = empty;

            ASTNEXT(RH_sm_string, s)
              s->tag.str = empty;
            
            ASTENDCASED
          }
        }
      }
    }
  }
}


void synthesizeStartRule(Grammar &g, GrammarAST *ast)
{
  // get the first nonterminal; this is the user's start symbol
  TF_nonterm *firstNT = ast->firstNT;

  // find the name of the user's EOF token
  TermDecl const *eof = NULL;
  FOREACH_ASTLIST(TermDecl, ast->terms->decls, iter) {
    if (iter.data()->code == 0) {
      eof = iter.data();
      break;
    }
  }
  if (!eof) {
    astParseError("you have to have an EOF token, with code 0");
  }

  // build a start production
  RHSElt *rhs1 = new RH_name(LIT_STR("top").clone(), firstNT->name.clone());
  RHSElt *rhs2 = new RH_name(LIT_STR("").clone(), eof->name.clone());
  ASTList<RHSElt> *rhs = new ASTList<RHSElt>();
  rhs->append(rhs1);
  rhs->append(rhs2);
  char const *action = g.targetLang.equals("OCaml")? " top " :
                       firstNT->type.equals("void")? " return; " :
                                                     " return top; ";
  ProdDecl *startProd = new ProdDecl(rhs, LIT_STR(action).clone());

  // build an even earlier start symbol
  TF_nonterm *earlyStartNT
    = new TF_nonterm(
        LIT_STR("__EarlyStartSymbol").clone(),   // name
        firstNT->type.clone(),                   // type
        NULL,                                    // empty list of functions
        new ASTList<ProdDecl>(startProd),        // productions
        NULL                                     // subsets
      );

  // put it into the AST
  ast->forms.prepend(earlyStartNT);
}


void astParseNonterm(Environment &env, TF_nonterm const *nt)
{
  LocString const &name = nt->name;

  // get the Grammar object that represents the nonterminal
  Nonterminal *nonterm = env.g.findNonterminal(name);
  xassert(nonterm);

  nonterm->type = nt->type;

  // iterate over the productions
  FOREACH_ASTLIST(ProdDecl, nt->productions, iter) {
    astParseProduction(env, nonterm, iter.data());
  }

  // parse dup/del/merge
  astParseDDM(env, nonterm, nt->funcs);
  
  // record subsets                       
  {
    FOREACH_ASTLIST(LocString, nt->subsets, iter) {
      LocString const *ls = iter.data();
      Nonterminal *sub = env.g.findNonterminal(*ls);
      if (!sub) {
        astParseError(*ls, "nonexistent nonterminal");
      }

      // note that, since context-free language inclusion is
      // undecidable (Hopcroft/Ullman), we can't actually check that
      // the given nonterminals really are in the subset relation
      nonterm->subsets.prepend(sub);
    }
  }
}


void astParseProduction(Environment &env, Nonterminal *nonterm,
                        ProdDecl const *prodDecl)
{
  // is this the special start symbol I inserted?
  bool synthesizedStart = nonterm->name.equals("__EarlyStartSymbol");

  // build a production; use 'this' as the tag for LHS elements
  Production *prod = new Production(nonterm, "this");

  // put the code into it
  prod->action = prodDecl->actionCode;

  // deal with RHS elements
  FOREACH_ASTLIST(RHSElt, prodDecl->rhs, iter) {
    RHSElt const *n = iter.data();
    LocString symName;
    LocString symTag;
    bool isString = false;
    bool isPrec = false;

    // pull various info out of the AST node
    ASTSWITCHC(RHSElt, n) {
      ASTCASEC(RH_name, tname) {
        symName = tname->name;
        symTag = tname->tag;
      }

      ASTNEXTC(RH_sm_string, ts) {
        symName = ts->str;
        symTag = ts->tag;
        isString = true;
      }

      ASTNEXTC(RH_prec, p) {
        // apply the specified precedence
        prod->precedence = astParseToken(env, p->tokName)->precedence;

        // and require that this is the last RHS element
        iter.adv();
        if (!iter.isDone()) {
          astParseError(p->tokName,
            "precedence spec must be last thing in a production "
            "(before the action code)");
        }
        isPrec = true;
      }

      ASTENDCASECD
    }

    if (isPrec) {
      break;     // last element anyway
    }

    // see which (if either) thing this name already is
    Terminal *term = env.g.findTerminal(symName);
    Nonterminal *nonterm = env.g.findNonterminal(symName);
    xassert(!( term && nonterm ));     // better not be both!

    // syntax rules
    if (isString  &&  !term) {
      astParseError(symName, "terminals must be declared");
    }

    if (!term && !nonterm) {
      astParseErrorCont(env, symName, "undeclared symbol");

      // synthesize one anyway so we can find more errors
      nonterm = env.g.getOrMakeNonterminal(symName);
    }

    if (term && term->termIndex==0 && !synthesizedStart) {
      astParseError(symName, "you cannot use the EOF token in your rules");
    }

    if (symTag.equals("loc")) {
      // bad because loc is the name of the automatically-propagated
      // source location information
      astParseErrorCont(env, symTag, "cannot use \"loc\" as a tag");
    }

    // whenever we see a terminal, copy its precedence spec to
    // the production; thus, the last symbol appearing in the
    // production will be the one that gives the precedence
    if (term) {
      prod->precedence = term->precedence;
    }

    // decide which symbol to put in the production
    Symbol *s;
    if (nonterm) {
      s = nonterm;            // could do these two with a bitwise OR
    }                         // if I were feeling extra clever today
    else {
      s = term;
    }

    if (s->isEmptyString) {
      // "empty" is a syntactic convenience; it doesn't get
      // added to the production
    }
    else {
      // add it to the production
      prod->append(s, symTag);
    }
  }

  // after constructing the production we need to do this
  // update: no we don't -- GrammarAnalysis takes care of it (and
  // complains if we do)
  //prod->finished();

  // add production to grammar
  env.g.addProduction(prod);
}


// ----------------------- parser support ---------------------
// Bison parser calls this to get a token
int grampar_yylex(YYSTYPE *lvalp, void *parseParam)
{
  ParseParams *par = (ParseParams*)parseParam;
  GrammarLexer &lexer = par->lexer;

  int code = lexer.yylexInc();

  try {
    // yield semantic values for some things
    // note that the yielded semantic value must be consistent with
    // what is declared for these token types in grampar.y
    switch (code) {
      case TOK_INTEGER:
        lvalp->num = lexer.integerLiteral;
        break;

      case TOK_STRING:
        lvalp->str = new LocString(lexer.curLoc(), lexer.sm_stringLiteral);
        break;

      case TOK_NAME:
        lvalp->str = new LocString(lexer.curLoc(), lexer.curToken());
        break;

      case TOK_LIT_CODE:
        lvalp->str = new LocString(lexer.curLoc(), lexer.curFuncBody());
        break;

      default:
        lvalp->str = NULL;        // any attempt to use will segfault
    }
  }
  catch (xBase &x) {
    // e.g. malformed fundecl
    cout << lexer.curLocStr() << ": " << x << endl;

    // optimistically try just skipping the bad token
    return grampar_yylex(lvalp, parseParam);
  }

  return code;
}


void grampar_yyerror(char const *message, void *parseParam)
{
  ParseParams *par = (ParseParams*)parseParam;
  cout << par->lexer.curLocStr() << ": " << message << endl;
}


// ---------------------- merging -----------------------
void mergeContext(GrammarAST *base, TF_context * /*owner*/ ext)
{
  // do simple append, since the grammar parser above knows how
  // to handle multiple context classes
  base->forms.append(ext);

  #if 0
  // find 'base' context
  TF_context *baseContext = NULL;
  FOREACH_ASTLIST_NC(TopForm, base->forms, iter) {
    if (iter.data()->isTF_context()) {
      baseContext = iter.data()->asTF_context();
      break;
    }
  }

  if (!baseContext) {
    // base does not have a context class, so 'ext' becomes it
    base->forms.append(ext);
  }

  else if (baseContext->name.str == ext->name.str) {
    // same name; I'd like to append the code to what's already
    // there, but that's tricky because the location won't
    // be right..
    astParseError(ext->name, "context append not implemented");
  }

  else {
    // different name, replace the old
    base->forms.removeItem(baseContext);
    delete baseContext;
    base->forms.append(ext);
  }
  #endif // 0
}


void mergeOption(GrammarAST *base, TF_option * /*owner*/ ext)
{                    
  // find option with the same name
  FOREACH_ASTLIST_NC(TopForm, base->forms, iter) {
    if (!iter.data()->isTF_option()) continue;
    TF_option *op = iter.data()->asTF_option();
    
    if (op->name.str == ext->name.str) {
      // replace the old value
      op->value = ext->value;
      delete ext;
      return;
    }
  }

  // otherwise, just add the new option
  base->forms.append(ext);
}


void mergeTerminals(GrammarAST *base, TF_terminals * /*owner*/ ext)
{
  FOREACH_ASTLIST_NC(TopForm, base->forms, iter) {
    if (iter.data()->isTF_terminals()) {
      TF_terminals *t = iter.data()->asTF_terminals();
      
      // there's no point to changing codes, so all the
      // TermDecls just get added (collisions are detected
      // later, during AST parsing)
      t->decls.concat(ext->decls);
      
      // in fact, I'll do the same for the others, even though
      // it might make sense to do some replacement; my immediate
      // needs don't include replacement at this level
      t->types.concat(ext->types);
      t->prec.concat(ext->prec);
      
      delete ext;
      return;
    }
  }
  
  // no TF_terminals in 'base'.. unusual, but easy to handle
  base->forms.append(ext);
}


void mergeSpecFunc(TF_nonterm *base, SpecFunc * /*owner*/ ext)
{
  // find an existing spec func with the same name
  FOREACH_ASTLIST_NC(SpecFunc, base->funcs, iter) {
    SpecFunc *f = iter.data();
    if (f->name.str == ext->name) {
      // replace the old code with the extension code
      base->funcs.removeItem(f);
      delete f;
      break;
    }
  }

  // just add it
  base->funcs.append(ext);
}


bool equalRHSElt(RHSElt const *elt1, RHSElt const *elt2)
{
  if (elt1->kind() != elt2->kind()) {
    return false;
  }

  // if the RHS names a terminal, this isn't perfect because one might
  // use an alias.. but I don't have the necessary information to detect
  // that, since I haven't yet computed the associated Symbols
  if (elt1->isRH_name()) {
    return elt1->asRH_nameC()->name.str == elt2->asRH_nameC()->name.str;
  }
  if (elt1->isRH_sm_string()) {
    return elt1->asRH_sm_stringC()->str.str == elt2->asRH_sm_stringC()->str.str;
  }
  if (elt1->isRH_prec()) {
    // this means you can't change the precedence..
    return elt1->asRH_precC()->tokName.str == elt2->asRH_precC()->tokName.str;
  }

  xfailure("unknown RHSElt kind");
  return false;     // silence warning
}


bool equalRHS(ProdDecl const *prod1, ProdDecl const *prod2)
{
  if (prod1->rhs.count() != prod2->rhs.count()) {
    return false;
  }

  for (ASTListIter<RHSElt> iter1(prod1->rhs), iter2(prod2->rhs);
       !iter1.isDone(); iter1.adv(), iter2.adv()) {
    if (!equalRHSElt(iter1.data(), iter2.data())) {
      return false;
    }
  }
  return true;
}


void mergeProduction(TF_nonterm *base, ProdDecl *ext)
{
  // look for a production with an identical RHS
  FOREACH_ASTLIST_NC(ProdDecl, base->productions, iter) {
    ProdDecl *prod = iter.data();

    // check RHSs for equality
    if (equalRHS(prod, ext)) {
      // replace old with new
      base->productions.removeItem(prod);
      delete prod;
      break;
    }
  }

  // add the production
  base->productions.append(ext);
}


void mergeNonterminal(GrammarAST *base, TF_nonterm * /*owner*/ ext)
{
  // find an existing nonterminal with the same name
  TF_nonterm *exist = NULL;
  FOREACH_ASTLIST_NC(TopForm, base->forms, iter) {
    if (iter.data()->isTF_nonterm() &&
        iter.data()->asTF_nonterm()->name.str == ext->name) {
      exist = iter.data()->asTF_nonterm();
    }
  }

  if (!exist) {
    // no pre-existing, just append it
    base->forms.append(ext);
    return;
  }

  // make sure the types agree
  if (exist->type.str != ext->type) {
    astParseError(ext->type, "cannot redefine the type of a nonterminal");
  }

  // merge the spec funcs
  while (ext->funcs.isNotEmpty()) {
    mergeSpecFunc(exist, ext->funcs.removeFirst());
  }

  // merge the productions
  while (ext->productions.isNotEmpty()) {
    mergeProduction(exist, ext->productions.removeFirst());
  }

  delete ext;
}


void mergeGrammar(GrammarAST *base, GrammarAST *ext)
{
  // work through all the forms in 'ext', removing each
  // one; it will then either be added to 'base', or
  // discarded entirely
  while (ext->forms.isNotEmpty()) {
    TopForm *form = ext->forms.removeFirst();

    ASTSWITCH(TopForm, form) {
      ASTCASE(TF_context, c) {
        mergeContext(base, c);
      }

      ASTNEXT(TF_verbatim, v) {
        // verbatims simply accumulate
        base->forms.append(v);
      }

      ASTNEXT(TF_option, op) {
        mergeOption(base, op);
      }

      ASTNEXT(TF_terminals, t) {
        mergeTerminals(base, t);
      }

      ASTNEXT(TF_nonterm, n) {
        mergeNonterminal(base, n);
      }
      
      ASTDEFAULT {
        xfailure("doh");
      }
      
      ASTENDCASE
    }
  }
}


// ---------------- external interface -------------------
bool isGramlexEmbed(int code);     // defined in gramlex.lex

GrammarAST *parseGrammarFile(char const *fname, bool useML)
{
  #ifndef NDEBUG
  if (tracingSys("yydebug")) {
    yydebug = true;    // this flag goes away when NDEBUG is specified..
  }
  #endif // NDEBUG

  // open input file
  Owner<ifstream> in;
  if (fname == NULL) {
    fname = "<stdin>";
  }
  else {
    in = new ifstream(fname);
    if (!*in) {
      xsyserror("open", sm_stringc << "error opening input file " << fname);
    }
  }

  // choose embedded language              
  EmbeddedLang *embed = NULL;
  if (useML) {
    embed = new MLSubstrate;
  }
  
  // build lexer
  GrammarLexer lexer(isGramlexEmbed,
                     grammarStringTable,
                     fname,
                     in.xfr(),
                     embed);
  if (embed) {
    // install the refined error reporter
    embed->err = &lexer.altReporter;
  }

  ParseParams params(lexer);

  traceProgress() << "parsing grammar source: " << fname << endl;
  int retval = grampar_yyparse(&params);
  if (retval==0 && lexer.errors==0) {
    GrammarAST *ret = params.treeTop;

    if (tracingSys("printGrammarAST")) {
      // print AST
      cout << "AST:\n";
      ret->debugPrint(cout, 2);
    }

    return ret;
  }
  else {
    xbase("parsing finished with an error");
    return NULL;     // silence warning
  }
}


void parseGrammarAST(Grammar &g, GrammarAST *treeTop)
{
  setAnnotations(treeTop);
  
  // look at TF_options before synthesizing start rule,
  // so we can know what language is the target
  astParseOptions(g, treeTop);

  // fill in default types and actions
  addDefaultTypesActions(g, treeTop);

  // synthesize a rule "TrueStart -> Start EOF"
  synthesizeStartRule(g, treeTop);

  // parse the AST into a Grammar
  traceProgress() << "parsing grammar AST..\n";
  astParseGrammar(g, treeTop);

  // then check grammar properties; throws exception
  // on failure
  traceProgress() << "beginning grammar analysis..\n";
  g.checkWellFormed();
}


void readGrammarFile(Grammar &g, char const *fname)
{
  // make sure the tree gets deleted
  Owner<GrammarAST> treeTop(parseGrammarFile(fname, false /*useML*/));

  parseGrammarAST(g, treeTop);

  treeTop.del();

  // hmm.. I'd like to restore this functionality...
  //if (ASTNode::nodeCount > 0) {
  //  cout << "leaked " << ASTNode::nodeCount << " AST nodes\n";
  //}
}


// ----------------------- test code -----------------------
#ifdef TEST_GRAMPAR

#include "sm_bflatten.h"
#include <stdlib.h>       // system

int main(int argc, char **argv)
{
  if (argc < 2) {
    cout << "usage: " << argv[0] << " [-tr flags] filename.gr\n";
    cout << "  interesting trace flags:\n";
    cout << "    keep-tmp      do not delete the temporary files\n";
    //cout << "    cat-grammar   print the ascii rep to the screen\n";
    return 0;
  }

  traceAddSys("progress");
  TRACE_ARGS();

  bool printCode = true;

  // read the file
  Grammar g1;
  readGrammarFile(g1, argv[1]);

  // and print the grammar
  char const g1Fname[] = "grammar.g1.tmp";
  traceProgress() << "printing initial grammar to " << g1Fname << "\n";
  {
    ofstream out(g1Fname);
    g1.printSymbolTypes(out);
    g1.printProductions(out, printCode);
  }

  //if (tracingSys("cat-grammar")) {
    system("cat grammar.g1.tmp");
  //}

  // before using 'xfer' we have to tell it about the sm_string table
  flattenStrTable = &grammarStringTable;

  // write it to a binary file
  char const binFname[] = "grammar.bin.tmp";
  traceProgress() << "writing initial grammar to " << binFname << "\n";
  {
    BFlatten flat(binFname, false /*reading*/);
    g1.xfer(flat);
  }

  // read it back
  traceProgress() << "reading grammar from " << binFname << "\n";
  Grammar g2;
  {
    BFlatten flat(binFname, true /*reading*/);
    g2.xfer(flat);
  }

  // print that too
  char const g2Fname[] = "grammar.g2.tmp";
  traceProgress() << "printing just-read grammar to " << g2Fname << "\n";
  {
    ofstream out(g2Fname);
    g2.printSymbolTypes(out);
    g2.printProductions(out, printCode);
  }

  // compare the two written files
  int result = system(sm_stringc << "diff " << g1Fname << " " << g2Fname);
  if (result != 0) {
    cout << "the two ascii representations differ!!\n";
    return 4;
  }

  // remove the temp files
  if (!tracingSys("keep-tmp")) {
    remove(g1Fname);
    remove(g2Fname);
    remove(binFname);
  }

  cout << "successfully parsed, printed, wrote, and read a grammar!\n";
  return 0;
}

#endif // TEST_GRAMPAR
@h=tangler('elk/elk_grampar.tab.cpp')
@select(h)
/* A Bison parser, made from grampar.y
   by GNU bison 1.35.  */  /* tweak */

#define YYBISON 1  /* Identify Bison output.  */

# define        TOK_INTEGER     257
# define        TOK_NAME        258
# define        TOK_STRING      259
# define        TOK_LIT_CODE    260
# define        TOK_LBRACE      261
# define        TOK_RBRACE      262
# define        TOK_COLON       263
# define        TOK_SEMICOLON   264
# define        TOK_ARROW       265
# define        TOK_LPAREN      266
# define        TOK_RPAREN      267
# define        TOK_COMMA       268
# define        TOK_TERMINALS   269
# define        TOK_TOKEN       270
# define        TOK_NONTERM     271
# define        TOK_FUN 272
# define        TOK_VERBATIM    273
# define        TOK_IMPL_VERBATIM       274
# define        TOK_PRECEDENCE  275
# define        TOK_OPTION      276
# define        TOK_EXPECT      277
# define        TOK_CONTEXT_CLASS       278
# define        TOK_SUBSETS     279



#include "elk_grampar.h"
#include "elk_gramast.ast.gen.h"
#include "ast_gramlex.h"
#include "sm_owner.h"

#include <stdlib.h>         // malloc, free
#include <iostream.h>       // cout

// enable debugging the parser
#ifndef NDEBUG
  #define YYDEBUG 1
#endif

// name of extra parameter to yylex
#define YYLEX_PARAM parseParam

// make it call my yylex
#define yylex(lv, param) grampar_yylex(lv, param)

// Bison calls yyerror(msg) on error; we need the extra
// parameter too, so the macro shoehorns it in there
#define yyerror(msg) grampar_yyerror(msg, YYPARSE_PARAM)

// rename the externally-visible parsing routine to make it
// specific to this instance, so multiple bison-generated
// parsers can coexist
#define yyparse grampar_yyparse


// grab the parameter
#define PARAM ((ParseParams*)parseParam)

// return a locsm_string for 'str' with no location information
#define noloc(str)                                                    \
  new LocString(SL_UNKNOWN,      /* unknown location */               \
                PARAM->lexer.strtable.add(str))
                
// locsm_string for NULL, with no location
#define nolocNULL()                                                   \
  new LocString(SL_UNKNOWN, NULL)

// return a locsm_string with same location info as something else
// (passed as a pointer to a SourceLocation)
#define sameloc(otherLoc, str)                                        \
  new LocString(otherLoc->loc, PARAM->lexer.strtable.add(str))

// interpret the word into an associativity kind specification
AssocKind whichKind(LocString * /*owner*/ kind);


#ifndef YYSTYPE
typedef union YYSTYPE {
  int num;
  LocString *str;

  ASTList<TopForm> *topFormList;
  TopForm *topForm;

  ASTList<TermDecl> *termDecls;
  TermDecl *termDecl;
  ASTList<TermType> *termTypes;
  TermType *termType;
  ASTList<PrecSpec> *precSpecs;

  ASTList<SpecFunc> *specFuncs;
  SpecFunc *specFunc;
  ASTList<LocString> *sm_stringList;

  ASTList<ProdDecl> *prodDecls;
  ProdDecl *prodDecl;
  ASTList<RHSElt> *rhsList;
  RHSElt *rhsElt;
} yystype;
# define YYSTYPE yystype
# define YYSTYPE_IS_TRIVIAL 1
#endif
#ifndef YYDEBUG
# define YYDEBUG 0
#endif



#define YYFINAL         94
#define YYFLAG          -32768
#define YYNTBASE        26

/* YYTRANSLATE(YYLEX) -- Bison token number corresponding to YYLEX. */
#define YYTRANSLATE(x) ((unsigned)(x) <= 279 ? yytranslate[x] : 53)

/* YYTRANSLATE[YYLEX] -- Bison token number corresponding to YYLEX. */
static const char yytranslate[] =
{
       0,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     2,     2,     2,     2,
       2,     2,     2,     2,     2,     2,     1,     3,     4,     5,
       6,     7,     8,     9,    10,    11,    12,    13,    14,    15,
      16,    17,    18,    19,    20,    21,    22,    23,    24,    25
};

#if YYDEBUG
static const short yyprhs[] =
{
       0,     0,     2,     3,     6,     8,    10,    12,    14,    16,
      20,    23,    26,    30,    35,    42,    43,    46,    51,    57,
      59,    60,    61,    64,    69,    76,    77,    82,    83,    89,
      90,    93,    95,    97,    98,   101,   108,   109,   111,   113,
     117,   122,   131,   132,   135,   139,   141,   143,   144,   147,
     149,   153,   155,   159,   164,   165
};
static const short yyrhs[] =
{
      27,     0,     0,    27,    28,     0,    29,     0,    30,     0,
      31,     0,    32,     0,    46,     0,    24,     6,    10,     0,
      19,     6,     0,    20,     6,     0,    22,     4,    10,     0,
      22,     4,     3,    10,     0,    15,     7,    33,    36,    38,
       8,     0,     0,    33,    34,     0,     3,     9,     4,    10,
       0,     3,     9,     4,     5,    10,     0,     6,     0,     0,
       0,    36,    37,     0,    16,    35,     4,    10,     0,    16,
      35,     4,     7,    42,     8,     0,     0,    21,     7,    39,
       8,     0,     0,    39,     4,     3,    40,    10,     0,     0,
      40,    41,     0,     4,     0,     5,     0,     0,    42,    43,
       0,    18,     4,    12,    44,    13,     6,     0,     0,    45,
       0,     4,     0,    45,    14,     4,     0,    17,    35,     4,
      48,     0,    17,    35,     4,     7,    42,    47,    52,     8,
       0,     0,    47,    48,     0,    11,    50,    49,     0,     6,
       0,    10,     0,     0,    50,    51,     0,     4,     0,     4,
       9,     4,     0,     5,     0,     4,     9,     5,     0,    21,
      12,    41,    13,     0,     0,    25,    45,    10,     0
};

#endif

#if YYDEBUG
/* YYRLINE[YYN] -- source line where rule number YYN was defined. */
static const short yyrline[] =
{
       0,   158,   163,   164,   168,   169,   170,   171,   172,   176,
     181,   182,   187,   188,   199,   204,   205,   213,   215,   220,
     221,   225,   226,   230,   232,   237,   238,   242,   244,   249,
     250,   254,   255,   261,   262,   266,   271,   272,   276,   277,
     288,   291,   296,   297,   301,   305,   306,   310,   311,   320,
     322,   324,   326,   328,   333,   334
};
#endif


#if (YYDEBUG) || defined YYERROR_VERBOSE

/* YYTNAME[TOKEN_NUM] -- String name of the token TOKEN_NUM. */
static const char *const yytname[] =
{
  "$", "error", "$undefined.", "TOK_INTEGER", "TOK_NAME", "TOK_STRING", 
  "TOK_LIT_CODE", "\"{\"", "\"}\"", "\":\"", "\";\"", "\"->\"", "\"(\"", 
  "\")\"", "\",\"", "\"terminals\"", "\"token\"", "\"nonterm\"", 
  "\"fun\"", "\"verbatim\"", "\"impl_verbatim\"", "\"precedence\"", 
  "\"option\"", "\"expect\"", "\"context_class\"", "\"subsets\"", 
  "StartSymbol", "TopFormList", "TopForm", "ContextClass", "Verbatim", 
  "Option", "Terminals", "TermDecls", "TerminalDecl", "Type", "TermTypes", 
  "TermType", "Precedence", "PrecSpecs", "NameOrStringList", 
  "NameOrString", "SpecFuncs", "SpecFunc", "FormalsOpt", "Formals", 
  "Nonterminal", "Productions", "Production", "Action", "RHS", "RHSElt", 
  "Subsets", 0
};
#endif

/* YYR1[YYN] -- Symbol number of symbol that rule YYN derives. */
static const short yyr1[] =
{
       0,    26,    27,    27,    28,    28,    28,    28,    28,    29,
      30,    30,    31,    31,    32,    33,    33,    34,    34,    35,
      35,    36,    36,    37,    37,    38,    38,    39,    39,    40,
      40,    41,    41,    42,    42,    43,    44,    44,    45,    45,
      46,    46,    47,    47,    48,    49,    49,    50,    50,    51,
      51,    51,    51,    51,    52,    52
};

/* YYR2[YYN] -- Number of symbols composing right hand side of rule YYN. */
static const short yyr2[] =
{
       0,     1,     0,     2,     1,     1,     1,     1,     1,     3,
       2,     2,     3,     4,     6,     0,     2,     4,     5,     1,
       0,     0,     2,     4,     6,     0,     4,     0,     5,     0,
       2,     1,     1,     0,     2,     6,     0,     1,     1,     3,
       4,     8,     0,     2,     3,     1,     1,     0,     2,     1,
       3,     1,     3,     4,     0,     3
};

/* YYDEFACT[S] -- default rule to reduce with in state S when YYTABLE
   doesn't specify something else to do.  Zero means the default is an
   error. */
static const short yydefact[] =
{
       2,     1,     0,    20,     0,     0,     0,     0,     3,     4,
       5,     6,     7,     8,    15,    19,     0,    10,    11,     0,
       0,    21,     0,     0,    12,     9,     0,    16,    25,    33,
      47,    40,    13,     0,    20,     0,    22,     0,    42,     0,
       0,     0,    27,    14,     0,    34,    54,    49,    51,    45,
      46,     0,    44,    48,     0,    17,     0,     0,     0,     0,
      43,     0,     0,     0,    18,    33,    23,     0,    26,    36,
      38,     0,    41,    50,    52,    31,    32,     0,     0,    29,
       0,    37,    55,     0,    53,    24,     0,     0,    39,    28,
      30,    35,     0,     0,     0
};

static const short yydefgoto[] =
{
      92,     1,     8,     9,    10,    11,    12,    21,    27,    16,
      28,    36,    37,    57,    86,    77,    38,    45,    80,    71,
      13,    46,    31,    52,    39,    53,    61
};

static const short yypact[] =
{
  -32768,   -10,     4,    33,    34,    35,    38,    37,-32768,-32768,
  -32768,-32768,-32768,-32768,-32768,-32768,    40,-32768,-32768,     5,
      13,    42,    19,    28,-32768,-32768,    39,-32768,     0,-32768,
  -32768,-32768,-32768,    43,    33,    44,-32768,    41,    36,    -4,
      17,    46,-32768,-32768,    48,-32768,    -7,    47,-32768,-32768,
  -32768,    45,-32768,-32768,    49,-32768,    22,    20,    50,    51,
  -32768,    52,    29,    32,-32768,-32768,-32768,    55,-32768,    51,
  -32768,    21,-32768,-32768,-32768,-32768,-32768,    53,    -5,-32768,
      54,    56,-32768,    57,-32768,-32768,    15,    58,-32768,-32768,
  -32768,-32768,    63,    65,-32768
};

static const short yypgoto[] =
{
  -32768,-32768,-32768,-32768,-32768,-32768,-32768,-32768,-32768,    12,
  -32768,-32768,-32768,-32768,-32768,   -33,     3,-32768,-32768,     2,
  -32768,-32768,    23,-32768,-32768,-32768,-32768
};


#define YYLAST          71


static const short yytable[] =
{
      47,    48,    49,    85,    30,     2,    50,     3,    23,     4,
       5,    14,     6,    44,     7,    24,    34,    51,    59,    75,
      76,    35,    54,    25,    67,    89,    29,    55,    68,    65,
      30,    82,    66,    73,    74,    83,    75,    76,    32,    15,
      17,    18,    19,    20,    22,    26,    41,    40,    33,    43,
      56,    42,    58,    90,    44,    70,    62,    63,    79,    64,
      72,    88,    69,    93,    91,    94,    84,    87,    78,    60,
      83,    81
};

static const short yycheck[] =
{
       4,     5,     6,     8,    11,    15,    10,    17,     3,    19,
      20,     7,    22,    18,    24,    10,    16,    21,    25,     4,
       5,    21,     5,    10,     4,    10,     7,    10,     8,     7,
      11,    10,    10,     4,     5,    14,     4,     5,    10,     6,
       6,     6,     4,     6,     4,     3,    34,     4,     9,     8,
       4,     7,     4,    86,    18,     4,     9,    12,     3,    10,
       8,     4,    12,     0,     6,     0,    13,    13,    65,    46,
      14,    69
};
#define YYPURE 1

/* -*-C-*-  Note some compilers choke on comments on `#line' lines.  */

/* Skeleton output parser for bison,

   Copyright (C) 1984, 1989, 1990, 2000, 2001, 2002 Free Software
   Foundation, Inc.

   This program is free software; you can redistribute it and/or modify
   it under the terms of the GNU General Public License as published by
   the Free Software Foundation; either version 2, or (at your option)
   any later version.

   This program is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
   GNU General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with this program; if not, write to the Free Software
   Foundation, Inc., 59 Temple Place - Suite 330,
   Boston, MA 02111-1307, USA.  */

/* As a special exception, when this file is copied by Bison into a
   Bison output file, you may use that output file without restriction.
   This special exception was added by the Free Software Foundation
   in version 1.24 of Bison.  */

/* This is the parser code that is written into each bison parser when
   the %semantic_parser declaration is not specified in the grammar.
   It was written by Richard Stallman by simplifying the hairy parser
   used when %semantic_parser is specified.  */

/* All symbols defined below should begin with yy or YY, to avoid
   infringing on user name space.  This should be done even for local
   variables, as they might otherwise be expanded by user macros.
   There are some unavoidable exceptions within include files to
   define necessary library symbols; they are noted "INFRINGES ON
   USER NAME SPACE" below.  */

#if ! defined (yyoverflow) || defined (YYERROR_VERBOSE)

/* The parser invokes alloca or malloc; define the necessary symbols.  */

# if YYSTACK_USE_ALLOCA
#  define YYSTACK_ALLOC alloca
# else
#  ifndef YYSTACK_USE_ALLOCA
#   if defined (alloca) || defined (_ALLOCA_H)
#    define YYSTACK_ALLOC alloca
#   else
#    ifdef __GNUC__
#     define YYSTACK_ALLOC __builtin_alloca
#    endif
#   endif
#  endif
# endif

# ifdef YYSTACK_ALLOC
   /* Pacify GCC's `empty if-body' warning. */
#  define YYSTACK_FREE(Ptr) do { /* empty */; } while (0)
# else
#  if defined (__STDC__) || defined (__cplusplus)
#   include <stdlib.h> /* INFRINGES ON USER NAME SPACE */
#   define YYSIZE_T size_t
#  endif
#  define YYSTACK_ALLOC malloc
#  define YYSTACK_FREE free
# endif
#endif /* ! defined (yyoverflow) || defined (YYERROR_VERBOSE) */


#if (! defined (yyoverflow) \
     && (! defined (__cplusplus) \
         || (YYLTYPE_IS_TRIVIAL && YYSTYPE_IS_TRIVIAL)))

/* A type that is properly aligned for any stack member.  */
union yyalloc
{
  short yyss;
  YYSTYPE yyvs;
# if YYLSP_NEEDED
  YYLTYPE yyls;
# endif
};

/* The size of the maximum gap between one aligned stack and the next.  */
# define YYSTACK_GAP_MAX (sizeof (union yyalloc) - 1)

/* The size of an array large to enough to hold all stacks, each with
   N elements.  */
# if YYLSP_NEEDED
#  define YYSTACK_BYTES(N) \
     ((N) * (sizeof (short) + sizeof (YYSTYPE) + sizeof (YYLTYPE))      \
      + 2 * YYSTACK_GAP_MAX)
# else
#  define YYSTACK_BYTES(N) \
     ((N) * (sizeof (short) + sizeof (YYSTYPE))                         \
      + YYSTACK_GAP_MAX)
# endif

/* Copy COUNT objects from FROM to TO.  The source and destination do
   not overlap.  */
# ifndef YYCOPY
#  if 1 < __GNUC__
#   define YYCOPY(To, From, Count) \
      __builtin_memcpy (To, From, (Count) * sizeof (*(From)))
#  else
#   define YYCOPY(To, From, Count)              \
      do                                        \
        {                                       \
          register YYSIZE_T yyi;                \
          for (yyi = 0; yyi < (Count); yyi++)   \
            (To)[yyi] = (From)[yyi];            \
        }                                       \
      while (0)
#  endif
# endif

/* Relocate STACK from its old location to the new one.  The
   local variables YYSIZE and YYSTACKSIZE give the old and new number of
   elements in the stack, and YYPTR gives the new location of the
   stack.  Advance YYPTR to a properly aligned location for the next
   stack.  */
# define YYSTACK_RELOCATE(Stack)                                        \
    do                                                                  \
      {                                                                 \
        YYSIZE_T yynewbytes;                                            \
        YYCOPY (&yyptr->Stack, Stack, yysize);                          \
        Stack = &yyptr->Stack;                                          \
        yynewbytes = yystacksize * sizeof (*Stack) + YYSTACK_GAP_MAX;   \
        yyptr += yynewbytes / sizeof (*yyptr);                          \
      }                                                                 \
    while (0)

#endif


#if ! defined (YYSIZE_T) && defined (__SIZE_TYPE__)
# define YYSIZE_T __SIZE_TYPE__
#endif
#if ! defined (YYSIZE_T) && defined (size_t)
# define YYSIZE_T size_t
#endif
#if ! defined (YYSIZE_T)
# if defined (__STDC__) || defined (__cplusplus)
#  include <stddef.h> /* INFRINGES ON USER NAME SPACE */
#  define YYSIZE_T size_t
# endif
#endif
#if ! defined (YYSIZE_T)
# define YYSIZE_T unsigned int
#endif

#define yyerrok         (yyerrstatus = 0)
#define yyclearin       (yychar = YYEMPTY)
#define YYEMPTY         -2
#define YYEOF           0
#define YYACCEPT        goto yyacceptlab
#define YYABORT         goto yyabortlab
#define YYERROR         goto yyerrlab1
/* Like YYERROR except do call yyerror.  This remains here temporarily
   to ease the transition to the new meaning of YYERROR, for GCC.
   Once GCC version 2 has supplanted version 1, this can go.  */
#define YYFAIL          goto yyerrlab
#define YYRECOVERING()  (!!yyerrstatus)
#define YYBACKUP(Token, Value)                                  \
do                                                              \
  if (yychar == YYEMPTY && yylen == 1)                          \
    {                                                           \
      yychar = (Token);                                         \
      yylval = (Value);                                         \
      yychar1 = YYTRANSLATE (yychar);                           \
      YYPOPSTACK;                                               \
      goto yybackup;                                            \
    }                                                           \
  else                                                          \
    {                                                           \
      yyerror ("syntax error: cannot back up");                 \
      YYERROR;                                                  \
    }                                                           \
while (0)

#define YYTERROR        1
#define YYERRCODE       256


/* YYLLOC_DEFAULT -- Compute the default location (before the actions
   are run).

   When YYLLOC_DEFAULT is run, CURRENT is set the location of the
   first token.  By default, to implement support for ranges, extend
   its range to the last symbol.  */

#ifndef YYLLOC_DEFAULT
# define YYLLOC_DEFAULT(Current, Rhs, N)        \
   Current.last_line   = Rhs[N].last_line;      \
   Current.last_column = Rhs[N].last_column;
#endif


/* YYLEX -- calling `yylex' with the right arguments.  */

#if YYPURE
# if YYLSP_NEEDED
#  ifdef YYLEX_PARAM
#   define YYLEX                yylex (&yylval, &yylloc, YYLEX_PARAM)
#  else
#   define YYLEX                yylex (&yylval, &yylloc)
#  endif
# else /* !YYLSP_NEEDED */
#  ifdef YYLEX_PARAM
#   define YYLEX                yylex (&yylval, YYLEX_PARAM)
#  else
#   define YYLEX                yylex (&yylval)
#  endif
# endif /* !YYLSP_NEEDED */
#else /* !YYPURE */
# define YYLEX                  yylex ()
#endif /* !YYPURE */


/* Enable debugging if requested.  */
#if YYDEBUG

# ifndef YYFPRINTF
#  include <stdio.h> /* INFRINGES ON USER NAME SPACE */
#  define YYFPRINTF fprintf
# endif

# define YYDPRINTF(Args)                        \
do {                                            \
  if (yydebug)                                  \
    YYFPRINTF Args;                             \
} while (0)
/* Nonzero means print parse trace.  It is left uninitialized so that
   multiple parsers can coexist.  */
int yydebug;
#else /* !YYDEBUG */
# define YYDPRINTF(Args)
#endif /* !YYDEBUG */

/* YYINITDEPTH -- initial size of the parser's stacks.  */
#ifndef YYINITDEPTH
# define YYINITDEPTH 200
#endif

/* YYMAXDEPTH -- maximum size the stacks can grow to (effective only
   if the built-in stack extension method is used).

   Do not make this value too large; the results are undefined if
   SIZE_MAX < YYSTACK_BYTES (YYMAXDEPTH)
   evaluated with infinite-precision integer arithmetic.  */

#if YYMAXDEPTH == 0
# undef YYMAXDEPTH
#endif

#ifndef YYMAXDEPTH
# define YYMAXDEPTH 10000
#endif

#ifdef YYERROR_VERBOSE

# ifndef yystrlen
#  if defined (__GLIBC__) && defined (_STRING_H)
#   define yystrlen strlen
#  else
/* Return the length of YYSTR.  */
static YYSIZE_T
#   if defined (__STDC__) || defined (__cplusplus)
yystrlen (const char *yystr)
#   else
yystrlen (yystr)
     const char *yystr;
#   endif
{
  register const char *yys = yystr;

  while (*yys++ != '\0')
    continue;

  return yys - yystr - 1;
}
#  endif
# endif

# ifndef yystpcpy
#  if defined (__GLIBC__) && defined (_STRING_H) && defined (_GNU_SOURCE)
#   define yystpcpy stpcpy
#  else
/* Copy YYSRC to YYDEST, returning the address of the terminating '\0' in
   YYDEST.  */
static char *
#   if defined (__STDC__) || defined (__cplusplus)
yystpcpy (char *yydest, const char *yysrc)
#   else
yystpcpy (yydest, yysrc)
     char *yydest;
     const char *yysrc;
#   endif
{
  register char *yyd = yydest;
  register const char *yys = yysrc;

  while ((*yyd++ = *yys++) != '\0')
    continue;

  return yyd - 1;
}
#  endif
# endif
#endif



/* The user can define YYPARSE_PARAM as the name of an argument to be passed
   into yyparse.  The argument should have type void *.
   It should actually point to an object.
   Grammar actions can access the variable by casting it
   to the proper pointer type.  */

#ifdef YYPARSE_PARAM
# if defined (__STDC__) || defined (__cplusplus)
#  define YYPARSE_PARAM_ARG void *YYPARSE_PARAM
#  define YYPARSE_PARAM_DECL
# else
#  define YYPARSE_PARAM_ARG YYPARSE_PARAM
#  define YYPARSE_PARAM_DECL void *YYPARSE_PARAM;
# endif
#else /* !YYPARSE_PARAM */
# define YYPARSE_PARAM_ARG
# define YYPARSE_PARAM_DECL
#endif /* !YYPARSE_PARAM */

/* Prevent warning if -Wstrict-prototypes.  */
#ifdef __GNUC__
# ifdef YYPARSE_PARAM
int yyparse (void *);
# else
int yyparse (void);
# endif
#endif

/* YY_DECL_VARIABLES -- depending whether we use a pure parser,
   variables are global, or local to YYPARSE.  */

#define YY_DECL_NON_LSP_VARIABLES                       \
/* The lookahead symbol.  */                            \
int yychar;                                             \
                                                        \
/* The semantic value of the lookahead symbol. */       \
YYSTYPE yylval;                                         \
                                                        \
/* Number of parse errors so far.  */                   \
int yynerrs;

#if YYLSP_NEEDED
# define YY_DECL_VARIABLES                      \
YY_DECL_NON_LSP_VARIABLES                       \
                                                \
/* Location data for the lookahead symbol.  */  \
YYLTYPE yylloc;
#else
# define YY_DECL_VARIABLES                      \
YY_DECL_NON_LSP_VARIABLES
#endif


/* If nonreentrant, generate the variables here. */

#if !YYPURE
YY_DECL_VARIABLES
#endif  /* !YYPURE */

int
yyparse (YYPARSE_PARAM_ARG)
     YYPARSE_PARAM_DECL
{
  /* If reentrant, generate the variables here. */
#if YYPURE
  YY_DECL_VARIABLES
#endif  /* !YYPURE */

  register int yystate;
  register int yyn;
  int yyresult;
  /* Number of tokens to shift before error messages enabled.  */
  int yyerrstatus;
  /* Lookahead token as an internal (translated) token number.  */
  int yychar1 = 0;

  /* Three stacks and their tools:
     `yyss': related to states,
     `yyvs': related to semantic values,
     `yyls': related to locations.

     Refer to the stacks thru separate pointers, to allow yyoverflow
     to reallocate them elsewhere.  */

  /* The state stack. */
  short yyssa[YYINITDEPTH];
  short *yyss = yyssa;
  register short *yyssp;

  /* The semantic value stack.  */
  YYSTYPE yyvsa[YYINITDEPTH];
  YYSTYPE *yyvs = yyvsa;
  register YYSTYPE *yyvsp;

#if YYLSP_NEEDED
  /* The location stack.  */
  YYLTYPE yylsa[YYINITDEPTH];
  YYLTYPE *yyls = yylsa;
  YYLTYPE *yylsp;
#endif

#if YYLSP_NEEDED
# define YYPOPSTACK   (yyvsp--, yyssp--, yylsp--)
#else
# define YYPOPSTACK   (yyvsp--, yyssp--)
#endif

  YYSIZE_T yystacksize = YYINITDEPTH;


  /* The variables used to return semantic value and location from the
     action routines.  */
  YYSTYPE yyval;
#if YYLSP_NEEDED
  YYLTYPE yyloc;
#endif

  /* When reducing, the number of symbols on the RHS of the reduced
     rule. */
  int yylen;

  YYDPRINTF ((stderr, "Starting parse\n"));

  yystate = 0;
  yyerrstatus = 0;
  yynerrs = 0;
  yychar = YYEMPTY;             /* Cause a token to be read.  */

  /* Initialize stack pointers.
     Waste one element of value and location stack
     so that they stay on the same level as the state stack.
     The wasted elements are never initialized.  */

  yyssp = yyss;
  yyvsp = yyvs;
#if YYLSP_NEEDED
  yylsp = yyls;
#endif
  goto yysetstate;

/*------------------------------------------------------------.
| yynewstate -- Push a new state, which is found in yystate.  |
`------------------------------------------------------------*/
 yynewstate:
  /* In all cases, when you get here, the value and location stacks
     have just been pushed. so pushing a state here evens the stacks.
     */
  yyssp++;

 yysetstate:
  *yyssp = yystate;

  if (yyssp >= yyss + yystacksize - 1)
    {
      /* Get the current used size of the three stacks, in elements.  */
      YYSIZE_T yysize = yyssp - yyss + 1;

#ifdef yyoverflow
      {
        /* Give user a chance to reallocate the stack. Use copies of
           these so that the &'s don't force the real ones into
           memory.  */
        YYSTYPE *yyvs1 = yyvs;
        short *yyss1 = yyss;

        /* Each stack pointer address is followed by the size of the
           data in use in that stack, in bytes.  */
# if YYLSP_NEEDED
        YYLTYPE *yyls1 = yyls;
        /* This used to be a conditional around just the two extra args,
           but that might be undefined if yyoverflow is a macro.  */
        yyoverflow ("parser stack overflow",
                    &yyss1, yysize * sizeof (*yyssp),
                    &yyvs1, yysize * sizeof (*yyvsp),
                    &yyls1, yysize * sizeof (*yylsp),
                    &yystacksize);
        yyls = yyls1;
# else
        yyoverflow ("parser stack overflow",
                    &yyss1, yysize * sizeof (*yyssp),
                    &yyvs1, yysize * sizeof (*yyvsp),
                    &yystacksize);
# endif
        yyss = yyss1;
        yyvs = yyvs1;
      }
#else /* no yyoverflow */
# ifndef YYSTACK_RELOCATE
      goto yyoverflowlab;
# else
      /* Extend the stack our own way.  */
      if (yystacksize >= YYMAXDEPTH)
        goto yyoverflowlab;
      yystacksize *= 2;
      if (yystacksize > YYMAXDEPTH)
        yystacksize = YYMAXDEPTH;

      {
        short *yyss1 = yyss;
        union yyalloc *yyptr =
          (union yyalloc *) YYSTACK_ALLOC (YYSTACK_BYTES (yystacksize));
        if (! yyptr)
          goto yyoverflowlab;
        YYSTACK_RELOCATE (yyss);
        YYSTACK_RELOCATE (yyvs);
# if YYLSP_NEEDED
        YYSTACK_RELOCATE (yyls);
# endif
# undef YYSTACK_RELOCATE
        if (yyss1 != yyssa)
          YYSTACK_FREE (yyss1);
      }
# endif
#endif /* no yyoverflow */

      yyssp = yyss + yysize - 1;
      yyvsp = yyvs + yysize - 1;
#if YYLSP_NEEDED
      yylsp = yyls + yysize - 1;
#endif

      YYDPRINTF ((stderr, "Stack size increased to %lu\n",
                  (unsigned long int) yystacksize));

      if (yyssp >= yyss + yystacksize - 1)
        YYABORT;
    }

  YYDPRINTF ((stderr, "Entering state %d\n", yystate));

  goto yybackup;


/*-----------.
| yybackup.  |
`-----------*/
yybackup:

/* Do appropriate processing given the current state.  */
/* Read a lookahead token if we need one and don't already have one.  */
/* yyresume: */

  /* First try to decide what to do without reference to lookahead token.  */

  yyn = yypact[yystate];
  if (yyn == YYFLAG)
    goto yydefault;

  /* Not known => get a lookahead token if don't already have one.  */

  /* yychar is either YYEMPTY or YYEOF
     or a valid token in external form.  */

  if (yychar == YYEMPTY)
    {
      YYDPRINTF ((stderr, "Reading a token: "));
      yychar = YYLEX;
    }

  /* Convert token to internal form (in yychar1) for indexing tables with */

  if (yychar <= 0)              /* This means end of input. */
    {
      yychar1 = 0;
      yychar = YYEOF;           /* Don't call YYLEX any more */

      YYDPRINTF ((stderr, "Now at end of input.\n"));
    }
  else
    {
      yychar1 = YYTRANSLATE (yychar);

#if YYDEBUG
     /* We have to keep this `#if YYDEBUG', since we use variables
        which are defined only if `YYDEBUG' is set.  */
      if (yydebug)
        {
          YYFPRINTF (stderr, "Next token is %d (%s",
                     yychar, yytname[yychar1]);
          /* Give the individual parser a way to print the precise
             meaning of a token, for further debugging info.  */
# ifdef YYPRINT
          YYPRINT (stderr, yychar, yylval);
# endif
          YYFPRINTF (stderr, ")\n");
        }
#endif
    }

  yyn += yychar1;
  if (yyn < 0 || yyn > YYLAST || yycheck[yyn] != yychar1)
    goto yydefault;

  yyn = yytable[yyn];

  /* yyn is what to do for this token type in this state.
     Negative => reduce, -yyn is rule number.
     Positive => shift, yyn is new state.
       New state is final state => don't bother to shift,
       just return success.
     0, or most negative number => error.  */

  if (yyn < 0)
    {
      if (yyn == YYFLAG)
        goto yyerrlab;
      yyn = -yyn;
      goto yyreduce;
    }
  else if (yyn == 0)
    goto yyerrlab;

  if (yyn == YYFINAL)
    YYACCEPT;

  /* Shift the lookahead token.  */
  YYDPRINTF ((stderr, "Shifting token %d (%s), ",
              yychar, yytname[yychar1]));

  /* Discard the token being shifted unless it is eof.  */
  if (yychar != YYEOF)
    yychar = YYEMPTY;

  *++yyvsp = yylval;
#if YYLSP_NEEDED
  *++yylsp = yylloc;
#endif

  /* Count tokens shifted since error; after three, turn off error
     status.  */
  if (yyerrstatus)
    yyerrstatus--;

  yystate = yyn;
  goto yynewstate;


/*-----------------------------------------------------------.
| yydefault -- do the default action for the current state.  |
`-----------------------------------------------------------*/
yydefault:
  yyn = yydefact[yystate];
  if (yyn == 0)
    goto yyerrlab;
  goto yyreduce;


/*-----------------------------.
| yyreduce -- Do a reduction.  |
`-----------------------------*/
yyreduce:
  /* yyn is the number of a rule to reduce with.  */
  yylen = yyr2[yyn];

  /* If YYLEN is nonzero, implement the default value of the action:
     `$$ = $1'.

     Otherwise, the following line sets YYVAL to the semantic value of
     the lookahead token.  This behavior is undocumented and Bison
     users should not rely upon it.  Assigning to YYVAL
     unconditionally makes the parser a bit smaller, and it avoids a
     GCC warning that YYVAL may be used uninitialized.  */
  yyval = yyvsp[1-yylen];

#if YYLSP_NEEDED
  /* Similarly for the default location.  Let the user run additional
     commands if for instance locations are ranges.  */
  yyloc = yylsp[1-yylen];
  YYLLOC_DEFAULT (yyloc, (yylsp - yylen), yylen);
#endif

#if YYDEBUG
  /* We have to keep this `#if YYDEBUG', since we use variables which
     are defined only if `YYDEBUG' is set.  */
  if (yydebug)
    {
      int yyi;

      YYFPRINTF (stderr, "Reducing via rule %d (line %d), ",
                 yyn, yyrline[yyn]);

      /* Print the symbols being reduced, and their result.  */
      for (yyi = yyprhs[yyn]; yyrhs[yyi] > 0; yyi++)
        YYFPRINTF (stderr, "%s ", yytname[yyrhs[yyi]]);
      YYFPRINTF (stderr, " -> %s\n", yytname[yyr1[yyn]]);
    }
#endif

  switch (yyn) {

case 1:
{ ((ParseParams*)parseParam)->treeTop = new GrammarAST(yyvsp[0].topFormList); yyval.num=0; ;
    break;}
case 2:
{ yyval.topFormList = new ASTList<TopForm>; ;
    break;}
case 3:
{ (yyval.topFormList=yyvsp[-1].topFormList)->append(yyvsp[0].topForm); ;
    break;}
case 4:
{ yyval.topForm = yyvsp[0].topForm; ;
    break;}
case 5:
{ yyval.topForm = yyvsp[0].topForm; ;
    break;}
case 6:
{ yyval.topForm = yyvsp[0].topForm; ;
    break;}
case 7:
{ yyval.topForm = yyvsp[0].topForm; ;
    break;}
case 8:
{ yyval.topForm = yyvsp[0].topForm; ;
    break;}
case 9:
{ yyval.topForm = new TF_context(yyvsp[-1].str); ;
    break;}
case 10:
{ yyval.topForm = new TF_verbatim(false, yyvsp[0].str); ;
    break;}
case 11:
{ yyval.topForm = new TF_verbatim(true, yyvsp[0].str); ;
    break;}
case 12:
{ yyval.topForm = new TF_option(yyvsp[-1].str, 1); ;
    break;}
case 13:
{ yyval.topForm = new TF_option(yyvsp[-2].str, yyvsp[-1].num); ;
    break;}
case 14:
{ yyval.topForm = new TF_terminals(yyvsp[-3].termDecls, yyvsp[-2].termTypes, yyvsp[-1].precSpecs); ;
    break;}
case 15:
{ yyval.termDecls = new ASTList<TermDecl>; ;
    break;}
case 16:
{ (yyval.termDecls=yyvsp[-1].termDecls)->append(yyvsp[0].termDecl); ;
    break;}
case 17:
{ yyval.termDecl = new TermDecl(yyvsp[-3].num, yyvsp[-1].str, sameloc(yyvsp[-1].str, "")); ;
    break;}
case 18:
{ yyval.termDecl = new TermDecl(yyvsp[-4].num, yyvsp[-2].str, yyvsp[-1].str); ;
    break;}
case 19:
{ yyval.str = yyvsp[0].str; ;
    break;}
case 20:
{ yyval.str = nolocNULL(); ;
    break;}
case 21:
{ yyval.termTypes = new ASTList<TermType>; ;
    break;}
case 22:
{ (yyval.termTypes=yyvsp[-1].termTypes)->append(yyvsp[0].termType); ;
    break;}
case 23:
{ yyval.termType = new TermType(yyvsp[-1].str, yyvsp[-2].str, new ASTList<SpecFunc>); ;
    break;}
case 24:
{ yyval.termType = new TermType(yyvsp[-3].str, yyvsp[-4].str, yyvsp[-1].specFuncs); ;
    break;}
case 25:
{ yyval.precSpecs = new ASTList<PrecSpec>; ;
    break;}
case 26:
{ yyval.precSpecs = yyvsp[-1].precSpecs; ;
    break;}
case 27:
{ yyval.precSpecs = new ASTList<PrecSpec>; ;
    break;}
case 28:
{ (yyval.precSpecs=yyvsp[-4].precSpecs)->append(new PrecSpec(whichKind(yyvsp[-3].str), yyvsp[-2].num, yyvsp[-1].sm_stringList)); ;
    break;}
case 29:
{ yyval.sm_stringList = new ASTList<LocString>; ;
    break;}
case 30:
{ (yyval.sm_stringList=yyvsp[-1].sm_stringList)->append(yyvsp[0].str); ;
    break;}
case 31:
{ yyval.str = yyvsp[0].str; ;
    break;}
case 32:
{ yyval.str = yyvsp[0].str; ;
    break;}
case 33:
{ yyval.specFuncs = new ASTList<SpecFunc>; ;
    break;}
case 34:
{ (yyval.specFuncs=yyvsp[-1].specFuncs)->append(yyvsp[0].specFunc); ;
    break;}
case 35:
{ yyval.specFunc = new SpecFunc(yyvsp[-4].str, yyvsp[-2].sm_stringList, yyvsp[0].str); ;
    break;}
case 36:
{ yyval.sm_stringList = new ASTList<LocString>; ;
    break;}
case 37:
{ yyval.sm_stringList = yyvsp[0].sm_stringList; ;
    break;}
case 38:
{ yyval.sm_stringList = new ASTList<LocString>(yyvsp[0].str); ;
    break;}
case 39:
{ (yyval.sm_stringList=yyvsp[-2].sm_stringList)->append(yyvsp[0].str); ;
    break;}
case 40:
{ yyval.topForm = new TF_nonterm(yyvsp[-1].str, yyvsp[-2].str, new ASTList<SpecFunc>,
                                     new ASTList<ProdDecl>(yyvsp[0].prodDecl), NULL); ;
    break;}
case 41:
{ yyval.topForm = new TF_nonterm(yyvsp[-5].str, yyvsp[-6].str, yyvsp[-3].specFuncs, yyvsp[-2].prodDecls, yyvsp[-1].sm_stringList); ;
    break;}
case 42:
{ yyval.prodDecls = new ASTList<ProdDecl>; ;
    break;}
case 43:
{ (yyval.prodDecls=yyvsp[-1].prodDecls)->append(yyvsp[0].prodDecl); ;
    break;}
case 44:
{ yyval.prodDecl = new ProdDecl(yyvsp[-1].rhsList, yyvsp[0].str); ;
    break;}
case 45:
{ yyval.str = yyvsp[0].str; ;
    break;}
case 46:
{ yyval.str = nolocNULL(); ;
    break;}
case 47:
{ yyval.rhsList = new ASTList<RHSElt>; ;
    break;}
case 48:
{ (yyval.rhsList=yyvsp[-1].rhsList)->append(yyvsp[0].rhsElt); ;
    break;}
case 49:
{ yyval.rhsElt = new RH_name(sameloc(yyvsp[0].str, ""), yyvsp[0].str); ;
    break;}
case 50:
{ yyval.rhsElt = new RH_name(yyvsp[-2].str, yyvsp[0].str); ;
    break;}
case 51:
{ yyval.rhsElt = new RH_sm_string(sameloc(yyvsp[0].str, ""), yyvsp[0].str); ;
    break;}
case 52:
{ yyval.rhsElt = new RH_sm_string(yyvsp[-2].str, yyvsp[0].str); ;
    break;}
case 53:
{ yyval.rhsElt = new RH_prec(yyvsp[-1].str); ;
    break;}
case 54:
{ yyval.sm_stringList = NULL; ;
    break;}
case 55:
{ yyval.sm_stringList = yyvsp[-1].sm_stringList; ;
    break;}
}



  yyvsp -= yylen;
  yyssp -= yylen;
#if YYLSP_NEEDED
  yylsp -= yylen;
#endif

#if YYDEBUG
  if (yydebug)
    {
      short *yyssp1 = yyss - 1;
      YYFPRINTF (stderr, "state stack now");
      while (yyssp1 != yyssp)
        YYFPRINTF (stderr, " %d", *++yyssp1);
      YYFPRINTF (stderr, "\n");
    }
#endif

  *++yyvsp = yyval;
#if YYLSP_NEEDED
  *++yylsp = yyloc;
#endif

  /* Now `shift' the result of the reduction.  Determine what state
     that goes to, based on the state we popped back to and the rule
     number reduced by.  */

  yyn = yyr1[yyn];

  yystate = yypgoto[yyn - YYNTBASE] + *yyssp;
  if (yystate >= 0 && yystate <= YYLAST && yycheck[yystate] == *yyssp)
    yystate = yytable[yystate];
  else
    yystate = yydefgoto[yyn - YYNTBASE];

  goto yynewstate;


/*------------------------------------.
| yyerrlab -- here on detecting error |
`------------------------------------*/
yyerrlab:
  /* If not already recovering from an error, report this error.  */
  if (!yyerrstatus)
    {
      ++yynerrs;

#ifdef YYERROR_VERBOSE
      yyn = yypact[yystate];

      if (yyn > YYFLAG && yyn < YYLAST)
        {
          YYSIZE_T yysize = 0;
          char *yymsg;
          int yyx, yycount;

          yycount = 0;
          /* Start YYX at -YYN if negative to avoid negative indexes in
             YYCHECK.  */
          for (yyx = yyn < 0 ? -yyn : 0;
               yyx < (int) (sizeof (yytname) / sizeof (char *)); yyx++)
            if (yycheck[yyx + yyn] == yyx)
              yysize += yystrlen (yytname[yyx]) + 15, yycount++;
          yysize += yystrlen ("parse error, unexpected ") + 1;
          yysize += yystrlen (yytname[YYTRANSLATE (yychar)]);
          yymsg = (char *) YYSTACK_ALLOC (yysize);
          if (yymsg != 0)
            {
              char *yyp = yystpcpy (yymsg, "parse error, unexpected ");
              yyp = yystpcpy (yyp, yytname[YYTRANSLATE (yychar)]);

              if (yycount < 5)
                {
                  yycount = 0;
                  for (yyx = yyn < 0 ? -yyn : 0;
                       yyx < (int) (sizeof (yytname) / sizeof (char *));
                       yyx++)
                    if (yycheck[yyx + yyn] == yyx)
                      {
                        const char *yyq = ! yycount ? ", expecting " : " or ";
                        yyp = yystpcpy (yyp, yyq);
                        yyp = yystpcpy (yyp, yytname[yyx]);
                        yycount++;
                      }
                }
              yyerror (yymsg);
              YYSTACK_FREE (yymsg);
            }
          else
            yyerror ("parse error; also virtual memory exhausted");
        }
      else
#endif /* defined (YYERROR_VERBOSE) */
        yyerror ("parse error");
    }
  goto yyerrlab1;


/*--------------------------------------------------.
| yyerrlab1 -- error raised explicitly by an action |
`--------------------------------------------------*/
yyerrlab1:
  if (yyerrstatus == 3)
    {
      /* If just tried and failed to reuse lookahead token after an
         error, discard it.  */

      /* return failure if at end of input */
      if (yychar == YYEOF)
        YYABORT;
      YYDPRINTF ((stderr, "Discarding token %d (%s).\n",
                  yychar, yytname[yychar1]));
      yychar = YYEMPTY;
    }

  /* Else will try to reuse lookahead token after shifting the error
     token.  */

  yyerrstatus = 3;              /* Each real token shifted decrements this */

  goto yyerrhandle;


/*-------------------------------------------------------------------.
| yyerrdefault -- current state does not do anything special for the |
| error token.                                                       |
`-------------------------------------------------------------------*/
yyerrdefault:
#if 0
  /* This is wrong; only states that explicitly want error tokens
     should shift them.  */

  /* If its default is to accept any token, ok.  Otherwise pop it.  */
  yyn = yydefact[yystate];
  if (yyn)
    goto yydefault;
#endif


/*---------------------------------------------------------------.
| yyerrpop -- pop the current state because it cannot handle the |
| error token                                                    |
`---------------------------------------------------------------*/
yyerrpop:
  if (yyssp == yyss)
    YYABORT;
  yyvsp--;
  yystate = *--yyssp;
#if YYLSP_NEEDED
  yylsp--;
#endif

#if YYDEBUG
  if (yydebug)
    {
      short *yyssp1 = yyss - 1;
      YYFPRINTF (stderr, "Error: state stack now");
      while (yyssp1 != yyssp)
        YYFPRINTF (stderr, " %d", *++yyssp1);
      YYFPRINTF (stderr, "\n");
    }
#endif

/*--------------.
| yyerrhandle.  |
`--------------*/
yyerrhandle:
  yyn = yypact[yystate];
  if (yyn == YYFLAG)
    goto yyerrdefault;

  yyn += YYTERROR;
  if (yyn < 0 || yyn > YYLAST || yycheck[yyn] != YYTERROR)
    goto yyerrdefault;

  yyn = yytable[yyn];
  if (yyn < 0)
    {
      if (yyn == YYFLAG)
        goto yyerrpop;
      yyn = -yyn;
      goto yyreduce;
    }
  else if (yyn == 0)
    goto yyerrpop;

  if (yyn == YYFINAL)
    YYACCEPT;

  YYDPRINTF ((stderr, "Shifting error token, "));

  *++yyvsp = yylval;
#if YYLSP_NEEDED
  *++yylsp = yylloc;
#endif

  yystate = yyn;
  goto yynewstate;


/*-------------------------------------.
| yyacceptlab -- YYACCEPT comes here.  |
`-------------------------------------*/
yyacceptlab:
  yyresult = 0;
  goto yyreturn;

/*-----------------------------------.
| yyabortlab -- YYABORT comes here.  |
`-----------------------------------*/
yyabortlab:
  yyresult = 1;
  goto yyreturn;

/*---------------------------------------------.
| yyoverflowab -- parser overflow comes here.  |
`---------------------------------------------*/
yyoverflowlab:
  yyerror ("parser stack overflow");
  yyresult = 2;
  /* Fall through.  */

yyreturn:
#ifndef yyoverflow
  if (yyss != yyssa)
    YYSTACK_FREE (yyss);
#endif
  return yyresult;
}

/* ------------------ extra C code ------------------ */
AssocKind whichKind(LocString * /*owner*/ kind)
{ 
  // delete 'kind' however we exit
  Owner<LocString> killer(kind);
  
  #define CHECK(syntax, value)   \
    if (kind->equals(syntax)) {  \
      return value;              \
    }
  CHECK("left", AK_LEFT);
  CHECK("right", AK_RIGHT);
  CHECK("nonassoc", AK_NONASSOC);
  CHECK("prec", AK_NEVERASSOC);
  CHECK("assoc_split", AK_SPLIT);
  #undef CHECK

  xbase(sm_stringc << kind->locString()
                << ": invalid associativity kind: " << *kind);
}
@h=tangler('elk/elk_mlsstr.cpp')
@select(h)
// mlsstr.cc            see license.txt for copyright and terms of use
// code for mlsstr.h
// based on ccsstr.cc

#include "elk_mlsstr.h"
#include "sm_xassert.h"
#include "sm_exc.h"
#include "sm_strutil.h"

#include <iostream.h>    // cout
#include <ctype.h>       // isspace


MLSubstrate::MLSubstrate(ReportError *err)
  : EmbeddedLang(err)
{
  reset();
}

void MLSubstrate::reset(int initNest)
{
  state = ST_NORMAL;
  nesting = initNest;
  comNesting = 0;
  prev = 0;
  text.setlength(0);
}


MLSubstrate::~MLSubstrate()
{}


void MLSubstrate::handle(char const *str, int len, char finalDelim)
{
  text.append(str, len);

  for (; len>0; len--,str++) {
    switch (state) {
      case ST_NORMAL:
        switch (*str) {
          case '{':
          case '(':
          case '[':
            nesting++;
            break;

          case '}':
          case ')':
          case ']':
            if (nesting == 0) {
              err->reportError(sm_stringc
                << "unexpected closing delimiter `" << *str
                << "' -- probably due to missing `" << finalDelim << "'");
            }
            else {
              nesting--;
            }
            break;

          case '\"':
            state = ST_STRING;
            break;

          case '\'':
            state = ST_CHAR;
            break;

          case '*':
            if (prev == '(') {
              state = ST_COMMENT;
              xassert(comNesting == 0);
              xassert(nesting > 0);
              nesting--;     // undo 'nesting++' from the '('
              
              // if the next char is ')', i.e. input was "(*)", do
              // not allow it to use this '*' to finish the comment
              prev = 0;                                            
              continue;
            }
            break;
        }
        break;

      case ST_STRING:
      case ST_CHAR:
        if (prev != '\\') {
          if ((state == ST_STRING && *str == '\"') ||
              (state == ST_CHAR && *str == '\'')) {
            state = ST_NORMAL;
          }
          else if (*str == '\n') {
            err->reportError("unterminated sm_string or char literal");
          }
        }
        break;

      case ST_COMMENT:
        if (prev == '(' && *str == '*') {
          comNesting++;
          prev = 0;      // like above
          continue;                   
        }
        else if (prev == '*' && *str == ')') {
          xassert(comNesting >= 0);
          if (comNesting == 0) {
            // done with comment
            state = ST_NORMAL;
          }
          else {
            // decrease nesting
            comNesting--;
          }
        }
        break;

      default:
        xfailure("unknown state");
    }

    prev = *str;
  }
}


bool MLSubstrate::zeroNesting() const
{
  return state == ST_NORMAL && nesting == 0;
}


sm_string MLSubstrate::getFuncBody() const
{
  return text;
}


// 4/29/04: I have no idea if this is right or not.. this is the
// definition from ccsstr.cc.
sm_string MLSubstrate::getDeclName() const
{
  // go with the rather inelegant heuristic that the word
  // just before the first '(' is the function's name
  char const *start = text.pcharc();
  char const *p = start;
  
  // find first '('
  while (*p && *p!='(') { p++; }
  if (!*p) {
    xformat("missing '('");
  }             
  if (p == start) {
    xformat("missing name");
  }

  // skip backward past any whitespace before the '('
  p--;
  while (p>=start && isspace(*p)) { p--; }
  if (p<start) {
    xformat("missing name");
  }
  char const *nameEnd = p+1;    // char just past last
  
  // move backward through the name
  while (p>=start && 
         (isalnum(*p) || *p=='_'))
    { p--; }
  p++;    // move back to most recent legal char
  
  // done
  return sm_string(p, nameEnd-p);
}


// ------------------ test code -------------------
#ifdef TEST_MLSSTR

#define ML MLSubstrate
#define Test MLSubstrateTest

// test code is put into a class just so that MLSubstrate
// can grant it access to private fields
class Test {
public:
  void feed(ML &ml, char const *src);
  void test(char const *src, ML::State state, int nesting, 
            int comNesting, char prev);
  void normal(char const *src, int nesting);
  void str(char const *src, int nesting, bool bs);
  void yes(char const *src);
  void no(char const *src);
  void name(char const *body, char const *n);
  void badname(char const *body);
  int main();
};


#define min(a,b) ((a)<(b)?(a):(b))

void Test::feed(ML &ml, char const *src)
{
  cout << "trying: " << src << endl;
  while (*src) {
    // feed it in 10 char increments, to test split processing too
    int len = min(strlen(src), 10);
    ml.handle(src, len, '}');
    src += len;
  }
}


void Test::test(char const *src, ML::State state, int nesting,
                int comNesting, char prev)
{
  ML ml;
  feed(ml, src);

  if (!( ml.state == state &&
         ml.nesting == nesting &&
         ml.prev == prev )) {
    xfailure(sm_stringc << "failed on src: " << src);
  }
}


void Test::normal(char const *src, int nesting)
{
  test(src, ML::ST_NORMAL, nesting, 0, src[strlen(src)-1]);
}

void Test::str(char const *src, int nesting, bool bs)
{
  char prev = (bs? '\\' : src[strlen(src)-1]);
  test(src, ML::ST_STRING, nesting, 0, prev);

  // repeat the test with single-tick
  sm_string another = replace(src, "\"", "\'");
  test(another, ML::ST_CHAR, nesting, 0, prev);
}


void Test::yes(char const *src)
{
  ML ml;
  feed(ml, src);

  xassert(ml.zeroNesting());
}

void Test::no(char const *src)
{
  ML ml;
  feed(ml, src);

  xassert(!ml.zeroNesting());
}

void Test::name(char const *body, char const *n)
{
  ML ml;
  feed(ml, body);
  xassert(ml.getDeclName().equals(n));
}

void Test::badname(char const *body)
{
  ML ml;
  feed(ml, body);
  try {
    ml.getDeclName();
    xfailure("got a name when it shoudn't have!");
  }
  catch (...)
    {}
}


int Test::main()
{
  normal("int main()", 0);
  normal("int main() { hi", 1);
  normal("int main() { hi {", 2);
  normal("int main() { hi { foo[5", 3);
  normal("int main() { hi { foo[5] and ", 2);
  normal("int main() { hi { foo[5] and } bar ", 1);
  normal("int main() { hi { foo[5] and } bar } baz ", 0);

  normal("main() { printf(\"hello \\ world\"); ret", 1);

  normal("()[]{}([{}])", 0);
  normal("{ ()[]{}([{}]) } ", 0);
  normal("( ()[]{}([{}]) )", 0);
  normal("[ ()[]{}([{}]) ]", 0);
  normal("\"foo\" ()[]{}([{}])", 0);

  str("main() { printf(\"hello", 2, false);
  str("main() { printf(\"hello \\", 2, true);
  str("main() { printf(\"hello \\ world", 2, false);
  str("main() { printf(\"hello \\ world\", \"hi", 2, false);

  test("\"a\" 'b' (", ML::ST_NORMAL, 1, 0, '(');

  // test comments, particularly testing
  test("(", ML::ST_NORMAL, 1, 0, '(');
  test("(*", ML::ST_COMMENT, 0, 0, 0);
  test("(*)", ML::ST_COMMENT, 0, 0, ')');
  test("(*)(", ML::ST_COMMENT, 0, 0, '(');
  test("(*)(*", ML::ST_COMMENT, 0, 1, 0);
  test("(*)(*)", ML::ST_COMMENT, 0, 1, ')');
  test("(*)(*)*", ML::ST_COMMENT, 0, 1, '*');
  test("(*)(*)*)", ML::ST_COMMENT, 0, 0, ')');
  test("(*)(*)*)*", ML::ST_COMMENT, 0, 0, '*');
  test("(*)(*)*)*)", ML::ST_NORMAL, 0, 0, ')');
  
  test("(*(*(*(*", ML::ST_COMMENT, 0, 4, 0);

  yes("main() {}");
  yes("main() { printf(\"foo\", 3, 4 (*yep{*)); }");
  yes("some (* junk {\n more*)");
  yes("'\\''");
  yes("\"\\\"\"");
  yes("[][][][][]");
  yes("\"[[[\"");
  yes("*");
  yes("(* [ / * [ *)");

  no("\"");
  no("(");
  no(" ( (* ) *) ");

  name("int main()", "main");
  name("int eval(Environment &env)", "eval");
  name("man()", "man");
  badname("(");
  badname("  (");
  badname("  ");
  badname("");
  badname(")");
  badname("main");

  cout << "\nmlsstr: all tests PASSED\n";

  return 0;
}

int main()
{
  Test t;
  return t.main();
}

#endif // TEST_MLSSTR
@h=tangler('elk/elk_parsetables.cpp')
@select(h)
// parsetables.cc            see license.txt for copyright and terms of use
// code for parsetables.h

#include "elk_parsetables.h"
#include "sm_bflatten.h"
#include "sm_trace.h"
#include "sm_crc.h"
#include "elk_emitcode.h"
#include "sm_bit2d.h"

#include <string.h>         // memset
#include <stdlib.h>         // qsort, system


// array index code
enum { UNASSIGNED = -1 };

               
// fwd
template <class EltType>
void printTable(EltType const *table, int size, int rowLength,
                char const *typeName, char const *tableName);


ParseTables::ParseTables(int t, int nt, int s, int p, StateId start, int final)
{
  alloc(t, nt, s, p, start, final);
}
    
template <class T>
void allocInitArray(T *&arr, int size, T init)
{
  arr = new T[size];
  for (int i=0; i<size; i++) {
    arr[i] = init;
  }
}

template <class T>
void allocZeroArray(T *&arr, int size)
{
  arr = new T[size];
  memset(arr, 0, sizeof(arr[0]) * size);
}

void ParseTables::alloc(int t, int nt, int s, int p, StateId start, int final)
{
  owning = true;

  temp = new TempData(s);

  numTerms = t;
  numNonterms = nt;
  numStates = s;
  numProds = p;

  actionCols = numTerms;
  actionRows = numStates;

  gotoCols = numNonterms;
  gotoRows = numStates;

  allocZeroArray(actionTable, actionTableSize());

  allocZeroArray(gotoTable, gotoTableSize());

  allocZeroArray(prodInfo, numProds);

  allocZeroArray(stateSymbol, numStates);

  // table of ambiguous actions is NULL until someone fills in the
  // whole thing; since we don't know how many there might be, we
  // can't even allocate the storage now
  ambigTableSize = 0;
  ambigTable = NULL;

  startState = start;
  finalProductionIndex = final;

  allocZeroArray(nontermOrder, nontermOrderSize());

  if (ENABLE_CRS_COMPRESSION) {
    allocZeroArray(firstWithTerminal, numTerms);
    allocZeroArray(firstWithNonterminal, numNonterms);
  }
  else {
    firstWithTerminal = NULL;
    firstWithNonterminal = NULL;
  }

  bigProductionListSize = 0;
  bigProductionList = NULL;
  if (ENABLE_CRS_COMPRESSION) {
    allocZeroArray(productionsForState, numStates);
  }
  else {
    productionsForState = NULL;
  }

  if (ENABLE_CRS_COMPRESSION) {
    allocZeroArray(ambigStateTable, numStates);
  }
  else {
    ambigStateTable = NULL;
  }

  // # of bytes, but rounded up to nearest 32-bit boundary
  errorBitsRowSize = ((numTerms+31) >> 5) * 4;

  // no compressed info
  uniqueErrorRows = 0;
  errorBits = NULL;
  errorBitsPointers = NULL;

  actionIndexMap = NULL;
  actionRowPointers = NULL;

  gotoIndexMap = NULL;
  gotoRowPointers = NULL;
}


ParseTables::~ParseTables()
{
  if (temp) {
    delete temp;
  }

  if (owning) {
    delete[] actionTable;
    delete[] gotoTable;
    delete[] prodInfo;
    delete[] stateSymbol;

    if (ambigTable) {
      delete[] ambigTable;
    }

    delete[] nontermOrder;

    if (firstWithTerminal) {
      delete[] firstWithTerminal;
    }
    if (firstWithNonterminal) {
      delete[] firstWithNonterminal;
    }
    
    if (bigProductionList) {
      delete[] bigProductionList;
    }

    if (errorBits) {
      delete[] errorBits;
    }
    if (actionIndexMap) {
      delete[] actionIndexMap;
    }
    if (gotoIndexMap) {
      delete[] gotoIndexMap;
    }
  }

  // these are always owned
  if (productionsForState) {
    delete[] productionsForState;
  }
  if (ambigStateTable) {
    delete[] ambigStateTable;
  }
  if (errorBitsPointers) {
    delete[] errorBitsPointers;
  }
  if (actionRowPointers) {
    delete[] actionRowPointers;
  }
  if (gotoRowPointers) {
    delete[] gotoRowPointers;
  }
}


ParseTables::TempData::TempData(int numStates)
  : ambigTable(),
    bigProductionList(),
    productionsForState(numStates),
    ambigStateTable(numStates)
{
  productionsForState.setAll(UNASSIGNED);
  ambigStateTable.setAll(UNASSIGNED);
}

ParseTables::TempData::~TempData()
{}


ActionEntry ParseTables::validateAction(int code) const
{
  // make sure that 'code' is representable; if this fails, most likely
  // there are more than 32k states or productions; in turn, the most
  // likely cause of *that* would be the grammar is being generated
  // automatically from some other specification; you can change the
  // typedefs of ActionEntry and GotoEntry in gramanl.h to get more
  // capacity
  ActionEntry ret = (ActionEntry)code;
  xassert((int)ret == code);
  return ret;
}

GotoEntry ParseTables::validateGoto(int code) const
{
  // see above
  GotoEntry ret = (GotoEntry)code;
  xassert((int)ret == code);
  xassert(ret != errorGotoEntry);    // otherwise collision with error code
  return ret;
}


// doesn't init anything; for use by emitConstructionCode's emitted code
ParseTables::ParseTables(bool o)
  : owning(o),
    temp(NULL)
{
  xassert(owning == false);
}


#if ENABLE_CRS_COMPRESSION
ActionEntry makeAE(ActionEntryKind k, int index)
{                                      
  // must fit into 6 bits for my encoding
  if ((unsigned)index <= AE_MAXINDEX) {
    // ok
  }
  else {                     
    // this is just so I can see the resulting truncated table;
    // the parser will *not* work
    cout << "error: index " << index << " truncated!\n";
    index = AE_MAXINDEX;
  }
  
  if (k == AE_ERROR) {
    xassert(index == 0);
  }

  return k | index;
}
#endif


ActionEntry ParseTables::encodeShift(StateId destState, int shiftedTermId)
{
  #if ENABLE_CRS_COMPRESSION
    int delta = destState - firstWithTerminal[shiftedTermId];
    return makeAE(AE_SHIFT, delta);
  #else
    return validateAction(+destState+1);
  #endif
}


ActionEntry ParseTables::encodeReduce(int prodId, StateId inWhatState)
{
  #if ENABLE_CRS_COMPRESSION
    int begin = temp->productionsForState[inWhatState];
    int end = temp->bigProductionList.length();
    if (begin == UNASSIGNED) {
      // starting a new set of per-state productions
      temp->productionsForState[inWhatState] = end;
      temp->bigProductionList.push(prodId);
      return AE_REDUCE | 0 /*first in set*/;
    }
    else {
      // continuing a set; search for existing 'prodId' in that set
      int delta;
      for (int i=begin; i<end; i++) {
        if (temp->bigProductionList[i] == prodId) {
          // re-use this offset
          delta = i-begin;
          goto encode;
        }
      }

      // not found: add another production id to this set
      temp->bigProductionList.push(prodId);
      delta = end-begin;

    encode:
      return makeAE(AE_REDUCE, delta);
    }

  #else
    return validateAction(-prodId-1);
  #endif
}


ActionEntry ParseTables::encodeAmbig
  (ArrayStack<ActionEntry> const &set, StateId inWhatState)
{
  #if ENABLE_CRS_COMPRESSION
    int begin = temp->ambigStateTable[inWhatState];
    int end = temp->ambigTable.length();
    if (begin == UNASSIGNED) {
      // starting a new set of per-state ambiguous actions
      temp->ambigStateTable[inWhatState] = end;
      appendAmbig(set);
      return makeAE(AE_AMBIGUOUS, 0 /*first in set*/);
    }
    else {
      // continuing a set: Look for another ambiguous action set in
      // the same line that has identical contents.  Due to the way
      // sets are constructed, their representation is canonical.
      // This is important because some grammars (cc2) have many
      // ambiguous entries, but they're all the same set of actions;
      // were we to not consolidate like this, the 6-bit cell encoding
      // would not be enough.

      // # of big-table entries that will be used
      int encodeLen = set.length()+1;

      for (int i=begin; i+encodeLen <= end; i++) {
        // does this offset contain the same set of actions?
        if (compareAmbig(set, i)) {
          return makeAE(AE_AMBIGUOUS, i-begin /*delta*/);
        }
      }

      // no match
      appendAmbig(set);
      return makeAE(AE_AMBIGUOUS, end-begin /*delta*/);
    }

  #else
    int end = temp->ambigTable.length();
    appendAmbig(set);
    return validateAction(numStates+end+1);
  #endif
}


void ParseTables::appendAmbig(ArrayStack<ActionEntry> const &set)
{
  temp->ambigTable.push(set.length());
  for (int j=0; j < set.length(); j++) {
    temp->ambigTable.push(set[j]);
  }
}

bool ParseTables::compareAmbig(ArrayStack<ActionEntry> const &set,
                               int startIndex)
{
  if (temp->ambigTable[startIndex] != set.length()) {
    return false;           // mismatch in 1st entry
  }
  for (int j=0; j < set.length(); j++) {
    if (temp->ambigTable[startIndex+1+j] != set[j]) {
      return false;         // mismatch in j+2nd entry
    }
  }
  return true;              // match!
}


ActionEntry ParseTables::encodeError() const
{
  #if ENABLE_CRS_COMPRESSION
    return makeAE(AE_ERROR, 0);
  #else
    return validateAction(0);
  #endif
}


GotoEntry ParseTables::encodeGoto(StateId destState, int shiftedNontermId) const
{
  #if ENABLE_CRS_COMPRESSION
    xassert(0 <= shiftedNontermId && shiftedNontermId < numNonterms);
    int delta = destState - firstWithNonterminal[shiftedNontermId];
    return validateGoto(delta);
  #else
    return validateGoto(destState);
  #endif
}


// simple alloc + copy
template <class T>
void copyArray(int &len, T *&dest, ArrayStack<T> const &src)
{
  len = src.length();
  dest = new T[len];
  memcpy(dest, src.getArray(), sizeof(T) * len);
}

// given an array 'src' of indices relative to 'base', allocate the
// array 'dest' and fill it in with actual pointers into 'base'
template <class T>
void copyIndexPtrArray(int len, T **&dest, T *base, ArrayStack<int> const &src)
{
  dest = new T* [len];
  for (int i=0; i<len; i++) {          
    if (src[i] != UNASSIGNED) {
      dest[i] = base + src[i];
    }
    else {
      dest[i] = NULL;      // so segfault if deref unassigned entry
    }
  }
}

void ParseTables::finishTables()
{
  // copy the ambiguous actions
  copyArray(ambigTableSize, ambigTable, temp->ambigTable);

  if (ENABLE_CRS_COMPRESSION) {
    // transfer bigProductionList
    copyArray(bigProductionListSize, bigProductionList, temp->bigProductionList);

    // transfer productionsForState, translating indices into pointers
    copyIndexPtrArray(numStates, productionsForState, bigProductionList,
                      temp->productionsForState);

    // ambigStateTable
    copyIndexPtrArray(numStates, ambigStateTable, ambigTable,
                      temp->ambigStateTable);
  }

  delete temp;
  temp = NULL;
}


// -------------------- table compression --------------------
void ParseTables::computeErrorBits()
{                     
  traceProgress() << "computing errorBits[]\n";

  // should only be done once
  xassert(!errorBits);       

  // allocate and clear it
  int rowSize = ((numTerms+31) >> 5) * 4;
  allocZeroArray(errorBits, numStates * rowSize);

  // build the pointer table
  allocZeroArray(errorBitsPointers, numStates);

  // find and set the error bits
  fillInErrorBits(true /*setPointers*/);

  // compute which rows are identical; I only compress the rows (and
  // not the columns) because I can fold the former's compression into
  // the errorBitsPointers[] access, whereas the latter would require
  // yet another table
  int *compressed = new int[numStates];   // row -> new location in errorBits[]
  uniqueErrorRows = 0;
  int s;
  for (s=0; s < numStates; s++) {
    // is 's' the same as any rows that preceded it?
    for (int t=0; t < s; t++) {
      // do 's' and 't' have the same contents?
      if (0==memcmp(errorBitsPointers[s],
                    errorBitsPointers[t],
                    sizeof(ErrorBitsEntry) * errorBitsRowSize)) {
        // yes, map 's' to 't' instead
        compressed[s] = compressed[t];
        goto next_s;
      }
    }

    // not the same as any
    compressed[s] = uniqueErrorRows;
    uniqueErrorRows++;

  next_s:
    ;
  }

  // make a smaller 'errorBits' array
  delete[] errorBits;
  allocZeroArray(errorBits, uniqueErrorRows * rowSize);

  // rebuild 'errorBitsPointers' according to 'compressed'
  for (s=0; s < numStates; s++) {
    errorBitsPointers[s] = errorBits + (compressed[s] * errorBitsRowSize);
  }
  delete[] compressed;

  // fill in the bits again, using the new pointers map
  fillInErrorBits(false /*setPointers*/);
}


void ParseTables::fillInErrorBits(bool setPointers)
{
  for (int s=0; s < numStates; s++) {
    if (setPointers) {
      errorBitsPointers[s] = errorBits + (s * errorBitsRowSize);
    }

    for (int t=0; t < numTerms; t++) {
      if (isErrorAction(actionEntry((StateId)s, t))) {
        ErrorBitsEntry &b = errorBitsPointers[s][t >> 3];
        b |= 1 << (t & 7);
      }
    }
  }
}


void ParseTables::mergeActionColumns()
{
  traceProgress() << "merging action columns\n";

  // can only do this if we've already pulled out the errors
  xassert(errorBits);

  // for now I assume we don't have a map yet
  xassert(!actionIndexMap);

  if (tracingSys("mergeActionColumnsPre")) {
    // print the action table before compression
    printTable(actionTable, actionTableSize(), actionCols,
               "ActionEntry", "actionTable");
  }

  // compute graph of conflicting 'action' columns
  // (will be symmetric)
  Bit2d graph(point(numTerms, numTerms));
  graph.setall(0);

  // fill it in
  for (int t1=0; t1 < numTerms; t1++) {
    for (int t2=0; t2 < t1; t2++) {
      // does column 't1' conflict with column 't2'?
      for (int s=0; s < numStates; s++) {
        ActionEntry a1 = actionEntry((StateId)s, t1);
        ActionEntry a2 = actionEntry((StateId)s, t2);

        if (isErrorAction(a1) ||
            isErrorAction(a2) ||
            a1 == a2) {
          // no problem
        }
        else {
          // conflict!
          graph.set(point(t1, t2));
          graph.set(point(t2, t1));
          break;
        }
      }
    }
  }
  
  // color the graph
  Array<int> color(numTerms);      // terminal -> color
  int numColors = colorTheGraph(color, graph);
  
  // build a new, compressed action table; the entries are initialized
  // to 'error', meaning every cell starts as don't-care
  ActionEntry *newTable;
  allocInitArray(newTable, numStates * numColors, errorActionEntry);

  // merge columns in 'actionTable' into those in 'newTable'
  // according to the 'color' map
  actionIndexMap = new TermIndex[numTerms];
  for (int t=0; t<numTerms; t++) {
    int c = color[t];

    // merge actionTable[t] into newTable[c]
    for (int s=0; s<numStates; s++) {
      ActionEntry &dest = newTable[s*numColors + c];

      ActionEntry src = actionEntry((StateId)s, t);
      if (!isErrorAction(src)) {
        // make sure there's no conflict (otherwise the graph
        // coloring algorithm screwed up)
        xassert(isErrorAction(dest) ||
                dest == src);

        // merge the entry
        dest = src;
      }
    }

    // fill in the action index map
    TermIndex ti = (TermIndex)c;
    xassert(ti == c);     // otherwise value truncation happened
    actionIndexMap[t] = ti;
  }

  trace("compression")
    << "action table: from " << (actionTableSize() * sizeof(ActionEntry))
    << " down to " << (numStates * numColors * sizeof(ActionEntry))
    << " bytes\n";

  // replace the existing table with the compressed one
  delete[] actionTable;
  actionTable = newTable;
  actionCols = numColors;
}


// unsurprisingly, this function has considerable structure in common
// with 'mergeActionColumns'; however, my attempts to consolidate them
// have led to code that is harder to understand and debug, so they
// remain separate (at least for now)
void ParseTables::mergeActionRows()
{
  traceProgress() << "merging action rows\n";

  // can only do this if we've already pulled out the errors
  xassert(errorBits);

  // for now I assume we don't have a map yet
  xassert(!actionRowPointers);

  // compute graph of conflicting 'action' rows
  // (will be symmetric)
  Bit2d graph(point(numStates, numStates));
  graph.setall(0);

  // fill it in
  for (int s1=0; s1 < numStates; s1++) {
    for (int s2=0; s2 < s1; s2++) {
      // does row 's1' conflict with row 's2'?
      for (int t=0; t < actionCols; t++) {    // t is an equivalence class of terminals
        ActionEntry a1 = actionTable[s1*actionCols + t];
        ActionEntry a2 = actionTable[s2*actionCols + t];

        if (isErrorAction(a1) ||
            isErrorAction(a2) ||
            a1 == a2) {
          // no problem
        }
        else {
          // conflict!
          graph.set(point(s1, s2));
          graph.set(point(s2, s1));
          break;
        }
      }
    }
  }

  // color the graph
  Array<int> color(numStates);      // state -> color (equivalence class)
  int numColors = colorTheGraph(color, graph);

  // build a new, compressed action table
  ActionEntry *newTable;
  allocInitArray(newTable, numColors * actionCols, errorActionEntry);

  // merge rows in 'actionTable' into those in 'newTable'
  // according to the 'color' map
  
  // actionTable[]:
  //
  //             t0    t1    t2    t3      // terminal equivalence classes
  //   s0
  //   s1
  //   s2
  //    ...
  //   /*states*/

  // newTable[]:
  //
  //             t0    t1    t2    t3      // terminal equivalence classes
  //   c0
  //   c1
  //   c2    < e.g., union of state1 and state4 (color[1]==color[4]==2) >
  //    ...
  //   /*state equivalence classes (colors)*/

  actionRowPointers = new ActionEntry* [numStates];
  for (int s=0; s<numStates; s++) {
    int c = color[s];

    // merge actionTable row 's' into newTable row 'c'
    for (int t=0; t<actionCols; t++) {
      ActionEntry &dest = newTable[c*actionCols + t];

      ActionEntry src = actionTable[s*actionCols + t];
      if (!isErrorAction(src)) {
        // make sure there's no conflict (otherwise the graph
        // coloring algorithm screwed up)
        xassert(isErrorAction(dest) ||
                dest == src);

        // merge the entry
        dest = src;
      }
    }

    // fill in the row pointer map
    actionRowPointers[s] = newTable + c*actionCols;
  }

  trace("compression")
    << "action table: from " << (numStates * actionCols * sizeof(ActionEntry))
    << " down to " << (numColors * actionCols * sizeof(ActionEntry))
    << " bytes\n";

  // replace the existing table with the compressed one
  delete[] actionTable;
  actionTable = newTable;
  actionRows = numColors;

  // how many single-value rows?  I'm investigating some other options
  // for further compression...
  {
    int ct=0;
    for (int s=0; s<actionRows; s++) {
      int val = 0;
      for (int t=0; t<actionCols; t++) {
        int entry = actionRowPointers[s][t];
        if (val==0) {
          val = entry;
        }
        else if (entry != 0 && entry != val) {
          // not all the same
          goto next_s;
        }
      }

      // all same
      ct++;

    next_s:
      ;
    }
    trace("compression") << ct << " same-valued action rows\n";
  }
}


// created by copying 'mergeGotoRows' and replacing 'action'
// with 'goto', etc.
void ParseTables::mergeGotoColumns()
{
  traceProgress() << "merging goto columns\n";

  // can only do this if we've already pulled out the errors
  xassert(errorBits);

  // for now I assume we don't have a map yet
  xassert(!gotoIndexMap);

  // compute graph of conflicting 'goto' columns
  Bit2d graph(point(numNonterms, numNonterms));
  graph.setall(0);

  // fill it in
  for (int nt1=0; nt1 < numNonterms; nt1++) {
    for (int nt2=0; nt2 < nt1; nt2++) {
      // does column 't1' conflict with column 't2'?
      for (int s=0; s < numStates; s++) {
        GotoEntry g1 = gotoEntry((StateId)s, nt1);
        GotoEntry g2 = gotoEntry((StateId)s, nt2);

        if (isErrorGoto(g1) ||
            isErrorGoto(g2) ||
            g1 == g2) {
          // no problem
        }
        else {
          // conflict!
          graph.set(point(nt1, nt2));
          graph.set(point(nt2, nt1));
          break;
        }
      }
    }
  }

  // color the graph
  Array<int> color(numNonterms);      // nonterminal -> color
  int numColors = colorTheGraph(color, graph);

  // build a new, compressed goto table; the entries are initialized
  // to 'error', meaning every cell starts as don't-care
  GotoEntry *newTable;
  allocInitArray(newTable, numStates * numColors, encodeGotoError());

  // merge columns in 'gotoTable' into those in 'newTable'
  // according to the 'color' map
  gotoIndexMap = new NtIndex[numNonterms];
  for (int nt=0; nt<numNonterms; nt++) {
    int c = color[nt];

    // merge gotoTable[nt] into newTable[c]
    for (int s=0; s<numStates; s++) {
      GotoEntry &dest = newTable[s*numColors + c];

      GotoEntry src = gotoEntry((StateId)s, nt);
      if (!isErrorGoto(src)) {
        // make sure there's no conflict (otherwise the graph
        // coloring and/or conflict map algorithms screwed up)
        xassert(isErrorGoto(dest) ||
                dest == src);

        // merge the entry
        dest = src;
      }
    }

    // fill in the goto index map
    NtIndex nti = (NtIndex)c;
    xassert(nti == c);     // otherwise value truncation happened
    gotoIndexMap[nt] = nti;
  }

  trace("compression")
    << "goto table: from " << (gotoTableSize() * sizeof(GotoEntry))
    << " down to " << (numStates * numColors * sizeof(GotoEntry))
    << " bytes\n";

  // replace the existing table with the compressed one
  delete[] gotoTable;
  gotoTable = newTable;
  gotoCols = numColors;
}


// created by copying 'mergeActionRows' and replacing 'action'
// with 'goto', etc.
void ParseTables::mergeGotoRows()
{
  traceProgress() << "merging goto rows\n";

  // can only do this if we've already pulled out the errors
  xassert(errorBits);

  // for now I assume we don't have a map yet
  xassert(!gotoRowPointers);

  // compute graph of conflicting 'goto' rows
  Bit2d graph(point(numStates, numStates));
  graph.setall(0);

  // fill it in
  for (int s1=0; s1 < numStates; s1++) {
    for (int s2=0; s2 < s1; s2++) {
      // does row 's1' conflict with row 's2'?
      for (int nt=0; nt < gotoCols; nt++) {    // nt is an equivalence class of nonterminals
        GotoEntry g1 = gotoTable[s1*gotoCols + nt];
        GotoEntry g2 = gotoTable[s2*gotoCols + nt];

        if (isErrorGoto(g1) ||
            isErrorGoto(g2) ||
            g1 == g2) {
          // no problem
        }
        else {
          // conflict!
          graph.set(point(s1, s2));
          graph.set(point(s2, s1));
          break;
        }
      }
    }
  }

  // color the graph
  Array<int> color(numStates);      // state -> color (equivalence class)
  int numColors = colorTheGraph(color, graph);

  // build a new, compressed goto table
  GotoEntry *newTable;
  allocInitArray(newTable, numColors * gotoCols, encodeGotoError());

  // merge rows in 'gotoTable' into those in 'newTable'
  // according to the 'color' map

  // gotoTable[]:
  //
  //             t0    t1    t2    t3      // nonterminal equivalence classes
  //   s0
  //   s1
  //   s2
  //    ...
  //   /*states*/

  // newTable[]:
  //
  //             t0    t1    t2    t3      // nonterminal equivalence classes
  //   c0
  //   c1
  //   c2    < e.g., union of state1 and state4 (color[1]==color[4]==2) >
  //    ...
  //   /*state equivalence classes (colors)*/

  gotoRowPointers = new GotoEntry* [numStates];
  for (int s=0; s<numStates; s++) {
    int c = color[s];

    // merge gotoTable row 's' into newTable row 'c'
    for (int nt=0; nt<gotoCols; nt++) {
      GotoEntry &dest = newTable[c*gotoCols + nt];

      GotoEntry src = gotoTable[s*gotoCols + nt];
      if (!isErrorGoto(src)) {
        // make sure there's no conflict (otherwise the graph
        // coloring algorithm screwed up)
        xassert(isErrorGoto(dest) ||
                dest == src);

        // merge the entry
        dest = src;
      }
    }

    // fill in the row pointer map
    gotoRowPointers[s] = newTable + c*gotoCols;
  }

  trace("compression")
    << "goto table: from " << (numStates * gotoCols * sizeof(GotoEntry))
    << " down to " << (numColors * gotoCols * sizeof(GotoEntry))
    << " bytes\n";

  // replace the existing table with the compressed one
  delete[] gotoTable;
  gotoTable = newTable;
  gotoRows = numColors;
}


static int intCompare(void const *left, void const *right)
{
  return *((int const*)left) - *((int const*)right);
}

int ParseTables::colorTheGraph(int *color, Bit2d &graph)
{
  int n = graph.Size().x;  // same as y

  if (tracingSys("graphColor") && n < 20) {
    graph.print();
  }

  // node -> # of adjacent nodes
  Array<int> degree(n);
  memset((int*)degree, 0, n * sizeof(int));

  // node -> # of adjacent nodes that have colors already
  Array<int> blocked(n);

  // initialize some arrays
  enum { UNASSIGNED = -1 };
  {
    for (int i=0; i<n; i++) {
      // clear the color map
      color[i] = UNASSIGNED;
      blocked[i] = 0;

      for (int j=0; j<n; j++) {
        if (graph.get(point(i,j))) {
          degree[i]++;
        }
      }
    }
  }

  // # of colors used
  int usedColors = 0;

  for (int numColored=0; numColored < n; numColored++) {
    // Find a vertex to color.  Prefer nodes that are more constrained
    // (have more blocked colors) to those that are less constrained.
    // Then, prefer those that are least constraining (heave least
    // uncolored neighbors) to those that are more constraining.  If
    // ties remain, choose arbitrarily.
    int best = -1;
    int bestBlocked = 0;
    int bestUnblocked = 0;

    for (int choice = 0; choice < n; choice++) {
      if (color[choice] != UNASSIGNED) continue;

      int chBlocked = blocked[choice];
      int chUnblocked = degree[choice] - blocked[choice];
      if (best == -1 ||                          // no choice yet
          chBlocked > bestBlocked ||             // more constrained
          (chBlocked == bestBlocked &&
           chUnblocked < bestUnblocked)) {       // least constraining
        // new best
        best = choice;
        bestBlocked = chBlocked;
        bestUnblocked = chUnblocked;
      }
    }

    // get the assigned colors of the adjacent vertices
    Array<int> adjColor(bestBlocked);
    int adjIndex = 0;
    for (int i=0; i<n; i++) {
      if (graph.get(point(best,i)) &&
          color[i] != UNASSIGNED) {
        adjColor[adjIndex++] = color[i];
      }
    }
    xassert(adjIndex == bestBlocked);

    // sort them
    qsort((int*)adjColor, bestBlocked, sizeof(int), intCompare);

    // select the lowest-numbered color that won't conflict
    int selColor = 0;
    for (int j=0; j<bestBlocked; j++) {
      if (selColor == adjColor[j]) {
        selColor++;
      }
      else if (selColor < adjColor[j]) {
        // found one that doesn't conflict
        break;
      }
      else {
        // happens when we have two neighbors that have the same color;
        // that's fine, we'll go around the loop again to see what the
        // next neighbor has to say
      }
    }

    // assign 'selColor' to 'best'
    color[best] = selColor;
    if (selColor+1 > usedColors) {
      usedColors = selColor+1;
    }

    // update 'blocked[]'
    for (int k=0; k<n; k++) {
      if (graph.get(point(best,k))) {
        // every neighbor of 'k' now has one more blocked color
        blocked[k]++;
      }
    }
  }

  ostream &os = trace("graphColor") << "colors[]:";

  for (int i=0; i<n; i++) {
    // every node should now have blocked == degree
    xassert(blocked[i] == degree[i]);

    // and have a color assigned
    xassert(color[i] != UNASSIGNED);
    os << " " << color[i];
  }

  os << "\n";

  return usedColors;
}


// --------------------- table emission -------------------
// create literal tables
template <class EltType>
void emitTable(EmitCode &out, EltType const *table, int size, int rowLength,
               char const *typeName, char const *tableName)
{
  if (!table || !size) {
    out << "  " << typeName << " *" << tableName << " = NULL;\n";
    return;
  }

  bool printHex = 0==strcmp(typeName, "ErrorBitsEntry") ||
                  (ENABLE_CRS_COMPRESSION && 0==strcmp(typeName, "ActionEntry")) ||
                  (ENABLE_CRS_COMPRESSION && 0==strcmp(typeName, "GotoEntry")) ;
  bool needCast = 0==strcmp(typeName, "StateId");

  if (size * sizeof(*table) > 50) {    // suppress small ones
    out << "  // storage size: " << size * sizeof(*table) << " bytes\n";
    if (size % rowLength == 0) {
      out << "  // rows: " << (size/rowLength) << "  cols: " << rowLength << "\n";
    }
  }

  int rowNumWidth = sm_stringf("%d", size / rowLength /*round down*/).length();

  // I make tables 'const' because that way the OS loader might be
  // smart enough to share them (on a read-only basis) across multiple
  // processes started from the same executable.  But I immediately
  // cast them to non-const, since ParseTables doesn't declare
  // pointers-to-const (since it also has methods to modify the tables
  // at parser generation time).

  out << "  static " << typeName << " const " << tableName << "[" << size << "] = {";
  int row = 0;
  for (int i=0; i<size; i++) {
    if (i % rowLength == 0) {    // one row per state
      out << sm_stringf("\n    /""*%*d*""/ ", rowNumWidth, row++);
    }

    if (needCast) {
      out << "(" << typeName << ")";
    }

    if (printHex) {
      out << sm_stringf("0x%02X, ", table[i]);
    }
    else if (sizeof(table[i]) == 1) {
      // little bit of a hack to make sure 'unsigned char' gets
      // printed as an int; the casts are necessary because this
      // code gets compiled even when EltType is ProdInfo
      out << (int)(*((unsigned char*)(table+i))) << ", ";
    }
    else {
      // print the other int-sized things, or ProdInfo using
      // the overloaded '<<' below
      out << table[i] << ", ";
    }
  }
  out << "\n"
      << "  };\n";
}

// used to emit the elements of the prodInfo table
sm_stringBuilder& operator<< (sm_stringBuilder &sb, ParseTables::ProdInfo const &info)
{
  sb << "{" << (int)info.rhsLen << "," << (int)info.lhsIndex << "}";
  return sb;
}


// like 'emitTable', but also set a local called 'tableName'
template <class EltType>
void emitTable2(EmitCode &out, EltType const *table, int size, int rowLength,
                char const *typeName, char const *tableName)
{
  sm_string tempName = sm_stringc << tableName << "_static";
  emitTable(out, table, size, rowLength, typeName, tempName);
  out << "  " << tableName << " = const_cast<" << typeName << "*>(" 
      << tempName << ");\n\n";
}


template <class EltType>
void emitOffsetTable(EmitCode &out, EltType **table, EltType *base, int size,
                     char const *typeName, char const *tableName, char const *baseName)
{
  if (!table) {
    out << "  " << tableName << " = NULL;\n\n";
    return;
  }

  // make the pointers persist by storing a table of offsets
  Array<int> offsets(size);
  bool allUnassigned = true;
  for (int i=0; i < size; i++) {
    if (table[i]) {
      offsets[i] = table[i] - base;
      allUnassigned = false;
    }
    else {
      offsets[i] = UNASSIGNED;    // codes for a NULL entry
    }
  }

  if (allUnassigned) {
    // for example, an LALR(1) grammar has no ambiguous entries in its tables
    size = 0;
  }

  if (size > 0) {
    out << "  " << tableName << " = new " << typeName << " [" << size << "];\n";

    emitTable(out, (int*)offsets, size, 16, "int", sm_stringc << tableName << "_offsets");

    // at run time, interpret the offsets table
    out << "  for (int i=0; i < " << size << "; i++) {\n"
        << "    int ofs = " << tableName << "_offsets[i];\n"
        << "    if (ofs >= 0) {\n"
        << "      " << tableName << "[i] = " << baseName << " + ofs;\n"
        << "    }\n"
        << "    else {\n"
        << "      " << tableName << "[i] = NULL;\n"
        << "    }\n"
        << "  }\n\n";
  }
  else {
    out << "  // offset table is empty\n"
        << "  " << tableName << " = NULL;\n\n";
  }
}

                
// for debugging
template <class EltType>
void printTable(EltType const *table, int size, int rowLength,
                char const *typeName, char const *tableName)
{            
  // disabled for now since I don't need it anymore, and it adds
  // a link dependency on emitcode.cc ...
  #if 0
  {
    EmitCode out("printTable.tmp");
    emitTable(out, table, size, rowLength, typeName, tableName);
  }

  system("cat printTable.tmp; rm printTable.tmp");
  #endif // 0
}


// emit code for a function which, when compiled and executed, will
// construct this same table (except the constructed table won't own
// the table data, since it will point to static program data)
void ParseTables::emitConstructionCode(EmitCode &out,
  char const *className, char const *funcName)
{
  // must have already called 'finishTables'
  xassert(!temp);

  out << "// this makes a ParseTables from some literal data;\n"
      << "// the code is written by ParseTables::emitConstructionCode()\n"
      << "// in " << __FILE__ << "\n"
      << "class " << className << "_ParseTables : public ParseTables {\n"
      << "public:\n"
      << "  " << className << "_ParseTables();\n"
      << "};\n"
      << "\n"
      << className << "_ParseTables::" << className << "_ParseTables()\n"
      << "  : ParseTables(false /*owning*/)\n"
      << "{\n"
      ;

  // set all the integer-like variables
  #define SET_VAR(var) \
    out << "  " #var " = " << var << ";\n";
  SET_VAR(numTerms);
  SET_VAR(numNonterms);
  SET_VAR(numStates);
  SET_VAR(numProds);
  SET_VAR(actionCols);
  SET_VAR(actionRows);
  SET_VAR(gotoCols);
  SET_VAR(gotoRows);
  SET_VAR(ambigTableSize);
  out << "  startState = (StateId)" << (int)startState << ";\n";
  SET_VAR(finalProductionIndex);
  SET_VAR(bigProductionListSize);
  SET_VAR(errorBitsRowSize);
  SET_VAR(uniqueErrorRows);
  #undef SET_VAR
  out << "\n";

  // action table, one row per state
  emitTable2(out, actionTable, actionTableSize(), actionCols,
             "ActionEntry", "actionTable");

  // goto table, one row per state
  emitTable2(out, gotoTable, gotoTableSize(), gotoCols,
             "GotoEntry", "gotoTable");

  // production info, arbitrarily 16 per row
  emitTable2(out, prodInfo, numProds, 16, "ParseTables::ProdInfo", "prodInfo");

  // state symbol map, arbitrarily 16 per row
  emitTable2(out, stateSymbol, numStates, 16, "SymbolId", "stateSymbol");

  // ambigTable
  emitTable2(out, ambigTable, ambigTableSize, 16, "ActionEntry", "ambigTable");

  // nonterminal order
  emitTable2(out, nontermOrder, nontermOrderSize(), 16,
             "NtIndex", "nontermOrder");

  // errorBits
  emitTable2(out, errorBits, uniqueErrorRows * errorBitsRowSize, errorBitsRowSize,
             "ErrorBitsEntry", "errorBits");

  emitOffsetTable(out, errorBitsPointers, errorBits, numStates,
                  "ErrorBitsEntry*", "errorBitsPointers", "errorBits");

  // actionIndexMap
  emitTable2(out, actionIndexMap, numTerms, 16,
             "TermIndex", "actionIndexMap");

  // actionRowPointers
  emitOffsetTable(out, actionRowPointers, actionTable, numStates,
                  "ActionEntry*", "actionRowPointers", "actionTable");

  // gotoIndexMap
  emitTable2(out, gotoIndexMap, numNonterms, 16,
             "NtIndex", "gotoIndexMap");

  // gotoRowPointers
  emitOffsetTable(out, gotoRowPointers, gotoTable, numStates,
                  "GotoEntry*", "gotoRowPointers", "gotoTable");

  if (ENABLE_CRS_COMPRESSION) {
    emitTable2(out, firstWithTerminal, numTerms, 16,
               "StateId", "firstWithTerminal");

    emitTable2(out, firstWithNonterminal, numNonterms, 16,
               "StateId", "firstWithNonterminal");

    emitTable2(out, bigProductionList, bigProductionListSize, 16,
               "ProdIndex", "bigProductionList");

    emitOffsetTable(out, productionsForState, bigProductionList, numStates,
                    "ProdIndex*", "productionsForState", "bigProductionList");
                    
    emitOffsetTable(out, ambigStateTable, ambigTable, numStates,
                    "ActionEntry*", "ambigStateTable", "ambigTable");
  }
  else {
    out << "  firstWithTerminal = NULL;\n"
        << "  firstWithNonterminal = NULL;\n"
        << "  bigProductionList = NULL;\n"
        << "  productionsForState = NULL;\n"
        << "  ambigStateTable = NULL;\n"
        ;
  }

  out << "}\n"
      << "\n"
      << "\n"
      << "ParseTables *" << className << "::" << funcName << "()\n"
      << "{\n"
      << "  return new " << className << "_ParseTables;\n"
      << "}\n"
      << "\n"
      ;
}


// EOF
@h=tangler('elk/elk_ptreeact.cpp')
@select(h)
// ptreeact.cc            see license.txt for copyright and terms of use
// code for ptreeact.h

#include "elk_ptreeact.h"
#include "elk_ptreenode.h"
#include "elk_parsetables.h"
#include "sm_trace.h"


// ------------------- ParseTreeLexer -------------------
ParseTreeLexer::ParseTreeLexer(LexerInterface *u, UserActions *a)
  : underlying(u),
    underToken(u->getTokenFunc()),
    actions(a)
{
  // the underlying lexer is already primed
  copyFields();
}

STATICDEF void ParseTreeLexer::nextToken(LexerInterface *lex)
{
  ParseTreeLexer *ths = static_cast<ParseTreeLexer*>(lex);

  // call underlying token function
  ths->underToken(ths->underlying);

  // grab its fields
  ths->copyFields();
}

void ParseTreeLexer::copyFields()
{
  type = underlying->type;
  loc = underlying->loc;

  // leak underlying's 'sval'.. we'll just assume it doesn't matter

  // my sval is always a newly-allocated PTreeNode, with no children,
  // and named according to the name of the token yielded
  PTreeNode *ret = new PTreeNode(actions->terminalName(type));
  sval = (SemanticValue)ret;
}


sm_string ParseTreeLexer::tokenDesc() const
{
  return underlying->tokenDesc();
}

sm_string ParseTreeLexer::tokenKindDesc(int kind) const
{
  return underlying->tokenKindDesc(kind);
}


// ---------------------- ParseTreeActions -------------------
STATICDEF SemanticValue ParseTreeActions::reduce(
  UserActions *context,
  int productionId,
  SemanticValue const *svals
  SOURCELOCARG( SourceLoc loc ) )
{
  ParseTreeActions *ths = static_cast<ParseTreeActions*>(context);

  // get info about this production
  ParseTables::ProdInfo const &info = ths->tables->getProdInfo(productionId);
  xassert(info.rhsLen <= PTreeNode::MAXCHILDREN);

  // make a bare PTreeNode, labeled with the LHS nonterminal name
  PTreeNode *ret = new PTreeNode(ths->underlying->nonterminalName(info.lhsIndex));

  // add the children
  for (int i=0; i < info.rhsLen; i++) {
    ret->children[i] = (PTreeNode*)svals[i];
  }
  ret->numChildren = info.rhsLen;

  return (SemanticValue)ret;
}


SemanticValue ParseTreeActions::mergeAlternativeParses(
  int ntIndex, SemanticValue left, SemanticValue right
  SOURCELOCARG( SourceLoc loc ) )
{
  trace("ptreeactMerge") << underlying->nonterminalName(ntIndex) << "\n";

  // link the ambiguities together in the usual way
  PTreeNode *L = (PTreeNode*)left;
  PTreeNode *R = (PTreeNode*)right;

  L->addAlternative(R);
  return left;
}


char const *ParseTreeActions::terminalName(int termId)
{
  return underlying->terminalName(termId);
}

char const *ParseTreeActions::nonterminalName(int termId)
{
  return underlying->nonterminalName(termId);
}
@h=tangler('elk/elk_ptreenode.cpp')
@select(h)
// ptreenode.cc            see license.txt for copyright and terms of use
// code for ptreenode.h

#include "elk_ptreenode.h"
#include "sm_typ.h"
#include "sm_str.h"
#include "sm_trace.h"

#include <string.h>         // strchr

int PTreeNode::allocCount = 0;
int PTreeNode::alternativeCount = 0;


void PTreeNode::init()
{ 
  merged = NULL;
  allocCount++;
}


TreeCount PTreeNode::countTrees()
{
  // memoize to avoid exponential blowup
  if (count != 0) {
    return count;
  }
  
  else {
    // a single tree can have any possibility for each of
    // its children, so the result is their product
    count = 1;
    for (int i=0; i<numChildren; i++) {
      count *= children[i]->countTrees();
    }
    
    // are there alternatives?
    if (merged) {
      // add them too (recurse down the list of alts)
      count += merged->countTrees();
    }
  }

  return count;
}


void PTreeNode::printTree(ostream &out, PrintFlags pf) const
{
  if (tracingSys("ptreeAddrs")) {
    pf = (PrintFlags)(pf | PF_ADDRS);
  }
  innerPrintTree(out, 0 /*indentation*/, pf);
}


// amount to indent per level
enum { INDENT_INC = 2 };

void PTreeNode::innerPrintTree(ostream &out, int indentation, 
                               PrintFlags pf) const
{
  int alts = 1;
  sm_string LHS;

  if (merged) {
    // this is an ambiguity node
    alts = countMergedList();

    // since all of the alternatives should rewrite the same LHS
    // nonterminal, extract it from the first one
    char const *firstSpace = strchr(type, ' ');
    if (!firstSpace) {
      LHS = type;     // no space, use whole thing
    }
    else {
      LHS = sm_string(type, firstSpace-type);
    }

    indentation += INDENT_INC;
  }

  // iterate over interpretations
  int ct=1;
  for (PTreeNode const *n = this; n != NULL; n = n->merged) {
    if (alts > 1) {
      indent(out, indentation - INDENT_INC);
      out << "--------- ambiguous " << LHS << ": "
          << ct << " of " << alts << " ---------\n";
    }

    indent(out, indentation);

    out << n->type;
    if (pf & PF_EXPAND) {
      // the type is just the LHS name; write out the RHS names
      // after an "->"
      if (n->numChildren) {
        out << " ->";
        for (int c=0; c < n->numChildren; c++) {
          out << " " << n->children[c]->type;
        }
      }
    }

    if (pf & PF_ADDRS) {
      // print the parse tree node address, so I can verify proper sharing
      out << " (" << ((void*)n) << ")";
    }
    out << "\n";

    // iterate over children
    for (int c=0; c < n->numChildren; c++) {
      // recursively print children
      n->children[c]->innerPrintTree(out, indentation + INDENT_INC, pf);
    }

    ct++;
  }

  if (merged) {
    // close up ambiguity display
    indentation -= INDENT_INC;
    indent(out, indentation);
    out << "--------- end of ambiguous " << LHS << " ---------\n";
  }
}

STATICDEF void PTreeNode::indent(ostream &out, int n)
{
  for (int i=0; i<n; i++) {
    out << " ";
  }
}

// # of nodes on the 'merged' list; always at least 1 since
// 'this' is considered to be in that list
int PTreeNode::countMergedList() const
{
  int ct = 1;
  for (PTreeNode const *n = merged; n != NULL; n = n->merged) {
    ct++;
  }
  return ct;
}


void PTreeNode::addAlternative(PTreeNode *alt)
{
  // insert as 2nd element
  alt->merged = this->merged;
  this->merged = alt;
  
  alternativeCount++;
}
@h=tangler('elk/elk_useract.cpp')
@select(h)
// useract.cc            see license.txt for copyright and terms of use
// code for useract.h

#include "elk_useract.h"
#include "sm_typ.h"
#include "sm_xassert.h"


UserActions::~UserActions()
{}


ParseTables *UserActions::makeTables()
{
  xfailure("this object does not have any tables");
  return NULL;   // silence warning
}


// ----------------- TrivialUserActions --------------------
UserActions::ReductionActionFunc TrivialUserActions::getReductionAction()
{
  return &TrivialUserActions::doReductionAction;
}

STATICDEF SemanticValue TrivialUserActions::doReductionAction(
  UserActions *, int , SemanticValue const *
  SOURCELOCARG( SourceLoc ) )
  { return NULL_SVAL; }

SemanticValue TrivialUserActions::duplicateTerminalValue(
  int , SemanticValue sval)
  { return sval; }

SemanticValue TrivialUserActions::duplicateNontermValue(
  int , SemanticValue sval)
  { return sval; }


void TrivialUserActions::deallocateTerminalValue(
  int , SemanticValue )
  {}

void TrivialUserActions::deallocateNontermValue(
  int , SemanticValue )
  {}

SemanticValue TrivialUserActions::mergeAlternativeParses(
  int , SemanticValue left, SemanticValue
  SOURCELOCARG( SourceLoc ) )
  { return left; }

bool TrivialUserActions::keepNontermValue(int , SemanticValue )
  { return true; }     // do not cancel


UserActions::ReclassifyFunc TrivialUserActions::getReclassifier()
{
  return &TrivialUserActions::reclassifyToken;
}

STATICDEF int TrivialUserActions::reclassifyToken(UserActions *,
  int oldTokenType, SemanticValue )
  { return oldTokenType; }

sm_string TrivialUserActions::terminalDescription(int, SemanticValue)
  { return sm_string(""); }

sm_string TrivialUserActions::nonterminalDescription(int, SemanticValue)
  { return sm_string(""); }
  
char const *TrivialUserActions::terminalName(int)
  { return ""; }
char const *TrivialUserActions::nonterminalName(int)
  { return ""; }

